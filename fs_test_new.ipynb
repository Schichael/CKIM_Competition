{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 13:11:47,014 (utils:129)INFO: the current machine is at 127.0.1.1\n",
      "2022-10-18 13:11:47,015 (utils:131)INFO: the current dir is /home/michael/Projects/CKIM_Competition\n",
      "2022-10-18 13:11:47,016 (utils:132)INFO: the output dir is exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "2022-10-18 13:11:47,038 (cikm_cup:57)INFO: Loading CIKMCUP data from /home/michael/Projects/CKIM_Competition/data/CIKM22Competition.\n",
      "2022-10-18 13:11:47,040 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #1.\n",
      "2022-10-18 13:11:47,041 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #2.\n",
      "2022-10-18 13:11:47,043 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #3.\n",
      "2022-10-18 13:11:47,044 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #4.\n",
      "2022-10-18 13:11:47,047 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #5.\n",
      "2022-10-18 13:11:47,048 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #6.\n",
      "2022-10-18 13:11:47,048 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #7.\n",
      "2022-10-18 13:11:47,049 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #8.\n",
      "2022-10-18 13:11:47,077 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graph\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:47,312 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-10-18 13:11:47,523 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.263789\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:47,590 (fed_runner:302)INFO: Client 1 has been set up ... \n",
      "2022-10-18 13:11:47,606 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.289617\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:47,662 (fed_runner:302)INFO: Client 2 has been set up ... \n",
      "2022-10-18 13:11:47,678 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.355404\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:47,767 (fed_runner:302)INFO: Client 3 has been set up ... \n",
      "2022-10-18 13:11:47,783 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.176471\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:47,831 (fed_runner:302)INFO: Client 4 has been set up ... \n",
      "2022-10-18 13:11:47,857 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.396825\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:47,920 (fed_runner:302)INFO: Client 5 has been set up ... \n",
      "2022-10-18 13:11:47,936 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.26158\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.0005\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:48,004 (fed_runner:302)INFO: Client 6 has been set up ... \n",
      "2022-10-18 13:11:48,021 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.302378\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:48,134 (fed_runner:302)INFO: Client 7 has been set up ... \n",
      "2022-10-18 13:11:48,149 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.211538\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 13:11:48,212 (fed_runner:302)INFO: Client 8 has been set up ... \n",
      "2022-10-18 13:11:48,213 (trainer:327)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-10-18 13:11:48,215 (trainer:335)INFO: Num of original para names: 66.\n",
      "2022-10-18 13:11:48,215 (trainer:336)INFO: Num of original trainable para names: 49.\n",
      "2022-10-18 13:11:48,216 (trainer:338)INFO: Num of preserved para names in local update: 33. \n",
      "Preserved para names in local update: {'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.1.nn.linears.1.bias', 'emb.weight', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.1.nn.norms.0.weight', 'gnn.convs.1.nn.norms.0.bias', 'gnn.convs.1.nn.norms.0.running_mean', 'gnn.convs.1.nn.linears.0.bias', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.1.eps', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.0.nn.norms.0.bias', 'linear.0.bias', 'gnn.convs.0.nn.norms.1.running_mean', 'gnn.convs.0.nn.norms.0.weight', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.linears.1.bias', 'gnn.convs.0.nn.norms.1.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.1.nn.norms.1.running_var', 'linear.0.weight', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.nn.linears.0.bias', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'gnn.convs.0.eps', 'gnn.convs.1.nn.norms.1.weight'}.\n",
      "2022-10-18 13:11:48,218 (trainer:342)INFO: Num of filtered para names in local update: 33. \n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.4.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.12.weight', 'encoder_atom.atom_embedding_list.11.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.16.weight', 'encoder_atom.atom_embedding_list.20.weight', 'bn_linear.num_batches_tracked', 'encoder_atom.atom_embedding_list.17.weight', 'encoder_atom.atom_embedding_list.1.weight', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.9.weight', 'encoder_atom.atom_embedding_list.15.weight', 'gnn.jk_linear.weight', 'encoder.bias', 'encoder_atom.atom_embedding_list.13.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.6.weight', 'bn_linear.running_var', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.14.weight', 'bn_linear.weight', 'bn_linear.running_mean', 'encoder_atom.atom_embedding_list.21.weight', 'encoder_atom.atom_embedding_list.10.weight', 'bn_linear.bias', 'encoder_atom.atom_embedding_list.5.weight', 'encoder.weight', 'encoder_atom.atom_embedding_list.19.weight', 'encoder_atom.atom_embedding_list.3.weight', 'gnn.jk_linear.bias', 'encoder_atom.atom_embedding_list.18.weight'}.\n",
      "2022-10-18 13:11:48,219 (trainer:347)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-10-18 13:11:48,221 (server:635)INFO: ----------- Starting training (Round #0) -------------\n",
      "2022-10-18 13:12:07,063 (client:260)INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_imp_ratio': 26.7773, 'train_avg_loss': 0.491415, 'train_loss': 10948.716271, 'train_total': 22280}}\n",
      "2022-10-18 13:12:24,703 (client:260)INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_imp_ratio': 16.831663, 'train_avg_loss': 0.571016, 'train_loss': 12670.850388, 'train_total': 22190}}\n",
      "2022-10-18 13:12:25,960 (client:260)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_imp_ratio': -63.103578, 'train_avg_loss': 0.701149, 'train_loss': 1269.079577, 'train_total': 1810}}\n",
      "2022-10-18 13:12:31,790 (client:260)INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_imp_ratio': 32.467385, 'train_avg_loss': 0.362563, 'train_loss': 2817.115734, 'train_total': 7770}}\n",
      "2022-10-18 13:12:32,907 (client:260)INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_imp_ratio': -21.187836, 'train_avg_loss': 0.524285, 'train_loss': 529.528285, 'train_total': 1010}}\n",
      "2022-10-18 13:12:43,083 (client:260)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_imp_ratio': 11.646637, 'train_avg_loss': 0.522311, 'train_loss': 6523.659427, 'train_total': 12490}}\n",
      "2022-10-18 13:12:51,864 (client:260)INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_imp_ratio': 17.708213, 'train_avg_loss': 0.531309, 'train_loss': 5849.715969, 'train_total': 11010}}\n",
      "2022-10-18 13:12:53,201 (client:260)INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_imp_ratio': -7.368192, 'train_avg_loss': 0.692094, 'train_loss': 1301.13676, 'train_total': 1880}}\n",
      "2022-10-18 13:12:53,219 (server:314)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-10-18 13:12:53,222 (server:321)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-10-18 13:13:02,538 (monitor:512)INFO: current_best=-4.796753, should_save=True\n",
      "2022-10-18 13:13:02,540 (client:435)INFO: Client: #1, val_imp_ratio: -4.796753. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:13:04,032 (monitor:512)INFO: current_best=-89.905979, should_save=True\n",
      "2022-10-18 13:13:04,033 (client:435)INFO: Client: #2, val_imp_ratio: -89.905979. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:13:19,735 (monitor:512)INFO: current_best=19.011087, should_save=True\n",
      "2022-10-18 13:13:19,737 (client:435)INFO: Client: #3, val_imp_ratio: 19.011087. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:13:20,851 (monitor:512)INFO: current_best=-66.666278, should_save=True\n",
      "2022-10-18 13:13:20,852 (client:435)INFO: Client: #4, val_imp_ratio: -66.666278. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model4.pth\n",
      "2022-10-18 13:13:22,373 (monitor:512)INFO: current_best=-8.000108, should_save=True\n",
      "2022-10-18 13:13:22,374 (client:435)INFO: Client: #5, val_imp_ratio: -8.000108. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model5.pth\n",
      "2022-10-18 13:13:30,177 (monitor:512)INFO: current_best=23.958222, should_save=True\n",
      "2022-10-18 13:13:30,179 (client:435)INFO: Client: #6, val_imp_ratio: 23.958222. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model6.pth\n",
      "2022-10-18 13:13:46,146 (monitor:512)INFO: current_best=1.187026, should_save=True\n",
      "2022-10-18 13:13:46,147 (client:435)INFO: Client: #7, val_imp_ratio: 1.187026. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model7.pth\n",
      "2022-10-18 13:13:52,336 (monitor:512)INFO: current_best=48.894237, should_save=True\n",
      "2022-10-18 13:13:52,337 (client:435)INFO: Client: #8, val_imp_ratio: 48.894237. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model8.pth\n",
      "2022-10-18 13:13:53,838 (client:260)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_imp_ratio': -23.233815, 'train_avg_loss': 0.65025, 'train_loss': 1176.953198, 'train_total': 1810}}\n",
      "2022-10-18 13:14:11,103 (client:260)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_imp_ratio': 37.21224, 'train_avg_loss': 0.43476, 'train_loss': 9686.454922, 'train_total': 22280}}\n",
      "2022-10-18 13:14:11,959 (client:260)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_imp_ratio': 26.501822, 'train_avg_loss': 0.418961, 'train_loss': 423.151087, 'train_total': 1010}}\n",
      "2022-10-18 13:14:17,592 (client:260)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_imp_ratio': 45.487187, 'train_avg_loss': 0.304553, 'train_loss': 2366.374247, 'train_total': 7770}}\n",
      "2022-10-18 13:14:28,159 (client:260)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_imp_ratio': 31.101981, 'train_avg_loss': 0.416186, 'train_loss': 5198.16287, 'train_total': 12490}}\n",
      "2022-10-18 13:14:29,550 (client:260)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_imp_ratio': 8.985015, 'train_avg_loss': 0.634997, 'train_loss': 1193.794102, 'train_total': 1880}}\n",
      "2022-10-18 13:14:46,354 (client:260)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_imp_ratio': 28.484613, 'train_avg_loss': 0.522246, 'train_loss': 11588.645546, 'train_total': 22190}}\n",
      "2022-10-18 13:14:54,828 (client:260)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_imp_ratio': 32.638791, 'train_avg_loss': 0.455651, 'train_loss': 5016.718045, 'train_total': 11010}}\n",
      "2022-10-18 13:14:54,831 (server:487)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_imp_ratio': -132.131619, 'test_avg_loss': 1.008985, 'test_loss': 311.068973, 'test_total': 335.625, 'val_imp_ratio': -9.539818, 'val_avg_loss': 0.563565, 'val_loss': 183.321728, 'val_total': 335.25}}\n",
      "2022-10-18 13:14:54,833 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-10-18 13:14:54,833 (monitor:512)INFO: current_best=-9.539818, should_save=True\n",
      "2022-10-18 13:14:54,854 (server:314)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-10-18 13:14:54,858 (server:321)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-10-18 13:15:03,814 (monitor:512)INFO: current_best=19.807702, should_save=True\n",
      "2022-10-18 13:15:03,815 (client:435)INFO: Client: #1, val_imp_ratio: 19.807702. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:15:05,329 (monitor:512)INFO: current_best=-61.132346, should_save=True\n",
      "2022-10-18 13:15:05,330 (client:435)INFO: Client: #2, val_imp_ratio: -61.132346. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:15:20,813 (monitor:512)INFO: current_best=24.334302, should_save=True\n",
      "2022-10-18 13:15:20,814 (client:435)INFO: Client: #3, val_imp_ratio: 24.334302. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:15:21,853 (monitor:512)INFO: current_best=16.666861, should_save=True\n",
      "2022-10-18 13:15:21,854 (client:435)INFO: Client: #4, val_imp_ratio: 16.666861. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model4.pth\n",
      "2022-10-18 13:15:23,472 (monitor:512)INFO: current_best=7.999908, should_save=True\n",
      "2022-10-18 13:15:23,473 (client:435)INFO: Client: #5, val_imp_ratio: 7.999908. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model5.pth\n",
      "2022-10-18 13:15:31,787 (monitor:512)INFO: current_best=42.70825, should_save=True\n",
      "2022-10-18 13:15:31,789 (client:435)INFO: Client: #6, val_imp_ratio: 42.70825. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model6.pth\n",
      "2022-10-18 13:15:47,100 (monitor:512)INFO: current_best=22.10689, should_save=True\n",
      "2022-10-18 13:15:47,102 (client:435)INFO: Client: #7, val_imp_ratio: 22.10689. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model7.pth\n",
      "2022-10-18 13:15:52,885 (monitor:512)INFO: current_best=52.544649, should_save=True\n",
      "2022-10-18 13:15:52,887 (client:435)INFO: Client: #8, val_imp_ratio: 52.544649. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model8.pth\n",
      "2022-10-18 13:16:02,613 (client:260)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_imp_ratio': 34.722127, 'train_avg_loss': 0.431743, 'train_loss': 4753.485534, 'train_total': 11010}}\n",
      "2022-10-18 13:16:20,033 (client:260)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_imp_ratio': 33.873628, 'train_avg_loss': 0.498134, 'train_loss': 11053.598942, 'train_total': 22190}}\n",
      "2022-10-18 13:16:20,850 (client:260)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_imp_ratio': 38.845027, 'train_avg_loss': 0.365196, 'train_loss': 368.848262, 'train_total': 1010}}\n",
      "2022-10-18 13:16:22,241 (client:260)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_imp_ratio': 20.110558, 'train_avg_loss': 0.609529, 'train_loss': 1145.915459, 'train_total': 1880}}\n",
      "2022-10-18 13:16:27,761 (client:260)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_imp_ratio': 53.457252, 'train_avg_loss': 0.261973, 'train_loss': 2035.530435, 'train_total': 7770}}\n",
      "2022-10-18 13:16:37,622 (client:260)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_imp_ratio': 45.640373, 'train_avg_loss': 0.345666, 'train_loss': 4317.36566, 'train_total': 12490}}\n",
      "2022-10-18 13:16:54,206 (client:260)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_imp_ratio': 43.194147, 'train_avg_loss': 0.399656, 'train_loss': 8904.33458, 'train_total': 22280}}\n",
      "2022-10-18 13:16:55,449 (client:260)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_imp_ratio': -6.446546, 'train_avg_loss': 0.628959, 'train_loss': 1138.415346, 'train_total': 1810}}\n",
      "2022-10-18 13:16:55,454 (server:487)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_imp_ratio': -119.476186, 'test_avg_loss': 1.092879, 'test_loss': 345.309642, 'test_total': 335.625, 'val_imp_ratio': 15.629527, 'val_avg_loss': 0.524753, 'val_loss': 168.624974, 'val_total': 335.25}}\n",
      "2022-10-18 13:16:55,455 (monitor:512)INFO: current_best=-9.539818, should_save=False\n",
      "2022-10-18 13:16:55,458 (monitor:512)INFO: current_best=15.629527, should_save=True\n",
      "2022-10-18 13:16:55,478 (server:314)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-10-18 13:16:55,480 (server:321)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-10-18 13:17:04,362 (monitor:512)INFO: current_best=47.145985, should_save=True\n",
      "2022-10-18 13:17:04,363 (client:435)INFO: Client: #1, val_imp_ratio: 47.145985. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:17:05,886 (monitor:512)INFO: current_best=-43.868166, should_save=True\n",
      "2022-10-18 13:17:05,888 (client:435)INFO: Client: #2, val_imp_ratio: -43.868166. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:17:21,315 (monitor:512)INFO: current_best=31.178435, should_save=True\n",
      "2022-10-18 13:17:21,317 (client:435)INFO: Client: #3, val_imp_ratio: 31.178435. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:17:22,253 (monitor:512)INFO: current_best=50.000117, should_save=True\n",
      "2022-10-18 13:17:22,254 (client:435)INFO: Client: #4, val_imp_ratio: 50.000117. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model4.pth\n",
      "2022-10-18 13:17:23,758 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:17:32,058 (monitor:512)INFO: current_best=46.874923, should_save=True\n",
      "2022-10-18 13:17:32,059 (client:435)INFO: Client: #6, val_imp_ratio: 46.874923. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model6.pth\n",
      "2022-10-18 13:17:47,789 (monitor:512)INFO: current_best=27.003028, should_save=True\n",
      "2022-10-18 13:17:47,790 (client:435)INFO: Client: #7, val_imp_ratio: 27.003028. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model7.pth\n",
      "2022-10-18 13:17:54,017 (monitor:512)INFO: current_best=52.544649, should_save=False\n",
      "2022-10-18 13:18:10,920 (client:260)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'train_imp_ratio': 37.119716, 'train_avg_loss': 0.481185, 'train_loss': 10677.487355, 'train_total': 22190}}\n",
      "2022-10-18 13:18:19,383 (client:260)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'train_imp_ratio': 37.256853, 'train_avg_loss': 0.414946, 'train_loss': 4568.558433, 'train_total': 11010}}\n",
      "2022-10-18 13:18:35,751 (client:260)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'train_imp_ratio': 48.404195, 'train_avg_loss': 0.37392, 'train_loss': 8330.945348, 'train_total': 22280}}\n",
      "2022-10-18 13:18:41,364 (client:260)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_imp_ratio': 55.464978, 'train_avg_loss': 0.249746, 'train_loss': 1940.524258, 'train_total': 7770}}\n",
      "2022-10-18 13:18:42,194 (client:260)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'train_imp_ratio': 41.089246, 'train_avg_loss': 0.331632, 'train_loss': 334.948263, 'train_total': 1010}}\n",
      "2022-10-18 13:18:43,547 (client:260)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'train_imp_ratio': 24.533967, 'train_avg_loss': 0.594227, 'train_loss': 1117.146697, 'train_total': 1880}}\n",
      "2022-10-18 13:18:44,847 (client:260)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_imp_ratio': -0.342084, 'train_avg_loss': 0.61367, 'train_loss': 1110.741896, 'train_total': 1810}}\n",
      "2022-10-18 13:18:54,766 (client:260)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_imp_ratio': 55.74744, 'train_avg_loss': 0.301853, 'train_loss': 3770.139924, 'train_total': 12490}}\n",
      "2022-10-18 13:18:54,769 (server:487)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_imp_ratio': -107.957131, 'test_avg_loss': 1.161844, 'test_loss': 370.74063, 'test_total': 335.625, 'val_imp_ratio': 24.990954, 'val_avg_loss': 0.507559, 'val_loss': 159.729761, 'val_total': 335.25}}\n",
      "2022-10-18 13:18:54,770 (monitor:512)INFO: current_best=15.629527, should_save=False\n",
      "2022-10-18 13:18:54,771 (monitor:512)INFO: current_best=24.990954, should_save=True\n",
      "2022-10-18 13:18:54,789 (server:314)INFO: Server #0: Starting evaluation at the end of round 3.\n",
      "2022-10-18 13:18:54,792 (server:321)INFO: ----------- Starting a new training round (Round #4) -------------\n",
      "2022-10-18 13:19:03,841 (monitor:512)INFO: current_best=58.992575, should_save=True\n",
      "2022-10-18 13:19:03,842 (client:435)INFO: Client: #1, val_imp_ratio: 58.992575. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:19:05,347 (monitor:512)INFO: current_best=-26.603986, should_save=True\n",
      "2022-10-18 13:19:05,348 (client:435)INFO: Client: #2, val_imp_ratio: -26.603986. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:19:20,763 (monitor:512)INFO: current_best=32.319124, should_save=True\n",
      "2022-10-18 13:19:20,764 (client:435)INFO: Client: #3, val_imp_ratio: 32.319124. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:19:21,736 (monitor:512)INFO: current_best=50.000117, should_save=True\n",
      "2022-10-18 13:19:21,738 (client:435)INFO: Client: #4, val_imp_ratio: 50.000117. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model4.pth\n",
      "2022-10-18 13:19:23,193 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:19:31,958 (monitor:512)INFO: current_best=46.874923, should_save=False\n",
      "2022-10-18 13:19:47,690 (monitor:512)INFO: current_best=31.899167, should_save=True\n",
      "2022-10-18 13:19:47,692 (client:435)INFO: Client: #7, val_imp_ratio: 31.899167. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model7.pth\n",
      "2022-10-18 13:19:53,642 (monitor:512)INFO: current_best=58.020266, should_save=True\n",
      "2022-10-18 13:19:53,644 (client:435)INFO: Client: #8, val_imp_ratio: 58.020266. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model8.pth\n",
      "2022-10-18 13:19:55,250 (client:260)INFO: {'Role': 'Client #5', 'Round': 4, 'Results_raw': {'train_imp_ratio': 28.421205, 'train_avg_loss': 0.578392, 'train_loss': 1087.377276, 'train_total': 1880}}\n",
      "2022-10-18 13:20:04,417 (client:260)INFO: {'Role': 'Client #6', 'Round': 4, 'Results_raw': {'train_imp_ratio': 38.090187, 'train_avg_loss': 0.402454, 'train_loss': 4431.015704, 'train_total': 11010}}\n",
      "2022-10-18 13:20:05,787 (client:260)INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_imp_ratio': 1.374795, 'train_avg_loss': 0.603964, 'train_loss': 1093.174227, 'train_total': 1810}}\n",
      "2022-10-18 13:20:22,439 (client:260)INFO: {'Role': 'Client #7', 'Round': 4, 'Results_raw': {'train_imp_ratio': 53.287688, 'train_avg_loss': 0.346692, 'train_loss': 7724.292735, 'train_total': 22280}}\n",
      "2022-10-18 13:20:23,221 (client:260)INFO: {'Role': 'Client #4', 'Round': 4, 'Results_raw': {'train_imp_ratio': 46.699794, 'train_avg_loss': 0.310884, 'train_loss': 313.992556, 'train_total': 1010}}\n",
      "2022-10-18 13:20:40,442 (client:260)INFO: {'Role': 'Client #3', 'Round': 4, 'Results_raw': {'train_imp_ratio': 39.630363, 'train_avg_loss': 0.466497, 'train_loss': 10351.571289, 'train_total': 22190}}\n",
      "2022-10-18 13:20:50,658 (client:260)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_imp_ratio': 61.787398, 'train_avg_loss': 0.264972, 'train_loss': 3309.494646, 'train_total': 12490}}\n",
      "2022-10-18 13:20:56,078 (client:260)INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_imp_ratio': 61.792358, 'train_avg_loss': 0.21758, 'train_loss': 1690.596848, 'train_total': 7770}}\n",
      "2022-10-18 13:20:56,081 (server:487)INFO: {'Role': 'Server #', 'Round': 4, 'Results_avg': {'test_imp_ratio': -106.066973, 'test_avg_loss': 1.281977, 'test_loss': 407.914213, 'test_total': 335.625, 'val_imp_ratio': 30.547135, 'val_avg_loss': 0.484366, 'val_loss': 150.698464, 'val_total': 335.25}}\n",
      "2022-10-18 13:20:56,082 (monitor:512)INFO: current_best=24.990954, should_save=False\n",
      "2022-10-18 13:20:56,083 (monitor:512)INFO: current_best=30.547135, should_save=True\n",
      "2022-10-18 13:20:56,103 (server:314)INFO: Server #0: Starting evaluation at the end of round 4.\n",
      "2022-10-18 13:20:56,107 (server:321)INFO: ----------- Starting a new training round (Round #5) -------------\n",
      "2022-10-18 13:21:05,594 (monitor:512)INFO: current_best=66.282784, should_save=True\n",
      "2022-10-18 13:21:05,595 (client:435)INFO: Client: #1, val_imp_ratio: 66.282784. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:21:07,152 (monitor:512)INFO: current_best=-26.603986, should_save=False\n",
      "2022-10-18 13:21:22,778 (monitor:512)INFO: current_best=33.840043, should_save=True\n",
      "2022-10-18 13:21:22,779 (client:435)INFO: Client: #3, val_imp_ratio: 33.840043. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:21:23,784 (monitor:512)INFO: current_best=50.000117, should_save=False\n",
      "2022-10-18 13:21:25,298 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:21:33,570 (monitor:512)INFO: current_best=46.874923, should_save=False\n",
      "2022-10-18 13:21:49,676 (monitor:512)INFO: current_best=34.124684, should_save=True\n",
      "2022-10-18 13:21:49,677 (client:435)INFO: Client: #7, val_imp_ratio: 34.124684. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model7.pth\n",
      "2022-10-18 13:21:55,931 (monitor:512)INFO: current_best=58.020266, should_save=False\n",
      "2022-10-18 13:21:57,352 (client:260)INFO: {'Role': 'Client #5', 'Round': 5, 'Results_raw': {'train_imp_ratio': 30.699931, 'train_avg_loss': 0.569371, 'train_loss': 1070.416895, 'train_total': 1880}}\n",
      "2022-10-18 13:22:14,196 (client:260)INFO: {'Role': 'Client #3', 'Round': 5, 'Results_raw': {'train_imp_ratio': 42.53409, 'train_avg_loss': 0.454977, 'train_loss': 10095.932271, 'train_total': 22190}}\n",
      "2022-10-18 13:22:19,783 (client:260)INFO: {'Role': 'Client #8', 'Round': 5, 'Results_raw': {'train_imp_ratio': 66.051172, 'train_avg_loss': 0.196582, 'train_loss': 1527.442947, 'train_total': 7770}}\n",
      "2022-10-18 13:22:21,112 (client:260)INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'train_imp_ratio': -2.440493, 'train_avg_loss': 0.594133, 'train_loss': 1075.380169, 'train_total': 1810}}\n",
      "2022-10-18 13:22:31,283 (client:260)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'train_imp_ratio': 63.547788, 'train_avg_loss': 0.252425, 'train_loss': 3152.789601, 'train_total': 12490}}\n",
      "2022-10-18 13:22:48,074 (client:260)INFO: {'Role': 'Client #7', 'Round': 5, 'Results_raw': {'train_imp_ratio': 55.380613, 'train_avg_loss': 0.328456, 'train_loss': 7317.990775, 'train_total': 22280}}\n",
      "2022-10-18 13:22:48,891 (client:260)INFO: {'Role': 'Client #4', 'Round': 5, 'Results_raw': {'train_imp_ratio': 50.627178, 'train_avg_loss': 0.292497, 'train_loss': 295.42209, 'train_total': 1010}}\n",
      "2022-10-18 13:22:57,574 (client:260)INFO: {'Role': 'Client #6', 'Round': 5, 'Results_raw': {'train_imp_ratio': 40.104079, 'train_avg_loss': 0.392744, 'train_loss': 4324.115797, 'train_total': 11010}}\n",
      "2022-10-18 13:22:57,578 (server:487)INFO: {'Role': 'Server #', 'Round': 5, 'Results_avg': {'test_imp_ratio': -107.502612, 'test_avg_loss': 1.31053, 'test_loss': 413.927023, 'test_total': 335.625, 'val_imp_ratio': 25.954207, 'val_avg_loss': 0.480093, 'val_loss': 149.255819, 'val_total': 335.25}}\n",
      "2022-10-18 13:22:57,579 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:22:57,580 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:22:57,597 (server:314)INFO: Server #0: Starting evaluation at the end of round 5.\n",
      "2022-10-18 13:22:57,599 (server:321)INFO: ----------- Starting a new training round (Round #6) -------------\n",
      "2022-10-18 13:23:06,715 (monitor:512)INFO: current_best=71.75044, should_save=True\n",
      "2022-10-18 13:23:06,717 (client:435)INFO: Client: #1, val_imp_ratio: 71.75044. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:23:08,252 (monitor:512)INFO: current_best=-26.603986, should_save=True\n",
      "2022-10-18 13:23:08,253 (client:435)INFO: Client: #2, val_imp_ratio: -26.603986. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:23:24,192 (monitor:512)INFO: current_best=34.220272, should_save=True\n",
      "2022-10-18 13:23:24,193 (client:435)INFO: Client: #3, val_imp_ratio: 34.220272. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:23:25,243 (monitor:512)INFO: current_best=50.000117, should_save=False\n",
      "2022-10-18 13:23:26,761 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:23:35,488 (monitor:512)INFO: current_best=46.874923, should_save=False\n",
      "2022-10-18 13:23:50,792 (monitor:512)INFO: current_best=34.124684, should_save=False\n",
      "2022-10-18 13:23:56,614 (monitor:512)INFO: current_best=59.845472, should_save=True\n",
      "2022-10-18 13:23:56,615 (client:435)INFO: Client: #8, val_imp_ratio: 59.845472. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model8.pth\n",
      "2022-10-18 13:24:13,841 (client:260)INFO: {'Role': 'Client #7', 'Round': 6, 'Results_raw': {'train_imp_ratio': 57.933685, 'train_avg_loss': 0.311825, 'train_loss': 6947.462808, 'train_total': 22280}}\n",
      "2022-10-18 13:24:15,157 (client:260)INFO: {'Role': 'Client #2', 'Round': 6, 'Results_raw': {'train_imp_ratio': 0.802502, 'train_avg_loss': 0.585613, 'train_loss': 1059.95875, 'train_total': 1810}}\n",
      "2022-10-18 13:24:23,850 (client:260)INFO: {'Role': 'Client #6', 'Round': 6, 'Results_raw': {'train_imp_ratio': 39.791579, 'train_avg_loss': 0.383547, 'train_loss': 4222.856339, 'train_total': 11010}}\n",
      "2022-10-18 13:24:24,697 (client:260)INFO: {'Role': 'Client #4', 'Round': 6, 'Results_raw': {'train_imp_ratio': 49.505068, 'train_avg_loss': 0.276565, 'train_loss': 279.33084, 'train_total': 1010}}\n",
      "2022-10-18 13:24:26,035 (client:260)INFO: {'Role': 'Client #5', 'Round': 6, 'Results_raw': {'train_imp_ratio': 30.968016, 'train_avg_loss': 0.559193, 'train_loss': 1051.283729, 'train_total': 1880}}\n",
      "2022-10-18 13:24:42,196 (client:260)INFO: {'Role': 'Client #3', 'Round': 6, 'Results_raw': {'train_imp_ratio': 44.727736, 'train_avg_loss': 0.444697, 'train_loss': 9867.81711, 'train_total': 22190}}\n",
      "2022-10-18 13:24:52,229 (client:260)INFO: {'Role': 'Client #1', 'Round': 6, 'Results_raw': {'train_imp_ratio': 68.28263, 'train_avg_loss': 0.228617, 'train_loss': 2855.426064, 'train_total': 12490}}\n",
      "2022-10-18 13:24:58,001 (client:260)INFO: {'Role': 'Client #8', 'Round': 6, 'Results_raw': {'train_imp_ratio': 68.42394, 'train_avg_loss': 0.184507, 'train_loss': 1433.617559, 'train_total': 7770}}\n",
      "2022-10-18 13:24:58,005 (server:487)INFO: {'Role': 'Server #', 'Round': 6, 'Results_avg': {'test_imp_ratio': -106.445933, 'test_avg_loss': 1.384346, 'test_loss': 437.529243, 'test_total': 335.625, 'val_imp_ratio': 27.866434, 'val_avg_loss': 0.472029, 'val_loss': 147.222313, 'val_total': 335.25}}\n",
      "2022-10-18 13:24:58,007 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:24:58,009 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:24:58,030 (server:314)INFO: Server #0: Starting evaluation at the end of round 6.\n",
      "2022-10-18 13:24:58,033 (server:321)INFO: ----------- Starting a new training round (Round #7) -------------\n",
      "2022-10-18 13:25:07,463 (monitor:512)INFO: current_best=71.75044, should_save=True\n",
      "2022-10-18 13:25:07,464 (client:435)INFO: Client: #1, val_imp_ratio: 71.75044. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:25:09,180 (monitor:512)INFO: current_best=-20.84926, should_save=True\n",
      "2022-10-18 13:25:09,181 (client:435)INFO: Client: #2, val_imp_ratio: -20.84926. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:25:25,265 (monitor:512)INFO: current_best=36.12142, should_save=True\n",
      "2022-10-18 13:25:25,266 (client:435)INFO: Client: #3, val_imp_ratio: 36.12142. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:25:26,358 (monitor:512)INFO: current_best=50.000117, should_save=False\n",
      "2022-10-18 13:25:27,896 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:25:36,599 (monitor:512)INFO: current_best=46.874923, should_save=False\n",
      "2022-10-18 13:25:52,650 (monitor:512)INFO: current_best=34.124684, should_save=False\n",
      "2022-10-18 13:25:58,569 (monitor:512)INFO: current_best=63.495884, should_save=True\n",
      "2022-10-18 13:25:58,571 (client:435)INFO: Client: #8, val_imp_ratio: 63.495884. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model8.pth\n",
      "2022-10-18 13:26:08,417 (client:260)INFO: {'Role': 'Client #6', 'Round': 7, 'Results_raw': {'train_imp_ratio': 41.805471, 'train_avg_loss': 0.375061, 'train_loss': 4129.41871, 'train_total': 11010}}\n",
      "2022-10-18 13:26:09,848 (client:260)INFO: {'Role': 'Client #2', 'Round': 7, 'Results_raw': {'train_imp_ratio': -0.15132, 'train_avg_loss': 0.573575, 'train_loss': 1038.170982, 'train_total': 1810}}\n",
      "2022-10-18 13:26:10,703 (client:260)INFO: {'Role': 'Client #4', 'Round': 7, 'Results_raw': {'train_imp_ratio': 51.188233, 'train_avg_loss': 0.274218, 'train_loss': 276.959876, 'train_total': 1010}}\n",
      "2022-10-18 13:26:27,345 (client:260)INFO: {'Role': 'Client #7', 'Round': 7, 'Results_raw': {'train_imp_ratio': 61.466424, 'train_avg_loss': 0.292734, 'train_loss': 6522.120038, 'train_total': 22280}}\n",
      "2022-10-18 13:26:37,177 (client:260)INFO: {'Role': 'Client #1', 'Round': 7, 'Results_raw': {'train_imp_ratio': 71.682003, 'train_avg_loss': 0.210071, 'train_loss': 2623.787402, 'train_total': 12490}}\n",
      "2022-10-18 13:26:42,770 (client:260)INFO: {'Role': 'Client #8', 'Round': 7, 'Results_raw': {'train_imp_ratio': 69.336542, 'train_avg_loss': 0.171869, 'train_loss': 1335.420644, 'train_total': 7770}}\n",
      "2022-10-18 13:26:44,110 (client:260)INFO: {'Role': 'Client #5', 'Round': 7, 'Results_raw': {'train_imp_ratio': 31.906315, 'train_avg_loss': 0.555221, 'train_loss': 1043.81558, 'train_total': 1880}}\n",
      "2022-10-18 13:27:00,437 (client:260)INFO: {'Role': 'Client #3', 'Round': 7, 'Results_raw': {'train_imp_ratio': 46.45222, 'train_avg_loss': 0.435602, 'train_loss': 9666.013126, 'train_total': 22190}}\n",
      "2022-10-18 13:27:00,441 (server:487)INFO: {'Role': 'Server #', 'Round': 7, 'Results_avg': {'test_imp_ratio': -109.095283, 'test_avg_loss': 1.468181, 'test_loss': 463.867734, 'test_total': 335.625, 'val_imp_ratio': 28.835357, 'val_avg_loss': 0.467023, 'val_loss': 146.120078, 'val_total': 335.25}}\n",
      "2022-10-18 13:27:00,442 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:27:00,444 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:27:00,464 (server:314)INFO: Server #0: Starting evaluation at the end of round 7.\n",
      "2022-10-18 13:27:00,467 (server:321)INFO: ----------- Starting a new training round (Round #8) -------------\n",
      "2022-10-18 13:27:10,132 (monitor:512)INFO: current_best=71.75044, should_save=False\n",
      "2022-10-18 13:27:11,582 (monitor:512)INFO: current_best=-20.84926, should_save=True\n",
      "2022-10-18 13:27:11,583 (client:435)INFO: Client: #2, val_imp_ratio: -20.84926. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:27:27,596 (monitor:512)INFO: current_best=36.12142, should_save=False\n",
      "2022-10-18 13:27:28,662 (monitor:512)INFO: current_best=50.000117, should_save=False\n",
      "2022-10-18 13:27:30,176 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:27:38,787 (monitor:512)INFO: current_best=46.874923, should_save=False\n",
      "2022-10-18 13:27:54,115 (monitor:512)INFO: current_best=35.014891, should_save=True\n",
      "2022-10-18 13:27:54,116 (client:435)INFO: Client: #7, val_imp_ratio: 35.014891. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model7.pth\n",
      "2022-10-18 13:28:00,007 (monitor:512)INFO: current_best=67.146295, should_save=True\n",
      "2022-10-18 13:28:00,009 (client:435)INFO: Client: #8, val_imp_ratio: 67.146295. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model8.pth\n",
      "2022-10-18 13:28:17,779 (client:260)INFO: {'Role': 'Client #3', 'Round': 8, 'Results_raw': {'train_imp_ratio': 47.859704, 'train_avg_loss': 0.426147, 'train_loss': 9456.196407, 'train_total': 22190}}\n",
      "2022-10-18 13:28:18,624 (client:260)INFO: {'Role': 'Client #4', 'Round': 8, 'Results_raw': {'train_imp_ratio': 52.310342, 'train_avg_loss': 0.259618, 'train_loss': 262.214274, 'train_total': 1010}}\n",
      "2022-10-18 13:28:24,353 (client:260)INFO: {'Role': 'Client #8', 'Round': 8, 'Results_raw': {'train_imp_ratio': 71.952671, 'train_avg_loss': 0.16025, 'train_loss': 1245.141332, 'train_total': 7770}}\n",
      "2022-10-18 13:28:25,700 (client:260)INFO: {'Role': 'Client #2', 'Round': 8, 'Results_raw': {'train_imp_ratio': 1.374795, 'train_avg_loss': 0.567926, 'train_loss': 1027.946381, 'train_total': 1810}}\n",
      "2022-10-18 13:28:27,166 (client:260)INFO: {'Role': 'Client #5', 'Round': 8, 'Results_raw': {'train_imp_ratio': 33.916955, 'train_avg_loss': 0.548821, 'train_loss': 1031.782883, 'train_total': 1880}}\n",
      "2022-10-18 13:28:36,880 (client:260)INFO: {'Role': 'Client #1', 'Round': 8, 'Results_raw': {'train_imp_ratio': 75.020674, 'train_avg_loss': 0.194837, 'train_loss': 2433.517549, 'train_total': 12490}}\n",
      "2022-10-18 13:28:54,219 (client:260)INFO: {'Role': 'Client #7', 'Round': 8, 'Results_raw': {'train_imp_ratio': 63.767158, 'train_avg_loss': 0.27672, 'train_loss': 6165.324739, 'train_total': 22280}}\n",
      "2022-10-18 13:29:02,747 (client:260)INFO: {'Role': 'Client #6', 'Round': 8, 'Results_raw': {'train_imp_ratio': 43.402695, 'train_avg_loss': 0.365366, 'train_loss': 4022.6849, 'train_total': 11010}}\n",
      "2022-10-18 13:29:02,751 (server:487)INFO: {'Role': 'Server #', 'Round': 8, 'Results_avg': {'test_imp_ratio': -107.250444, 'test_avg_loss': 1.499919, 'test_loss': 470.862645, 'test_total': 335.625, 'val_imp_ratio': 29.002854, 'val_avg_loss': 0.460982, 'val_loss': 144.182093, 'val_total': 335.25}}\n",
      "2022-10-18 13:29:02,754 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:29:02,756 (monitor:512)INFO: current_best=30.547135, should_save=False\n",
      "2022-10-18 13:29:02,777 (server:314)INFO: Server #0: Starting evaluation at the end of round 8.\n",
      "2022-10-18 13:29:02,780 (server:321)INFO: ----------- Starting a new training round (Round #9) -------------\n",
      "2022-10-18 13:29:12,896 (monitor:512)INFO: current_best=75.395545, should_save=True\n",
      "2022-10-18 13:29:12,898 (client:435)INFO: Client: #1, val_imp_ratio: 75.395545. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model1.pth\n",
      "2022-10-18 13:29:14,578 (monitor:512)INFO: current_best=-20.84926, should_save=True\n",
      "2022-10-18 13:29:14,580 (client:435)INFO: Client: #2, val_imp_ratio: -20.84926. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model2.pth\n",
      "2022-10-18 13:29:31,578 (monitor:512)INFO: current_best=38.402798, should_save=True\n",
      "2022-10-18 13:29:31,579 (client:435)INFO: Client: #3, val_imp_ratio: 38.402798. model saved at exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018131147/model3.pth\n",
      "2022-10-18 13:29:32,567 (monitor:512)INFO: current_best=50.000117, should_save=False\n",
      "2022-10-18 13:29:34,154 (monitor:512)INFO: current_best=7.999908, should_save=False\n",
      "2022-10-18 13:29:42,900 (monitor:512)INFO: current_best=46.874923, should_save=False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 54\u001B[0m\n\u001B[1;32m     47\u001B[0m init_cfg\u001B[38;5;241m.\u001B[39mfreeze()\n\u001B[1;32m     49\u001B[0m runner \u001B[38;5;241m=\u001B[39m FedRunner(data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m     50\u001B[0m                    server_class\u001B[38;5;241m=\u001B[39mget_server_cls(init_cfg),\n\u001B[1;32m     51\u001B[0m                    client_class\u001B[38;5;241m=\u001B[39mget_client_cls(init_cfg),\n\u001B[1;32m     52\u001B[0m                    config\u001B[38;5;241m=\u001B[39minit_cfg\u001B[38;5;241m.\u001B[39mclone(),\n\u001B[1;32m     53\u001B[0m                    client_config\u001B[38;5;241m=\u001B[39mclient_cfg)\n\u001B[0;32m---> 54\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/fed_runner.py:186\u001B[0m, in \u001B[0;36mFedRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    185\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mfinish_fed_runner(fl_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mbest_results\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/fed_runner.py:325\u001B[0m, in \u001B[0;36m_handle_msg\u001B[0;34m(self, msg, rcv)\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m each_receiver \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mmsg_handlers[msg\u001B[38;5;241m.\u001B[39mmsg_type](msg)\n\u001B[0;32m--> 325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(download_bytes)\n\u001B[1;32m    326\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[each_receiver]\u001B[38;5;241m.\u001B[39mmsg_handlers[msg\u001B[38;5;241m.\u001B[39mmsg_type](msg)\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/worker/client.py:394\u001B[0m, in \u001B[0;36mcallback_funcs_for_evaluate\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfinetune\u001B[38;5;241m.\u001B[39mbefore_eval:\n\u001B[1;32m    393\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mfinetune()\n\u001B[0;32m--> 394\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39meval\u001B[38;5;241m.\u001B[39msplit:\n\u001B[1;32m    395\u001B[0m     eval_metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mevaluate(\n\u001B[1;32m    396\u001B[0m         target_data_split_name\u001B[38;5;241m=\u001B[39msplit)\n\u001B[1;32m    398\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistributed\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/trainers/trainer.py:239\u001B[0m, in \u001B[0;36mTrainer.finetune\u001B[0;34m(self, target_data_split_name, hooks_set)\u001B[0m\n\u001B[1;32m    235\u001B[0m hooks_set \u001B[38;5;241m=\u001B[39m hooks_set \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks_in_ft\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcheck_data_split(target_data_split_name)\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_routine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFINETUNE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_data_split_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_routine(MODE\u001B[38;5;241m.\u001B[39mFINETUNE, hooks_set, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/trainers/trainer.py:279\u001B[0m, in \u001B[0;36mTrainer._run_routine\u001B[0;34m(self, mode, hooks_set, dataset_name)\u001B[0m\n\u001B[1;32m    277\u001B[0m     hook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 279\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcur_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/gfl/trainer/graphtrainer.py:40\u001B[0m, in \u001B[0;36mGraphMiniBatchTrainer._hook_on_batch_forward\u001B[0;34m(self, ctx)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# record the index of the ${MODE} samples\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ctx\u001B[38;5;241m.\u001B[39mdata_batch, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_index\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(\n\u001B[1;32m     38\u001B[0m         ctx,\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mctx\u001B[38;5;241m.\u001B[39mcur_data_split\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_y_inds\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m---> 40\u001B[0m         ctx\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mctx\u001B[38;5;241m.\u001B[39mcur_data_split\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_y_inds\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m [batch[_]\u001B[38;5;241m.\u001B[39mdata_index\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     41\u001B[0m                                                    \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(label))]\n\u001B[1;32m     42\u001B[0m     )\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/gfl/trainer/graphtrainer.py:40\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# record the index of the ${MODE} samples\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ctx\u001B[38;5;241m.\u001B[39mdata_batch, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_index\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(\n\u001B[1;32m     39\u001B[0m         ctx,\n\u001B[0;32m---> 40\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mctx\u001B[38;5;241m.\u001B[39mcur_data_split\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_y_inds\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     41\u001B[0m         ctx\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mctx\u001B[38;5;241m.\u001B[39mcur_data_split\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_y_inds\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m [batch[_]\u001B[38;5;241m.\u001B[39mdata_index\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(label))]\n\u001B[1;32m     42\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# with 8 clients\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "DEV_MODE = False  # simplify the federatedscope re-setup everytime we change\n",
    "# the source codes of federatedscope\n",
    "if DEV_MODE:\n",
    "    file_dir = os.path.join(os.path.dirname(__file__), '..')\n",
    "    sys.path.append(file_dir)\n",
    "\n",
    "from federatedscope.core.cmd_args import parse_args\n",
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_client_cls, \\\n",
    "    get_server_cls\n",
    "from federatedscope.core.configs.config import global_cfg\n",
    "from federatedscope.core.fed_runner import FedRunner\n",
    "\n",
    "if os.environ.get('https_proxy'):\n",
    "    del os.environ['https_proxy']\n",
    "if os.environ.get('http_proxy'):\n",
    "    del os.environ['http_proxy']\n",
    "\n",
    "cfg = 'federatedscope/gfl/baseline/laplacian_gine_on_cikmcup.yaml'\n",
    "cfg_client = 'federatedscope/gfl/baseline/laplacian_gine_on_cikmcup_per_client.yaml'\n",
    "\n",
    "init_cfg = global_cfg.clone()\n",
    "#args = parse_args()\n",
    "init_cfg.merge_from_file(cfg)\n",
    "#init_cfg.merge_from_list(args.opts)\n",
    "\n",
    "update_logger(init_cfg)\n",
    "setup_seed(init_cfg.seed)\n",
    "\n",
    "# load clients' cfg file\n",
    "client_cfg = CfgNode.load_cfg(open(cfg_client,\n",
    "                                   'r')) if cfg_client else None\n",
    "\n",
    "# federated dataset might change the number of clients\n",
    "# thus, we allow the creation procedure of dataset to modify the global\n",
    "# cfg object\n",
    "data, modified_cfg = get_data(config=init_cfg.clone())\n",
    "init_cfg.merge_from_other_cfg(modified_cfg)\n",
    "\n",
    "init_cfg.freeze()\n",
    "\n",
    "runner = FedRunner(data=data,\n",
    "                   server_class=get_server_cls(init_cfg),\n",
    "                   client_class=get_client_cls(init_cfg),\n",
    "                   config=init_cfg.clone(),\n",
    "                   client_config=client_cfg)\n",
    "_ = runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
