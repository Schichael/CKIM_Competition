{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:08:32,682 (utils:129)INFO: the current machine is at 127.0.1.1\n",
      "2022-10-18 12:08:32,684 (utils:131)INFO: the current dir is /home/michael/Projects/CKIM_Competition\n",
      "2022-10-18 12:08:32,685 (utils:132)INFO: the output dir is exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "2022-10-18 12:08:32,763 (cikm_cup:57)INFO: Loading CIKMCUP data from /home/michael/Projects/CKIM_Competition/data/CIKM22Competition.\n",
      "2022-10-18 12:08:32,765 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #1.\n",
      "2022-10-18 12:08:33,125 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #2.\n",
      "2022-10-18 12:08:33,155 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #3.\n",
      "2022-10-18 12:08:33,578 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #4.\n",
      "2022-10-18 12:08:33,595 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #5.\n",
      "2022-10-18 12:08:33,630 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #6.\n",
      "2022-10-18 12:08:33,873 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #7.\n",
      "2022-10-18 12:08:34,300 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #8.\n",
      "2022-10-18 12:08:34,474 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graph\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:34,614 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-10-18 12:08:34,634 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.263789\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:34,689 (fed_runner:302)INFO: Client 1 has been set up ... \n",
      "2022-10-18 12:08:34,707 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.289617\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:34,758 (fed_runner:302)INFO: Client 2 has been set up ... \n",
      "2022-10-18 12:08:34,774 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.355404\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:34,847 (fed_runner:302)INFO: Client 3 has been set up ... \n",
      "2022-10-18 12:08:34,865 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.176471\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:34,910 (fed_runner:302)INFO: Client 4 has been set up ... \n",
      "2022-10-18 12:08:34,925 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.396825\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:34,975 (fed_runner:302)INFO: Client 5 has been set up ... \n",
      "2022-10-18 12:08:34,992 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.26158\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.0005\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:35,060 (fed_runner:302)INFO: Client 6 has been set up ... \n",
      "2022-10-18 12:08:35,077 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.302378\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:35,160 (fed_runner:302)INFO: Client 7 has been set up ... \n",
      "2022-10-18 12:08:35,175 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 8\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikmcup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.211538\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 8\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 8\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 200\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: True\n",
      "  freeze_param: \n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep10_/sub_exp_20221018120832\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'jk_linear']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-10-18 12:08:35,227 (fed_runner:302)INFO: Client 8 has been set up ... \n",
      "2022-10-18 12:08:35,228 (trainer:327)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-10-18 12:08:35,229 (trainer:335)INFO: Num of original para names: 66.\n",
      "2022-10-18 12:08:35,230 (trainer:336)INFO: Num of original trainable para names: 49.\n",
      "2022-10-18 12:08:35,231 (trainer:338)INFO: Num of preserved para names in local update: 33. \n",
      "Preserved para names in local update: {'gnn.convs.1.nn.norms.0.running_mean', 'gnn.convs.0.nn.norms.0.bias', 'gnn.convs.0.nn.linears.1.bias', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.0.nn.linears.0.bias', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.bias', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.1.nn.linears.1.bias', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'gnn.convs.1.nn.norms.1.weight', 'gnn.convs.0.eps', 'gnn.convs.1.nn.linears.0.weight', 'linear.0.bias', 'gnn.convs.1.eps', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.nn.norms.0.weight', 'gnn.convs.1.nn.norms.1.running_var', 'emb.weight', 'gnn.convs.0.nn.norms.1.weight', 'gnn.convs.0.nn.norms.1.running_mean', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.weight', 'linear.0.weight', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.0.bias'}.\n",
      "2022-10-18 12:08:35,232 (trainer:342)INFO: Num of filtered para names in local update: 33. \n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.17.weight', 'encoder_atom.atom_embedding_list.15.weight', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.20.weight', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.13.weight', 'encoder.weight', 'bn_linear.weight', 'encoder_atom.atom_embedding_list.18.weight', 'encoder_atom.atom_embedding_list.5.weight', 'encoder_atom.atom_embedding_list.14.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.3.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.10.weight', 'encoder_atom.atom_embedding_list.16.weight', 'encoder.bias', 'gnn.jk_linear.weight', 'encoder_atom.atom_embedding_list.12.weight', 'encoder_atom.atom_embedding_list.11.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.19.weight', 'encoder_atom.atom_embedding_list.1.weight', 'clf.weight', 'gnn.jk_linear.bias', 'bn_linear.bias', 'bn_linear.running_var', 'bn_linear.num_batches_tracked', 'encoder_atom.atom_embedding_list.4.weight', 'encoder_atom.atom_embedding_list.9.weight', 'encoder_atom.atom_embedding_list.21.weight', 'bn_linear.running_mean'}.\n",
      "2022-10-18 12:08:35,233 (trainer:347)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-10-18 12:08:35,238 (server:639)INFO: ----------- Starting training (Round #0) -------------\n",
      "2022-10-18 12:08:54,954 (client:259)INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_imp_ratio': 26.584335, 'train_avg_loss': 0.49093, 'train_total': 22280, 'train_loss': 10937.930682}}\n",
      "2022-10-18 12:09:11,564 (client:259)INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_imp_ratio': 16.831663, 'train_avg_loss': 0.571059, 'train_total': 22190, 'train_loss': 12671.793529}}\n",
      "2022-10-18 12:09:12,871 (client:259)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_imp_ratio': -63.103578, 'train_avg_loss': 0.701144, 'train_total': 1810, 'train_loss': 1269.070671}}\n",
      "2022-10-18 12:09:18,621 (client:259)INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_imp_ratio': 32.893266, 'train_avg_loss': 0.362052, 'train_total': 7770, 'train_loss': 2813.143869}}\n",
      "2022-10-18 12:09:19,414 (client:259)INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_imp_ratio': -21.187836, 'train_avg_loss': 0.524285, 'train_total': 1010, 'train_loss': 529.528278}}\n",
      "2022-10-18 12:09:28,563 (client:259)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_imp_ratio': 12.253668, 'train_avg_loss': 0.517902, 'train_total': 12490, 'train_loss': 6468.599394}}\n",
      "2022-10-18 12:09:35,992 (client:259)INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_imp_ratio': 17.708213, 'train_avg_loss': 0.531308, 'train_total': 11010, 'train_loss': 5849.696623}}\n",
      "2022-10-18 12:09:37,106 (client:259)INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_imp_ratio': -7.368192, 'train_avg_loss': 0.692095, 'train_total': 1880, 'train_loss': 1301.138383}}\n",
      "2022-10-18 12:09:37,134 (server:318)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-10-18 12:09:37,137 (server:325)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-10-18 12:09:44,911 (client:414)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_imp_ratio': 7.272738, 'test_avg_loss': 0.450462, 'test_total': 417, 'test_loss': 187.842504, 'val_imp_ratio': -3.885477, 'val_avg_loss': 0.525409, 'val_total': 416, 'val_loss': 218.570024}}\n",
      "2022-10-18 12:09:44,913 (monitor:512)INFO: current_best=-3.885477, should_save=True\n",
      "2022-10-18 12:09:46,268 (client:414)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'test_imp_ratio': 43.396131, 'test_avg_loss': 0.564053, 'test_total': 61, 'test_loss': 34.407218, 'val_imp_ratio': -66.887073, 'val_avg_loss': 0.697896, 'val_total': 60, 'val_loss': 41.873746}}\n",
      "2022-10-18 12:09:46,270 (monitor:512)INFO: current_best=-66.887073, should_save=True\n",
      "2022-10-18 12:10:01,774 (client:414)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'test_imp_ratio': 14.068101, 'test_avg_loss': 0.636426, 'test_total': 740, 'test_loss': 470.955137, 'val_imp_ratio': 21.292464, 'val_avg_loss': 0.591333, 'val_total': 740, 'val_loss': 437.586514}}\n",
      "2022-10-18 12:10:01,775 (monitor:512)INFO: current_best=21.292464, should_save=True\n",
      "2022-10-18 12:10:02,681 (client:414)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'test_imp_ratio': 0.000233, 'test_avg_loss': 0.518344, 'test_total': 34, 'test_loss': 17.623704, 'val_imp_ratio': -266.665811, 'val_avg_loss': 0.779732, 'val_total': 34, 'val_loss': 26.510892}}\n",
      "2022-10-18 12:10:02,683 (monitor:512)INFO: current_best=-266.665811, should_save=True\n",
      "2022-10-18 12:10:04,197 (client:414)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'test_imp_ratio': 87.999988, 'test_avg_loss': 0.526316, 'test_total': 63, 'test_loss': 33.157922, 'val_imp_ratio': -4.000104, 'val_avg_loss': 0.646563, 'val_total': 63, 'val_loss': 40.733484}}\n",
      "2022-10-18 12:10:04,198 (monitor:512)INFO: current_best=-4.000104, should_save=True\n",
      "2022-10-18 12:10:12,530 (client:414)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'test_imp_ratio': -251.042179, 'test_avg_loss': 1.165271, 'test_total': 367, 'test_loss': 427.654348, 'val_imp_ratio': 23.958222, 'val_avg_loss': 0.507993, 'val_total': 367, 'val_loss': 186.433305}}\n",
      "2022-10-18 12:10:12,532 (monitor:512)INFO: current_best=23.958222, should_save=True\n",
      "2022-10-18 12:10:27,983 (client:414)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'test_imp_ratio': -29.080011, 'test_avg_loss': 0.745156, 'test_total': 743, 'test_loss': 553.650727, 'val_imp_ratio': 1.632129, 'val_avg_loss': 0.571697, 'val_total': 743, 'val_loss': 424.771038}}\n",
      "2022-10-18 12:10:27,984 (monitor:512)INFO: current_best=1.632129, should_save=True\n",
      "2022-10-18 12:10:33,991 (client:414)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'test_imp_ratio': -354.546446, 'test_avg_loss': 2.756727, 'test_total': 260, 'test_loss': 716.748989, 'val_imp_ratio': 47.069032, 'val_avg_loss': 0.338606, 'val_total': 259, 'val_loss': 87.699024}}\n",
      "2022-10-18 12:10:33,993 (monitor:512)INFO: current_best=47.069032, should_save=True\n",
      "2022-10-18 12:10:35,511 (client:259)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_imp_ratio': -22.279993, 'train_avg_loss': 0.650976, 'train_total': 1810, 'train_loss': 1178.266713}}\n",
      "2022-10-18 12:10:53,826 (client:259)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_imp_ratio': 36.663032, 'train_avg_loss': 0.434296, 'train_total': 22280, 'train_loss': 9676.123669}}\n",
      "2022-10-18 12:10:54,625 (client:259)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_imp_ratio': 24.257602, 'train_avg_loss': 0.421478, 'train_total': 1010, 'train_loss': 425.692865}}\n",
      "2022-10-18 12:11:00,369 (client:259)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_imp_ratio': 44.574584, 'train_avg_loss': 0.306487, 'train_total': 7770, 'train_loss': 2381.404465}}\n",
      "2022-10-18 12:11:09,851 (client:259)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_imp_ratio': 33.681862, 'train_avg_loss': 0.408579, 'train_total': 12490, 'train_loss': 5103.157225}}\n",
      "2022-10-18 12:11:11,150 (client:259)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_imp_ratio': 10.459485, 'train_avg_loss': 0.633981, 'train_total': 1880, 'train_loss': 1191.883435}}\n",
      "2022-10-18 12:11:27,160 (client:259)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_imp_ratio': 28.535334, 'train_avg_loss': 0.52226, 'train_total': 22190, 'train_loss': 11588.95958}}\n",
      "2022-10-18 12:11:35,915 (client:259)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_imp_ratio': 32.499902, 'train_avg_loss': 0.456026, 'train_total': 11010, 'train_loss': 5020.850721}}\n",
      "2022-10-18 12:11:35,918 (server:491)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_imp_ratio': -60.24143, 'test_avg_loss': 0.920344, 'test_total': 335.625, 'test_loss': 305.255069, 'val_imp_ratio': -30.935827, 'val_avg_loss': 0.582404, 'val_total': 335.25, 'val_loss': 183.022253}}\n",
      "2022-10-18 12:11:35,919 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-10-18 12:11:35,921 (monitor:512)INFO: current_best=-30.935827, should_save=True\n",
      "2022-10-18 12:11:35,950 (server:318)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-10-18 12:11:35,952 (server:325)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-10-18 12:11:44,701 (client:414)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_imp_ratio': -29.999985, 'test_avg_loss': 0.917623, 'test_total': 417, 'test_loss': 382.64865, 'val_imp_ratio': 22.54153, 'val_avg_loss': 0.491401, 'val_total': 416, 'val_loss': 204.42271}}\n",
      "2022-10-18 12:11:44,703 (monitor:512)INFO: current_best=22.54153, should_save=True\n",
      "2022-10-18 12:11:46,043 (client:414)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'test_imp_ratio': 88.679226, 'test_avg_loss': 0.513699, 'test_total': 61, 'test_loss': 31.335661, 'val_imp_ratio': -55.377619, 'val_avg_loss': 0.696788, 'val_total': 60, 'val_loss': 41.807306}}\n",
      "2022-10-18 12:11:46,044 (monitor:512)INFO: current_best=-55.377619, should_save=True\n",
      "2022-10-18 12:12:00,397 (client:414)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'test_imp_ratio': 7.604197, 'test_avg_loss': 0.688289, 'test_total': 740, 'test_loss': 509.334019, 'val_imp_ratio': 24.334302, 'val_avg_loss': 0.557589, 'val_total': 740, 'val_loss': 412.616145}}\n",
      "2022-10-18 12:12:00,398 (monitor:512)INFO: current_best=24.334302, should_save=True\n",
      "2022-10-18 12:12:01,129 (client:414)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'test_imp_ratio': -33.333022, 'test_avg_loss': 0.531566, 'test_total': 34, 'test_loss': 18.073249, 'val_imp_ratio': -216.665928, 'val_avg_loss': 0.738204, 'val_total': 34, 'val_loss': 25.098926}}\n",
      "2022-10-18 12:12:01,130 (monitor:512)INFO: current_best=-216.665928, should_save=True\n",
      "2022-10-18 12:12:02,386 (client:414)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'test_imp_ratio': 83.999984, 'test_avg_loss': 0.519087, 'test_total': 63, 'test_loss': 32.702508, 'val_imp_ratio': -4.000104, 'val_avg_loss': 0.646003, 'val_total': 63, 'val_loss': 40.698167}}\n",
      "2022-10-18 12:12:02,387 (monitor:512)INFO: current_best=-4.000104, should_save=True\n",
      "2022-10-18 12:12:09,865 (client:414)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'test_imp_ratio': -234.375488, 'test_avg_loss': 1.359211, 'test_total': 367, 'test_loss': 498.830325, 'val_imp_ratio': 41.666582, 'val_avg_loss': 0.454915, 'val_total': 367, 'val_loss': 166.953844}}\n",
      "2022-10-18 12:12:09,866 (monitor:512)INFO: current_best=41.666582, should_save=True\n",
      "2022-10-18 12:12:25,889 (client:414)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'test_imp_ratio': -28.634908, 'test_avg_loss': 0.771758, 'test_total': 743, 'test_loss': 573.415925, 'val_imp_ratio': 23.887304, 'val_avg_loss': 0.505618, 'val_total': 743, 'val_loss': 375.674301}}\n",
      "2022-10-18 12:12:25,890 (monitor:512)INFO: current_best=23.887304, should_save=True\n",
      "2022-10-18 12:12:31,542 (client:414)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'test_imp_ratio': -352.72826, 'test_avg_loss': 2.805848, 'test_total': 260, 'test_loss': 729.520468, 'val_imp_ratio': 52.544649, 'val_avg_loss': 0.317297, 'val_total': 259, 'val_loss': 82.1799}}\n",
      "2022-10-18 12:12:31,543 (monitor:512)INFO: current_best=52.544649, should_save=True\n",
      "2022-10-18 12:12:40,995 (client:259)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_imp_ratio': 35.034627, 'train_avg_loss': 0.431732, 'train_total': 11010, 'train_loss': 4753.369494}}\n",
      "2022-10-18 12:12:58,777 (client:259)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_imp_ratio': 33.759507, 'train_avg_loss': 0.498296, 'train_total': 22190, 'train_loss': 11057.192775}}\n",
      "2022-10-18 12:12:59,642 (client:259)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_imp_ratio': 37.161863, 'train_avg_loss': 0.367721, 'train_total': 1010, 'train_loss': 371.398243}}\n",
      "2022-10-18 12:13:01,142 (client:259)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_imp_ratio': 21.048857, 'train_avg_loss': 0.608353, 'train_total': 1880, 'train_loss': 1143.704571}}\n",
      "2022-10-18 12:13:07,112 (client:259)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_imp_ratio': 53.092211, 'train_avg_loss': 0.261878, 'train_total': 7770, 'train_loss': 2034.788343}}\n",
      "2022-10-18 12:13:17,512 (client:259)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_imp_ratio': 48.038146, 'train_avg_loss': 0.336103, 'train_total': 12490, 'train_loss': 4197.929606}}\n",
      "2022-10-18 12:13:35,246 (client:259)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_imp_ratio': 43.238677, 'train_avg_loss': 0.398859, 'train_total': 22280, 'train_loss': 8886.578242}}\n",
      "2022-10-18 12:13:36,520 (client:259)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_imp_ratio': -8.735719, 'train_avg_loss': 0.630062, 'train_total': 1810, 'train_loss': 1140.41178}}\n",
      "2022-10-18 12:13:36,523 (server:491)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_imp_ratio': -62.348532, 'test_avg_loss': 1.013385, 'test_total': 335.625, 'test_loss': 346.982601, 'val_imp_ratio': -13.883661, 'val_avg_loss': 0.550977, 'val_total': 335.25, 'val_loss': 168.681412}}\n",
      "2022-10-18 12:13:36,524 (monitor:512)INFO: current_best=-30.935827, should_save=False\n",
      "2022-10-18 12:13:36,525 (monitor:512)INFO: current_best=-13.883661, should_save=True\n",
      "2022-10-18 12:13:36,553 (server:318)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-10-18 12:13:36,556 (server:325)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-10-18 12:13:45,539 (client:414)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_imp_ratio': -39.999983, 'test_avg_loss': 1.029458, 'test_total': 417, 'test_loss': 429.283906, 'val_imp_ratio': 39.855776, 'val_avg_loss': 0.352248, 'val_total': 416, 'val_loss': 146.535072}}\n",
      "2022-10-18 12:13:45,542 (monitor:512)INFO: current_best=39.855776, should_save=True\n",
      "2022-10-18 12:13:46,917 (client:414)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'test_imp_ratio': 100.0, 'test_avg_loss': 0.475713, 'test_total': 61, 'test_loss': 29.018476, 'val_imp_ratio': -43.868166, 'val_avg_loss': 0.70081, 'val_total': 60, 'val_loss': 42.048583}}\n",
      "2022-10-18 12:13:46,918 (monitor:512)INFO: current_best=-43.868166, should_save=True\n",
      "2022-10-18 12:14:00,759 (client:414)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'test_imp_ratio': 3.801901, 'test_avg_loss': 0.71382, 'test_total': 740, 'test_loss': 528.227065, 'val_imp_ratio': 31.558665, 'val_avg_loss': 0.535759, 'val_total': 740, 'val_loss': 396.461687}}\n",
      "2022-10-18 12:14:00,760 (monitor:512)INFO: current_best=31.558665, should_save=True\n",
      "2022-10-18 12:14:01,528 (client:414)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'test_imp_ratio': -133.332789, 'test_avg_loss': 0.633852, 'test_total': 34, 'test_loss': 21.550952, 'val_imp_ratio': -149.999417, 'val_avg_loss': 0.671971, 'val_total': 34, 'val_loss': 22.847005}}\n",
      "2022-10-18 12:14:01,529 (monitor:512)INFO: current_best=-149.999417, should_save=True\n",
      "2022-10-18 12:14:02,820 (client:414)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'test_imp_ratio': 91.999992, 'test_avg_loss': 0.490146, 'test_total': 63, 'test_loss': 30.879176, 'val_imp_ratio': -8.000108, 'val_avg_loss': 0.653441, 'val_total': 63, 'val_loss': 41.166791}}\n",
      "2022-10-18 12:14:02,821 (monitor:512)INFO: current_best=-4.000104, should_save=False\n",
      "2022-10-18 12:14:10,238 (client:414)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'test_imp_ratio': -228.125479, 'test_avg_loss': 1.462214, 'test_total': 367, 'test_loss': 536.632463, 'val_imp_ratio': 45.833254, 'val_avg_loss': 0.437245, 'val_total': 367, 'val_loss': 160.46899}}\n",
      "2022-10-18 12:14:10,240 (monitor:512)INFO: current_best=45.833254, should_save=True\n",
      "2022-10-18 12:14:25,066 (client:414)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'test_imp_ratio': -31.305528, 'test_avg_loss': 0.852488, 'test_total': 743, 'test_loss': 633.39895, 'val_imp_ratio': 29.673649, 'val_avg_loss': 0.483195, 'val_total': 743, 'val_loss': 359.014231}}\n",
      "2022-10-18 12:14:25,067 (monitor:512)INFO: current_best=29.673649, should_save=True\n",
      "2022-10-18 12:14:30,190 (client:414)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'test_imp_ratio': -323.637288, 'test_avg_loss': 2.888301, 'test_total': 260, 'test_loss': 750.958269, 'val_imp_ratio': 47.069032, 'val_avg_loss': 0.413488, 'val_total': 259, 'val_loss': 107.093402}}\n",
      "2022-10-18 12:14:30,191 (monitor:512)INFO: current_best=52.544649, should_save=False\n",
      "2022-10-18 12:14:47,810 (client:259)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'train_imp_ratio': 37.170436, 'train_avg_loss': 0.480757, 'train_total': 22190, 'train_loss': 10668.00723}}\n",
      "2022-10-18 12:14:57,012 (client:259)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'train_imp_ratio': 37.847132, 'train_avg_loss': 0.414523, 'train_total': 11010, 'train_loss': 4563.897205}}\n",
      "2022-10-18 12:15:15,256 (client:259)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'train_imp_ratio': 48.448726, 'train_avg_loss': 0.373632, 'train_total': 22280, 'train_loss': 8324.521297}}\n",
      "2022-10-18 12:15:21,318 (client:259)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_imp_ratio': 56.560102, 'train_avg_loss': 0.247846, 'train_total': 7770, 'train_loss': 1925.766638}}\n",
      "2022-10-18 12:15:22,211 (client:259)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'train_imp_ratio': 41.089246, 'train_avg_loss': 0.334113, 'train_total': 1010, 'train_loss': 337.45459}}\n",
      "2022-10-18 12:15:23,746 (client:259)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'train_imp_ratio': 23.729711, 'train_avg_loss': 0.59343, 'train_total': 1880, 'train_loss': 1115.648965}}\n",
      "2022-10-18 12:15:25,130 (client:259)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_imp_ratio': -4.348137, 'train_avg_loss': 0.61565, 'train_total': 1810, 'train_loss': 1114.327034}}\n",
      "2022-10-18 12:15:35,843 (client:259)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_imp_ratio': 56.840095, 'train_avg_loss': 0.299607, 'train_total': 12490, 'train_loss': 3742.085656}}\n",
      "2022-10-18 12:15:35,846 (server:491)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_imp_ratio': -70.074897, 'test_avg_loss': 1.068249, 'test_total': 335.625, 'test_loss': 369.993657, 'val_imp_ratio': -0.984664, 'val_avg_loss': 0.53102, 'val_total': 335.25, 'val_loss': 159.45447}}\n",
      "2022-10-18 12:15:35,847 (monitor:512)INFO: current_best=-13.883661, should_save=False\n",
      "2022-10-18 12:15:35,849 (monitor:512)INFO: current_best=-0.984664, should_save=True\n",
      "2022-10-18 12:15:35,882 (server:318)INFO: Server #0: Starting evaluation at the end of round 3.\n",
      "2022-10-18 12:15:35,886 (server:325)INFO: ----------- Starting a new training round (Round #4) -------------\n",
      "2022-10-18 12:15:45,914 (client:414)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'test_imp_ratio': -54.545436, 'test_avg_loss': 1.315689, 'test_total': 417, 'test_loss': 548.642476, 'val_imp_ratio': 63.548955, 'val_avg_loss': 0.305793, 'val_total': 416, 'val_loss': 127.210081}}\n",
      "2022-10-18 12:15:45,917 (monitor:512)INFO: current_best=63.548955, should_save=True\n",
      "2022-10-18 12:15:47,572 (client:414)INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'test_imp_ratio': 100.0, 'test_avg_loss': 0.461795, 'test_total': 61, 'test_loss': 28.169472, 'val_imp_ratio': -43.868166, 'val_avg_loss': 0.700411, 'val_total': 60, 'val_loss': 42.024658}}\n",
      "2022-10-18 12:15:47,573 (monitor:512)INFO: current_best=-43.868166, should_save=True\n",
      "2022-10-18 12:16:05,385 (client:414)INFO: {'Role': 'Client #3', 'Round': 4, 'Results_raw': {'test_imp_ratio': -2.662003, 'test_avg_loss': 0.732808, 'test_total': 740, 'test_loss': 542.277958, 'val_imp_ratio': 35.360961, 'val_avg_loss': 0.522058, 'val_total': 740, 'val_loss': 386.322834}}\n",
      "2022-10-18 12:16:05,386 (monitor:512)INFO: current_best=35.360961, should_save=True\n",
      "2022-10-18 12:16:06,453 (client:414)INFO: {'Role': 'Client #4', 'Round': 4, 'Results_raw': {'test_imp_ratio': -133.332789, 'test_avg_loss': 0.761831, 'test_total': 34, 'test_loss': 25.902241, 'val_imp_ratio': -99.999533, 'val_avg_loss': 0.605941, 'val_total': 34, 'val_loss': 20.602008}}\n",
      "2022-10-18 12:16:06,454 (monitor:512)INFO: current_best=-99.999533, should_save=True\n",
      "2022-10-18 12:16:07,997 (client:414)INFO: {'Role': 'Client #5', 'Round': 4, 'Results_raw': {'test_imp_ratio': 95.999996, 'test_avg_loss': 0.475094, 'test_total': 63, 'test_loss': 29.930905, 'val_imp_ratio': -12.000112, 'val_avg_loss': 0.657949, 'val_total': 63, 'val_loss': 41.450774}}\n",
      "2022-10-18 12:16:07,998 (monitor:512)INFO: current_best=-4.000104, should_save=False\n",
      "2022-10-18 12:16:16,981 (client:414)INFO: {'Role': 'Client #6', 'Round': 4, 'Results_raw': {'test_imp_ratio': -222.917138, 'test_avg_loss': 1.517182, 'test_total': 367, 'test_loss': 556.805662, 'val_imp_ratio': 43.749918, 'val_avg_loss': 0.427414, 'val_total': 367, 'val_loss': 156.86087}}\n",
      "2022-10-18 12:16:16,983 (monitor:512)INFO: current_best=45.833254, should_save=False\n",
      "2022-10-18 12:16:31,852 (client:414)INFO: {'Role': 'Client #7', 'Round': 4, 'Results_raw': {'test_imp_ratio': -39.317391, 'test_avg_loss': 0.884055, 'test_total': 743, 'test_loss': 656.853088, 'val_imp_ratio': 32.34427, 'val_avg_loss': 0.468574, 'val_total': 743, 'val_loss': 348.150651}}\n",
      "2022-10-18 12:16:31,853 (monitor:512)INFO: current_best=32.34427, should_save=True\n",
      "2022-10-18 12:16:36,586 (client:414)INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'test_imp_ratio': -334.546403, 'test_avg_loss': 3.515045, 'test_total': 260, 'test_loss': 913.911816, 'val_imp_ratio': 59.845472, 'val_avg_loss': 0.380913, 'val_total': 259, 'val_loss': 98.656424}}\n",
      "2022-10-18 12:16:36,587 (monitor:512)INFO: current_best=59.845472, should_save=True\n",
      "2022-10-18 12:16:37,860 (client:259)INFO: {'Role': 'Client #5', 'Round': 4, 'Results_raw': {'train_imp_ratio': 27.348864, 'train_avg_loss': 0.577727, 'train_total': 1880, 'train_loss': 1086.127604}}\n",
      "2022-10-18 12:16:46,074 (client:259)INFO: {'Role': 'Client #6', 'Round': 4, 'Results_raw': {'train_imp_ratio': 38.749911, 'train_avg_loss': 0.401808, 'train_total': 11010, 'train_loss': 4423.908774}}\n",
      "2022-10-18 12:16:47,297 (client:259)INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_imp_ratio': -3.58508, 'train_avg_loss': 0.606423, 'train_total': 1810, 'train_loss': 1097.625272}}\n",
      "2022-10-18 12:17:03,621 (client:259)INFO: {'Role': 'Client #7', 'Round': 4, 'Results_raw': {'train_imp_ratio': 53.183784, 'train_avg_loss': 0.346822, 'train_total': 22280, 'train_loss': 7727.201198}}\n",
      "2022-10-18 12:17:04,384 (client:259)INFO: {'Role': 'Client #4', 'Round': 4, 'Results_raw': {'train_imp_ratio': 48.382959, 'train_avg_loss': 0.313062, 'train_total': 1010, 'train_loss': 316.19295}}\n",
      "2022-10-18 12:17:20,598 (client:259)INFO: {'Role': 'Client #3', 'Round': 4, 'Results_raw': {'train_imp_ratio': 39.313362, 'train_avg_loss': 0.466407, 'train_total': 22190, 'train_loss': 10349.574412}}\n",
      "2022-10-18 12:17:30,190 (client:259)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_imp_ratio': 63.608491, 'train_avg_loss': 0.259128, 'train_total': 12490, 'train_loss': 3236.510207}}\n",
      "2022-10-18 12:17:35,320 (client:259)INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_imp_ratio': 61.244797, 'train_avg_loss': 0.217979, 'train_total': 7770, 'train_loss': 1693.6988}}\n",
      "2022-10-18 12:17:35,324 (server:491)INFO: {'Role': 'Server #', 'Round': 4, 'Results_avg': {'test_imp_ratio': -73.915145, 'test_avg_loss': 1.207937, 'test_total': 335.625, 'test_loss': 412.811702, 'val_imp_ratio': 9.872721, 'val_avg_loss': 0.508632, 'val_total': 335.25, 'val_loss': 152.659787}}\n",
      "2022-10-18 12:17:35,325 (monitor:512)INFO: current_best=-0.984664, should_save=False\n",
      "2022-10-18 12:17:35,326 (monitor:512)INFO: current_best=9.872721, should_save=True\n",
      "2022-10-18 12:17:35,355 (server:318)INFO: Server #0: Starting evaluation at the end of round 4.\n",
      "2022-10-18 12:17:35,358 (server:325)INFO: ----------- Starting a new training round (Round #5) -------------\n",
      "2022-10-18 12:17:44,779 (client:414)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'test_imp_ratio': -46.363619, 'test_avg_loss': 1.104524, 'test_total': 417, 'test_loss': 460.586324, 'val_imp_ratio': 69.016612, 'val_avg_loss': 0.261256, 'val_total': 416, 'val_loss': 108.682623}}\n",
      "2022-10-18 12:17:44,780 (monitor:512)INFO: current_best=69.016612, should_save=True\n",
      "2022-10-18 12:17:46,201 (client:414)INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'test_imp_ratio': 100.0, 'test_avg_loss': 0.439501, 'test_total': 61, 'test_loss': 26.80956, 'val_imp_ratio': -43.868166, 'val_avg_loss': 0.701521, 'val_total': 60, 'val_loss': 42.091269}}\n",
      "2022-10-18 12:17:46,202 (monitor:512)INFO: current_best=-43.868166, should_save=True\n",
      "2022-10-18 12:18:01,288 (client:414)INFO: {'Role': 'Client #3', 'Round': 5, 'Results_raw': {'test_imp_ratio': -5.70384, 'test_avg_loss': 0.755526, 'test_total': 740, 'test_loss': 559.089251, 'val_imp_ratio': 36.50165, 'val_avg_loss': 0.510733, 'val_total': 740, 'val_loss': 377.942217}}\n",
      "2022-10-18 12:18:01,289 (monitor:512)INFO: current_best=36.50165, should_save=True\n",
      "2022-10-18 12:18:02,144 (client:414)INFO: {'Role': 'Client #4', 'Round': 5, 'Results_raw': {'test_imp_ratio': -149.999417, 'test_avg_loss': 0.873006, 'test_total': 34, 'test_loss': 29.682191, 'val_imp_ratio': -99.999533, 'val_avg_loss': 0.560561, 'val_total': 34, 'val_loss': 19.059084}}\n",
      "2022-10-18 12:18:02,145 (monitor:512)INFO: current_best=-99.999533, should_save=True\n",
      "2022-10-18 12:18:03,545 (client:414)INFO: {'Role': 'Client #5', 'Round': 5, 'Results_raw': {'test_imp_ratio': 95.999996, 'test_avg_loss': 0.462867, 'test_total': 63, 'test_loss': 29.160649, 'val_imp_ratio': -12.000112, 'val_avg_loss': 0.659525, 'val_total': 63, 'val_loss': 41.550096}}\n",
      "2022-10-18 12:18:03,546 (monitor:512)INFO: current_best=-4.000104, should_save=False\n",
      "2022-10-18 12:18:11,478 (client:414)INFO: {'Role': 'Client #6', 'Round': 5, 'Results_raw': {'test_imp_ratio': -221.875469, 'test_avg_loss': 1.552941, 'test_total': 367, 'test_loss': 569.929176, 'val_imp_ratio': 43.749918, 'val_avg_loss': 0.419525, 'val_total': 367, 'val_loss': 153.965846}}\n",
      "2022-10-18 12:18:11,480 (monitor:512)INFO: current_best=45.833254, should_save=False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 54\u001B[0m\n\u001B[1;32m     47\u001B[0m init_cfg\u001B[38;5;241m.\u001B[39mfreeze()\n\u001B[1;32m     49\u001B[0m runner \u001B[38;5;241m=\u001B[39m FedRunner(data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m     50\u001B[0m                    server_class\u001B[38;5;241m=\u001B[39mget_server_cls(init_cfg),\n\u001B[1;32m     51\u001B[0m                    client_class\u001B[38;5;241m=\u001B[39mget_client_cls(init_cfg),\n\u001B[1;32m     52\u001B[0m                    config\u001B[38;5;241m=\u001B[39minit_cfg\u001B[38;5;241m.\u001B[39mclone(),\n\u001B[1;32m     53\u001B[0m                    client_config\u001B[38;5;241m=\u001B[39mclient_cfg)\n\u001B[0;32m---> 54\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/fed_runner.py:186\u001B[0m, in \u001B[0;36mFedRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    185\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mfinish_fed_runner(fl_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mbest_results\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/fed_runner.py:325\u001B[0m, in \u001B[0;36mFedRunner._handle_msg\u001B[0;34m(self, msg, rcv)\u001B[0m\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(download_bytes)\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 325\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m[\u001B[49m\u001B[43meach_receiver\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_handlers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[each_receiver]\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(\n\u001B[1;32m    327\u001B[0m         download_bytes)\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/worker/client.py:393\u001B[0m, in \u001B[0;36mClient.callback_funcs_for_evaluate\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m    391\u001B[0m metrics \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfinetune\u001B[38;5;241m.\u001B[39mbefore_eval:\n\u001B[0;32m--> 393\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinetune\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39meval\u001B[38;5;241m.\u001B[39msplit:\n\u001B[1;32m    395\u001B[0m     eval_metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mevaluate(\n\u001B[1;32m    396\u001B[0m         target_data_split_name\u001B[38;5;241m=\u001B[39msplit)\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/trainers/trainer.py:239\u001B[0m, in \u001B[0;36mTrainer.finetune\u001B[0;34m(self, target_data_split_name, hooks_set)\u001B[0m\n\u001B[1;32m    235\u001B[0m hooks_set \u001B[38;5;241m=\u001B[39m hooks_set \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks_in_ft\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcheck_data_split(target_data_split_name)\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_routine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFINETUNE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_data_split_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_routine(MODE\u001B[38;5;241m.\u001B[39mFINETUNE, hooks_set, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/core/trainers/trainer.py:279\u001B[0m, in \u001B[0;36mTrainer._run_routine\u001B[0;34m(self, mode, hooks_set, dataset_name)\u001B[0m\n\u001B[1;32m    277\u001B[0m     hook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 279\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcur_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/gfl/trainer/graphtrainer.py:21\u001B[0m, in \u001B[0;36mGraphMiniBatchTrainer._hook_on_batch_forward\u001B[0;34m(self, ctx)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_hook_on_batch_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, ctx):\n\u001B[1;32m     20\u001B[0m     batch \u001B[38;5;241m=\u001B[39m ctx\u001B[38;5;241m.\u001B[39mdata_batch\u001B[38;5;241m.\u001B[39mto(ctx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 21\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# TODO: deal with the type of data within the dataloader or dataset\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ctx\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtask\u001B[38;5;241m.\u001B[39mlower():\n",
      "File \u001B[0;32m~/anaconda3/envs/FederatedScope/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/CKIM_Competition/federatedscope/gfl/model/graph_level.py:126\u001B[0m, in \u001B[0;36mGNN_Net_Graph.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    124\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memb(edge_attr)\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    125\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgnn(x, edge_index, edge_attr)\n\u001B[0;32m--> 126\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpooling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(x)\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/FederatedScope/lib/python3.9/site-packages/torch_geometric/nn/glob/glob.py:27\u001B[0m, in \u001B[0;36mglobal_add_pool\u001B[0;34m(x, batch, size)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 27\u001B[0m size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m size\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scatter(x, batch, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, dim_size\u001B[38;5;241m=\u001B[39msize, reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# with 8 clients\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "DEV_MODE = False  # simplify the federatedscope re-setup everytime we change\n",
    "# the source codes of federatedscope\n",
    "if DEV_MODE:\n",
    "    file_dir = os.path.join(os.path.dirname(__file__), '..')\n",
    "    sys.path.append(file_dir)\n",
    "\n",
    "from federatedscope.core.cmd_args import parse_args\n",
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_client_cls, \\\n",
    "    get_server_cls\n",
    "from federatedscope.core.configs.config import global_cfg\n",
    "from federatedscope.core.fed_runner import FedRunner\n",
    "\n",
    "if os.environ.get('https_proxy'):\n",
    "    del os.environ['https_proxy']\n",
    "if os.environ.get('http_proxy'):\n",
    "    del os.environ['http_proxy']\n",
    "\n",
    "cfg = 'federatedscope/gfl/baseline/laplacian_gine_on_cikmcup.yaml'\n",
    "cfg_client = 'federatedscope/gfl/baseline/laplacian_gine_on_cikmcup_per_client.yaml'\n",
    "\n",
    "init_cfg = global_cfg.clone()\n",
    "#args = parse_args()\n",
    "init_cfg.merge_from_file(cfg)\n",
    "#init_cfg.merge_from_list(args.opts)\n",
    "\n",
    "update_logger(init_cfg)\n",
    "setup_seed(init_cfg.seed)\n",
    "\n",
    "# load clients' cfg file\n",
    "client_cfg = CfgNode.load_cfg(open(cfg_client,\n",
    "                                   'r')) if cfg_client else None\n",
    "\n",
    "# federated dataset might change the number of clients\n",
    "# thus, we allow the creation procedure of dataset to modify the global\n",
    "# cfg object\n",
    "data, modified_cfg = get_data(config=init_cfg.clone())\n",
    "init_cfg.merge_from_other_cfg(modified_cfg)\n",
    "\n",
    "init_cfg.freeze()\n",
    "\n",
    "runner = FedRunner(data=data,\n",
    "                   server_class=get_server_cls(init_cfg),\n",
    "                   client_class=get_client_cls(init_cfg),\n",
    "                   config=init_cfg.clone(),\n",
    "                   client_config=client_cfg)\n",
    "_ = runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
