{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from federatedscope.register import register_data\n",
    "from federatedscope.register import register_trainer\n",
    "from federatedscope.register import register_metric\n",
    "from federatedscope.register import register_model\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from federatedscope.contrib.data.cikm_cup import call_cikm_cup_data\n",
    "\n",
    "register_data(\"cikm_cup\", call_cikm_cup_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#from federatedscope.contrib.model.mnist_model import call_my_net\n",
    "#register_model(\"mynet\", call_my_net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n",
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/logger.py:23: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI import call_laplacian_trainer\n",
    "\n",
    "register_trainer('laplacian_trainer', call_laplacian_trainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set data, model, trainer and metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from federatedscope.core.configs.config import global_cfg, CN\n",
    "cfg = global_cfg.clone()\n",
    "\n",
    "cfg.merge_from_file(\"federatedscope/gfl/baseline/laplacian_gine_on_cikmcup.yaml\")\n",
    "#cfg.data.type = 'cikm_cup'\n",
    "#cfg.data.root = 'data'\n",
    "#cfg.data.shuffle=True\n",
    "#cfg.data.transform = [['ToTensor'], ['Normalize', {'mean': [0.], 'std': [1]}]]\n",
    "#cfg.model.type = 'gin'\n",
    "#cfg.model.out_channels = 10\n",
    "#cfg.model.hidden = 64\n",
    "#cfg.model.task='graph'\n",
    "#cfg.model.dropout = 0.5\n",
    "#cfg.personalization.local_param = ['encoder_atom', 'encoder', 'clf']#['node_encoder', 'clf']\n",
    "#cfg.train.batch_or_epoch = \"epoch\"\n",
    "cfg.trainer.type = 'laplacian_trainer_with_domain_separation'\n",
    "cfg.data.batch_size = 64\n",
    "# cfg.eval.metric = ['mymetric']\n",
    "cfg.params = CN()\n",
    "cfg.params.alpha=0.1\n",
    "cfg.params.csd_importance= 1e2\n",
    "cfg.params.eps=1e-20\n",
    "cfg.params.p=0.\n",
    "cfg.params.diff_importance = 1\n",
    "cfg.params.mine_lr = 0.01  # MINE lr\n",
    "cfg.params.lam = 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### configure other options"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#cfg.use_gpu = True\n",
    "#cfg.best_res_update_round_wise_key = \"test_loss\"\n",
    "\n",
    "#cfg.federate.mode = 'standalone'\n",
    "\n",
    "cfg.federate.method = \\\n",
    "    f'Laplacian_domain_sep_sum_MI_csd{cfg.params.csd_importance}_lam{cfg.params.lam}_diff{cfg.params.diff_importance}_MI_lr_{cfg.params.mine_lr}_no_finetune'\n",
    "\n",
    "#cfg.federate.local_update_steps = 20000000\n",
    "#cfg.personalization.local_update_steps = 20000000\n",
    "#cfg.finetune.local_update_steps = 20000000\n",
    "#cfg.train.local_update_steps = 1\n",
    "\n",
    "cfg.federate.total_round_num = 2000\n",
    "\n",
    "cfg.federate.client_num = 13\n",
    "cfg.early_stop.patience = 10000\n",
    "#cfg.train.optimizer.lr = 0.001\n",
    "#cfg.train.optimizer.weight_decay = 0.0005\n",
    "#cfg.grad.grad_clip = 2.0\n",
    "cfg.criterion.type = 'CrossEntropyLoss'\n",
    "#cfg.seed = 123\n",
    "cfg.eval.freq = 1\n",
    "cfg.eval.metrics = ['imp_ratio']\n",
    "cfg.eval.report = ['avg']\n",
    "cfg.eval.best_res_update_round_wise_key = 'val_imp_ratio'\n",
    "cfg.eval.count_flops = False\n",
    "cfg.data.type = \"cikm_cup\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.manual_seed(0)\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.use_deterministic_algorithms(F/home/michael/Desktop/backup files/FederatedScope/data/CIKM22Competitionalse)\n",
    "#import random\n",
    "#random.seed(0)\n",
    "#import numpy as np\n",
    "#np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from yacs.config import CfgNode\n",
    "client_cfg_file = \"federatedscope/gfl/baseline/laplacian_gine_on_cikmcup_per_client.yaml\"\n",
    "client_cfg = CfgNode.load_cfg(open(client_cfg_file,\n",
    "                                       'r')) if client_cfg_file else None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start the FL prosess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:18:23,003 (trainer_builder:11)WARNING: No module named 'federatedscope.contrib.optimizer' in `federatedscope.contrib.trainer`, some modules are not available.\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "from federatedscope.core.fed_runner import FedRunner\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:18:23,245 (utils:129)INFO: the current machine is at 127.0.1.1\n",
      "2022-12-12 11:18:23,245 (utils:131)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2022-12-12 11:18:23,246 (utils:132)INFO: the output dir is exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "2022-12-12 11:18:23,246 (cikm_cup:58)INFO: Loading CIKMCUP data from /home/michael/Master-Thesis/CKIM_Competition/data/CIKM22Competition.\n",
      "2022-12-12 11:18:23,247 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #1.\n",
      "2022-12-12 11:18:23,502 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #2.\n",
      "2022-12-12 11:18:23,522 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #3.\n",
      "2022-12-12 11:18:23,795 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #4.\n",
      "2022-12-12 11:18:23,806 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #5.\n",
      "2022-12-12 11:18:23,826 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #6.\n",
      "2022-12-12 11:18:24,070 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #7.\n",
      "2022-12-12 11:18:24,376 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #8.\n",
      "2022-12-12 11:18:24,468 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #9.\n",
      "2022-12-12 11:18:48,269 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #10.\n",
      "2022-12-12 11:19:12,026 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #11.\n",
      "2022-12-12 11:19:12,271 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #12.\n",
      "2022-12-12 11:19:12,334 (cikm_cup:68)INFO: Loading CIKMCUP data for Client #13.\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.contrib.workers.laplacian_with_domain_separation_MI_client import LaplacianDomainSeparationMIClient\n",
    "from federatedscope.contrib.workers.laplacian_server_dom_sep import LaplacianServerDomSep\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "update_logger(cfg)\n",
    "data, modified_cfg = get_data(cfg)\n",
    "cfg.merge_from_other_cfg(modified_cfg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "server params: \n",
      "encoder_atom.atom_embedding_list.0.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:19:32,355 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-12-12 11:19:32,365 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.263789\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['acc', 'imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,430 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,431 (fed_runner:302)INFO: Client 1 has been set up ... \n",
      "2022-12-12 11:19:32,442 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.289617\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,503 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,503 (fed_runner:302)INFO: Client 2 has been set up ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_atom.atom_embedding_list.1.weight\n",
      "encoder_atom.atom_embedding_list.2.weight\n",
      "encoder_atom.atom_embedding_list.3.weight\n",
      "encoder_atom.atom_embedding_list.4.weight\n",
      "encoder_atom.atom_embedding_list.5.weight\n",
      "encoder_atom.atom_embedding_list.6.weight\n",
      "encoder_atom.atom_embedding_list.7.weight\n",
      "encoder_atom.atom_embedding_list.8.weight\n",
      "encoder_atom.atom_embedding_list.9.weight\n",
      "encoder_atom.atom_embedding_list.10.weight\n",
      "encoder_atom.atom_embedding_list.11.weight\n",
      "encoder_atom.atom_embedding_list.12.weight\n",
      "encoder_atom.atom_embedding_list.13.weight\n",
      "encoder_atom.atom_embedding_list.14.weight\n",
      "encoder_atom.atom_embedding_list.15.weight\n",
      "encoder_atom.atom_embedding_list.16.weight\n",
      "encoder_atom.atom_embedding_list.17.weight\n",
      "encoder_atom.atom_embedding_list.18.weight\n",
      "encoder_atom.atom_embedding_list.19.weight\n",
      "encoder_atom.atom_embedding_list.20.weight\n",
      "encoder_atom.atom_embedding_list.21.weight\n",
      "encoder.weight\n",
      "encoder.bias\n",
      "local_gnn.convs.0.nn.linears.0.weight\n",
      "local_gnn.convs.0.nn.linears.0.bias\n",
      "local_gnn.convs.0.nn.linears.1.weight\n",
      "local_gnn.convs.0.nn.linears.1.bias\n",
      "local_gnn.convs.0.nn.norms.0.weight\n",
      "local_gnn.convs.0.nn.norms.0.bias\n",
      "local_gnn.convs.0.nn.norms.1.weight\n",
      "local_gnn.convs.0.nn.norms.1.bias\n",
      "local_gnn.convs.1.nn.linears.0.weight\n",
      "local_gnn.convs.1.nn.linears.0.bias\n",
      "local_gnn.convs.1.nn.linears.1.weight\n",
      "local_gnn.convs.1.nn.linears.1.bias\n",
      "local_gnn.convs.1.nn.norms.0.weight\n",
      "local_gnn.convs.1.nn.norms.0.bias\n",
      "local_gnn.convs.1.nn.norms.1.weight\n",
      "local_gnn.convs.1.nn.norms.1.bias\n",
      "global_gnn.convs.0.nn.linears.0.weight\n",
      "global_gnn.convs.0.nn.linears.0.bias\n",
      "global_gnn.convs.0.nn.linears.1.weight\n",
      "global_gnn.convs.0.nn.linears.1.bias\n",
      "global_gnn.convs.0.nn.norms.0.weight\n",
      "global_gnn.convs.0.nn.norms.0.bias\n",
      "global_gnn.convs.0.nn.norms.1.weight\n",
      "global_gnn.convs.0.nn.norms.1.bias\n",
      "global_gnn.convs.1.nn.linears.0.weight\n",
      "global_gnn.convs.1.nn.linears.0.bias\n",
      "global_gnn.convs.1.nn.linears.1.weight\n",
      "global_gnn.convs.1.nn.linears.1.bias\n",
      "global_gnn.convs.1.nn.norms.0.weight\n",
      "global_gnn.convs.1.nn.norms.0.bias\n",
      "global_gnn.convs.1.nn.norms.1.weight\n",
      "global_gnn.convs.1.nn.norms.1.bias\n",
      "mine.T.1.weight\n",
      "mine.T.1.bias\n",
      "mine.T.3.weight\n",
      "mine.T.3.bias\n",
      "mine.T.5.weight\n",
      "mine.T.5.bias\n",
      "bn_edge.weight\n",
      "bn_edge.bias\n",
      "bn_node.weight\n",
      "bn_node.bias\n",
      "global_linear_out1.weight\n",
      "global_linear_out1.bias\n",
      "bn_linear0_glob.weight\n",
      "bn_linear0_glob.bias\n",
      "bn_linear1_glob.weight\n",
      "bn_linear1_glob.bias\n",
      "local_linear_out1.weight\n",
      "local_linear_out1.bias\n",
      "bn_linear0_loc.weight\n",
      "bn_linear0_loc.bias\n",
      "bn_linear1_loc.weight\n",
      "bn_linear1_loc.bias\n",
      "bn_after_summation.weight\n",
      "bn_after_summation.bias\n",
      "linear_out2.0.weight\n",
      "linear_out2.0.bias\n",
      "bn_linear2.weight\n",
      "bn_linear2.bias\n",
      "clf.weight\n",
      "clf.bias\n",
      "emb.weight\n",
      "emb.bias\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:19:32,518 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.355404\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,596 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,597 (fed_runner:302)INFO: Client 3 has been set up ... \n",
      "2022-12-12 11:19:32,607 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.176471\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,653 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,654 (fed_runner:302)INFO: Client 4 has been set up ... \n",
      "2022-12-12 11:19:32,664 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.396825\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,723 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:19:32,724 (fed_runner:302)INFO: Client 5 has been set up ... \n",
      "2022-12-12 11:19:32,734 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.26158\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.0005\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,798 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,799 (fed_runner:302)INFO: Client 6 has been set up ... \n",
      "2022-12-12 11:19:32,809 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.302378\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:32,892 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,893 (fed_runner:302)INFO: Client 7 has been set up ... \n",
      "2022-12-12 11:19:32,904 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.211538\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'accuracy']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:19:32,963 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:32,964 (fed_runner:302)INFO: Client 8 has been set up ... \n",
      "2022-12-12 11:19:32,975 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.059199\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:33,047 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:33,048 (fed_runner:302)INFO: Client 9 has been set up ... \n",
      "2022-12-12 11:19:33,058 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.007083\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 10\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:33,105 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:33,107 (fed_runner:302)INFO: Client 10 has been set up ... \n",
      "2022-12-12 11:19:33,116 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.734011\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:33,179 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:33,180 (fed_runner:302)INFO: Client 11 has been set up ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:19:33,190 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 1.361326\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 10\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:33,259 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:33,260 (fed_runner:302)INFO: Client 12 has been set up ... \n",
      "2022-12-12 11:19:33,271 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 13\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: cikm_cup\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: mean\n",
      "  patience: 10000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.004389\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 13\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 13\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 5000\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 2.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.0\n",
      "  embed_size: 8\n",
      "  graph_pooling: add\n",
      "  hidden: 512\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 12\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  lam: 1\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'bn_linear', 'local_gnn', 'emb', 'bn_dec', 'norms', 'norm', 'bn', 'linear_out1_loc', 'bn_linear2_loc', 'local', 'linear_out2', 'bn1', 'bn2', 'mine']\n",
      "  local_update_steps: 10\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0001\n",
      "trainer:\n",
      "  type: laplacian_trainer_with_domain_separation\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-12 11:19:33,330 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_MI.LaplacianDomainSeparationWithSummationMITrainer'>\n",
      "2022-12-12 11:19:33,331 (fed_runner:302)INFO: Client 13 has been set up ... \n",
      "2022-12-12 11:19:33,332 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-12-12 11:19:33,335 (trainer:332)INFO: Num of original para names: 146.\n",
      "2022-12-12 11:19:33,335 (trainer:333)INFO: Num of original trainable para names: 88.\n",
      "2022-12-12 11:19:33,336 (trainer:335)INFO: Num of preserved para names in local update: 12. \n",
      "Preserved para names in local update: {'global_gnn.convs.1.nn.linears.0.weight', 'global_gnn.convs.1.nn.linears.1.bias', 'global_linear_out1.weight', 'global_gnn.convs.0.nn.linears.0.weight', 'global_gnn.convs.0.nn.linears.1.bias', 'global_gnn.convs.0.nn.linears.1.weight', 'global_gnn.convs.1.nn.linears.1.weight', 'global_gnn.convs.0.eps', 'global_linear_out1.bias', 'global_gnn.convs.0.nn.linears.0.bias', 'global_gnn.convs.1.eps', 'global_gnn.convs.1.nn.linears.0.bias'}.\n",
      "2022-12-12 11:19:33,336 (trainer:339)INFO: Num of filtered para names in local update: 134. \n",
      "Filtered para names in local update: {'local_gnn.convs.1.nn.norms.0.num_batches_tracked', 'mine.T.3.bias', 'global_gnn.convs.1.nn.norms.0.num_batches_tracked', 'local_gnn.convs.1.nn.norms.1.running_var', 'local_gnn.convs.0.nn.linears.1.bias', 'mine.energy_loss.T.3.weight', 'bn_linear2.weight', 'local_gnn.convs.0.nn.norms.1.bias', 'encoder_atom.atom_embedding_list.21.weight', 'bn_linear0_loc.weight', 'bn_linear1_glob.running_var', 'bn_linear1_glob.bias', 'bn_linear1_glob.num_batches_tracked', 'local_gnn.convs.0.nn.norms.1.num_batches_tracked', 'global_gnn.convs.0.nn.norms.1.num_batches_tracked', 'emb.weight', 'bn_linear0_loc.running_mean', 'bn_linear0_loc.num_batches_tracked', 'bn_edge.weight', 'encoder.weight', 'local_gnn.convs.0.nn.norms.0.running_var', 'encoder_atom.atom_embedding_list.19.weight', 'bn_linear0_glob.running_var', 'bn_node.bias', 'bn_edge.num_batches_tracked', 'local_gnn.convs.0.nn.linears.0.bias', 'global_gnn.convs.1.nn.norms.1.running_mean', 'local_gnn.convs.1.nn.norms.0.weight', 'bn_node.running_var', 'mine.T.3.weight', 'bn_linear1_loc.running_mean', 'bn_edge.bias', 'global_gnn.convs.0.nn.norms.1.running_var', 'encoder_atom.atom_embedding_list.11.weight', 'encoder_atom.atom_embedding_list.17.weight', 'encoder_atom.atom_embedding_list.1.weight', 'bn_node.running_mean', 'bn_linear0_glob.num_batches_tracked', 'local_gnn.convs.0.nn.norms.1.running_mean', 'bn_after_summation.running_var', 'bn_linear2.running_mean', 'encoder_atom.atom_embedding_list.12.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.2.weight', 'local_gnn.convs.0.nn.norms.0.bias', 'local_gnn.convs.0.nn.norms.0.num_batches_tracked', 'global_gnn.convs.0.nn.norms.0.num_batches_tracked', 'bn_linear1_loc.weight', 'global_gnn.convs.0.nn.norms.1.weight', 'local_gnn.convs.0.nn.norms.1.running_var', 'bn_after_summation.weight', 'local_gnn.convs.0.nn.norms.0.running_mean', 'encoder_atom.atom_embedding_list.9.weight', 'mine.T.5.weight', 'local_gnn.convs.0.nn.norms.0.weight', 'encoder_atom.atom_embedding_list.4.weight', 'global_gnn.convs.1.nn.norms.0.running_var', 'clf.bias', 'bn_node.num_batches_tracked', 'mine.energy_loss.T.1.bias', 'mine.T.1.weight', 'bn_edge.running_var', 'bn_node.weight', 'global_gnn.convs.1.nn.norms.1.bias', 'encoder_atom.atom_embedding_list.15.weight', 'global_gnn.convs.1.nn.norms.1.weight', 'mine.energy_loss.T.5.bias', 'global_gnn.convs.0.nn.norms.0.bias', 'global_gnn.convs.1.nn.norms.0.bias', 'global_gnn.convs.1.nn.norms.0.running_mean', 'bn_linear0_glob.running_mean', 'encoder_atom.atom_embedding_list.13.weight', 'local_gnn.convs.1.nn.norms.1.num_batches_tracked', 'local_gnn.convs.1.nn.linears.1.bias', 'global_gnn.convs.1.nn.norms.1.num_batches_tracked', 'bn_linear1_loc.running_var', 'global_gnn.convs.0.nn.norms.0.running_mean', 'global_gnn.convs.0.nn.norms.0.weight', 'local_gnn.convs.0.nn.linears.1.weight', 'bn_linear0_glob.bias', 'bn_linear0_glob.weight', 'mine.energy_loss.T.3.bias', 'local_gnn.convs.1.nn.linears.0.bias', 'mine.T.1.bias', 'linear_out2.0.weight', 'local_gnn.convs.1.nn.norms.1.running_mean', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.10.weight', 'encoder_atom.atom_embedding_list.6.weight', 'local_gnn.convs.0.nn.linears.0.weight', 'local_gnn.convs.1.nn.norms.0.running_mean', 'local_gnn.convs.1.nn.norms.1.bias', 'local_linear_out1.weight', 'local_gnn.convs.0.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.18.weight', 'bn_linear2.num_batches_tracked', 'mine.energy_loss.T.1.weight', 'linear_out2.0.bias', 'local_linear_out1.bias', 'emb.bias', 'global_gnn.convs.0.nn.norms.0.running_var', 'local_gnn.convs.1.nn.linears.1.weight', 'bn_edge.running_mean', 'bn_linear0_loc.running_var', 'bn_after_summation.num_batches_tracked', 'global_gnn.convs.1.nn.norms.0.weight', 'bn_linear0_loc.bias', 'bn_linear1_glob.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.5.weight', 'global_gnn.convs.0.nn.norms.1.running_mean', 'local_gnn.convs.1.nn.linears.0.weight', 'encoder_atom.atom_embedding_list.3.weight', 'bn_linear2.bias', 'local_gnn.convs.0.eps', 'local_gnn.convs.1.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.16.weight', 'bn_linear2.running_var', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.20.weight', 'mine.T.5.bias', 'local_gnn.convs.1.eps', 'bn_linear1_loc.bias', 'bn_linear1_glob.running_mean', 'local_gnn.convs.1.nn.norms.0.running_var', 'global_gnn.convs.0.nn.norms.1.bias', 'local_gnn.convs.1.nn.norms.1.weight', 'bn_after_summation.bias', 'global_gnn.convs.1.nn.norms.1.running_var', 'encoder.bias', 'mine.energy_loss.T.5.weight', 'encoder_atom.atom_embedding_list.14.weight', 'bn_linear1_loc.num_batches_tracked', 'bn_after_summation.running_mean'}.\n",
      "2022-12-12 11:19:33,338 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-12-12 11:19:33,343 (server:628)INFO: ----------- Starting training (Round #0) -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:20:11,300 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_total': 22280, 'train_imp_ratio': 27.267134, 'train_loss': 10734.564341, 'train_avg_loss': 0.481803}}\n",
      "2022-12-12 11:20:20,484 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #12', 'Round': 0, 'Results_raw': {'train_loss': 52169.926514, 'train_total': 6080, 'train_imp_ratio': -530.31043, 'train_avg_loss': 8.58058}}\n",
      "2022-12-12 11:20:23,403 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_total': 1880, 'train_imp_ratio': -21.978845, 'train_loss': 1393.040247, 'train_avg_loss': 0.740979}}\n",
      "2022-12-12 11:21:01,677 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_loss': 25089.559699, 'train_total': 22680, 'train_imp_ratio': -50.71187, 'train_avg_loss': 1.106242}}\n",
      "2022-12-12 11:21:39,739 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_total': 22190, 'train_imp_ratio': 17.516385, 'train_loss': 12634.987882, 'train_avg_loss': 0.5694}}\n",
      "2022-12-12 11:25:13,942 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #9', 'Round': 0, 'Results_raw': {'train_loss': 7002.450434, 'train_total': 134706, 'train_imp_ratio': 12.189038, 'train_avg_loss': 0.051983}}\n",
      "2022-12-12 11:25:16,824 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_total': 1810, 'train_imp_ratio': -45.553252, 'train_loss': 1240.836903, 'train_avg_loss': 0.685545}}\n",
      "2022-12-12 11:25:28,892 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_total': 7770, 'train_imp_ratio': 24.314799, 'train_loss': 3143.417827, 'train_avg_loss': 0.404558}}\n",
      "2022-12-12 11:28:01,200 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #10', 'Round': 0, 'Results_raw': {'train_loss': 1624.841522, 'train_total': 109392, 'train_imp_ratio': -109.704641, 'train_avg_loss': 0.014853}}\n",
      "2022-12-12 11:28:03,137 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_total': 1010, 'train_imp_ratio': -175.477905, 'train_loss': 714.007474, 'train_avg_loss': 0.706938}}\n",
      "2022-12-12 11:28:24,136 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_total': 12490, 'train_imp_ratio': 51.316113, 'train_acc': 0.871577, 'train_loss': 3877.032022, 'train_avg_loss': 0.310411}}\n",
      "2022-12-12 11:28:42,858 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_total': 11010, 'train_imp_ratio': -34.444641, 'train_loss': 7020.202945, 'train_avg_loss': 0.637621}}\n",
      "2022-12-12 11:30:29,796 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #13', 'Round': 0, 'Results_raw': {'train_loss': 1585.480526, 'train_total': 70648, 'train_imp_ratio': -411.323042, 'train_avg_loss': 0.022442}}\n",
      "2022-12-12 11:30:29,885 (laplacian_server_dom_sep:168)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-12-12 11:30:29,888 (laplacian_server_dom_sep:175)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-12-12 11:30:30,171 (client:410)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_total': 417, 'test_imp_ratio': 100.0, 'test_acc': 1.0, 'test_loss': 13.021223, 'test_avg_loss': 0.031226, 'val_total': 416, 'val_imp_ratio': -45.804179, 'val_acc': 0.615385, 'val_loss': 828.455788, 'val_avg_loss': 1.99148}}\n",
      "2022-12-12 11:30:30,171 (monitor:512)INFO: current_best=-45.804179, should_save=True\n",
      "2022-12-12 11:30:30,172 (client:431)INFO: Client: #1, val_imp_ratio: -45.804179. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model1.pth\n",
      "2022-12-12 11:30:30,282 (client:410)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'test_total': 61, 'test_imp_ratio': 60.377292, 'test_loss': 33.853626, 'test_avg_loss': 0.554977, 'val_total': 60, 'val_imp_ratio': -26.603986, 'val_loss': 39.618777, 'val_avg_loss': 0.660313}}\n",
      "2022-12-12 11:30:30,283 (monitor:512)INFO: current_best=-26.603986, should_save=True\n",
      "2022-12-12 11:30:30,284 (client:431)INFO: Client: #2, val_imp_ratio: -26.603986. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model2.pth\n",
      "2022-12-12 11:30:30,740 (client:410)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'test_total': 740, 'test_imp_ratio': -38.023359, 'test_loss': 604.410008, 'test_avg_loss': 0.81677, 'val_total': 740, 'val_imp_ratio': 13.687872, 'val_loss': 463.031946, 'val_avg_loss': 0.625719}}\n",
      "2022-12-12 11:30:30,741 (monitor:512)INFO: current_best=13.687872, should_save=True\n",
      "2022-12-12 11:30:30,742 (client:431)INFO: Client: #3, val_imp_ratio: 13.687872. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model3.pth\n",
      "2022-12-12 11:30:30,841 (client:410)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'test_total': 34, 'test_imp_ratio': -183.332672, 'test_loss': 23.74735, 'test_avg_loss': 0.698451, 'val_total': 34, 'val_imp_ratio': -199.9993, 'val_loss': 25.08932, 'val_avg_loss': 0.737921}}\n",
      "2022-12-12 11:30:30,842 (monitor:512)INFO: current_best=-199.9993, should_save=True\n",
      "2022-12-12 11:30:30,842 (client:431)INFO: Client: #4, val_imp_ratio: -199.9993. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model4.pth\n",
      "2022-12-12 11:30:30,955 (client:410)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'test_total': 63, 'test_imp_ratio': -80.00018, 'test_loss': 51.539807, 'test_avg_loss': 0.818092, 'val_total': 63, 'val_imp_ratio': -16.000116, 'val_loss': 50.411728, 'val_avg_loss': 0.800186}}\n",
      "2022-12-12 11:30:30,956 (monitor:512)INFO: current_best=-16.000116, should_save=True\n",
      "2022-12-12 11:30:30,957 (client:431)INFO: Client: #5, val_imp_ratio: -16.000116. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model5.pth\n",
      "2022-12-12 11:30:31,217 (client:410)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'test_total': 367, 'test_imp_ratio': -122.916992, 'test_loss': 297.435596, 'test_avg_loss': 0.810451, 'val_total': 367, 'val_imp_ratio': -35.416864, 'val_loss': 233.077056, 'val_avg_loss': 0.635087}}\n",
      "2022-12-12 11:30:31,218 (monitor:512)INFO: current_best=-35.416864, should_save=True\n",
      "2022-12-12 11:30:31,219 (client:431)INFO: Client: #6, val_imp_ratio: -35.416864. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model6.pth\n",
      "2022-12-12 11:30:31,678 (client:410)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'test_total': 743, 'test_imp_ratio': 56.379858, 'test_loss': 276.895059, 'test_avg_loss': 0.372672, 'val_total': 743, 'val_imp_ratio': -26.40939, 'val_loss': 668.880427, 'val_avg_loss': 0.900243}}\n",
      "2022-12-12 11:30:31,679 (monitor:512)INFO: current_best=-26.40939, should_save=True\n",
      "2022-12-12 11:30:31,679 (client:431)INFO: Client: #7, val_imp_ratio: -26.40939. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model7.pth\n",
      "2022-12-12 11:30:31,883 (client:410)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'test_total': 260, 'test_imp_ratio': -309.091802, 'test_loss': 365.55851, 'test_avg_loss': 1.405994, 'val_total': 259, 'val_imp_ratio': 8.73971, 'val_loss': 139.078085, 'val_avg_loss': 0.536981}}\n",
      "2022-12-12 11:30:31,884 (monitor:512)INFO: current_best=8.73971, should_save=True\n",
      "2022-12-12 11:30:31,885 (client:431)INFO: Client: #8, val_imp_ratio: 8.73971. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model8.pth\n",
      "2022-12-12 11:30:52,460 (client:410)INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'test_loss': 37112.893754, 'test_total': 44902, 'test_imp_ratio': -1296.190802, 'test_avg_loss': 0.826531, 'val_loss': 27575.117694, 'val_total': 44902, 'val_imp_ratio': -937.378775, 'val_avg_loss': 0.614118}}\n",
      "2022-12-12 11:30:52,461 (monitor:512)INFO: current_best=-937.378775, should_save=True\n",
      "2022-12-12 11:30:52,461 (client:431)INFO: Client: #9, val_imp_ratio: -937.378775. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model9.pth\n",
      "2022-12-12 11:31:07,298 (client:410)INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'test_loss': 540503.493493, 'test_total': 36465, 'test_imp_ratio': -209169.051698, 'test_avg_loss': 14.822528, 'val_loss': 462508.736578, 'val_total': 36464, 'val_imp_ratio': -178976.42029, 'val_avg_loss': 12.683982}}\n",
      "2022-12-12 11:31:07,299 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-12-12 11:31:07,739 (client:410)INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'test_loss': 3175.342466, 'test_total': 756, 'test_imp_ratio': -472.224209, 'test_avg_loss': 4.200188, 'val_loss': 1545.360325, 'val_total': 756, 'val_imp_ratio': -178.487307, 'val_avg_loss': 2.044127}}\n",
      "2022-12-12 11:31:07,740 (monitor:512)INFO: current_best=-178.487307, should_save=True\n",
      "2022-12-12 11:31:07,740 (client:431)INFO: Client: #11, val_imp_ratio: -178.487307. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model11.pth\n",
      "2022-12-12 11:31:07,920 (client:410)INFO: {'Role': 'Client #12', 'Round': 1, 'Results_raw': {'test_loss': 561.646747, 'test_total': 203, 'test_imp_ratio': -103.238088, 'test_avg_loss': 2.766733, 'val_loss': 1418.799686, 'val_total': 203, 'val_imp_ratio': -413.408325, 'val_avg_loss': 6.989161}}\n",
      "2022-12-12 11:31:07,921 (monitor:512)INFO: current_best=-413.408325, should_save=True\n",
      "2022-12-12 11:31:07,922 (client:431)INFO: Client: #12, val_imp_ratio: -413.408325. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model12.pth\n",
      "2022-12-12 11:31:18,296 (client:410)INFO: {'Role': 'Client #13', 'Round': 1, 'Results_raw': {'test_loss': 606888.813423, 'test_total': 23550, 'test_imp_ratio': -587054.787367, 'test_avg_loss': 25.770226, 'val_loss': 530466.593281, 'val_total': 23549, 'val_imp_ratio': -513139.44356, 'val_avg_loss': 22.526077}}\n",
      "2022-12-12 11:31:18,297 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-12-12 11:31:36,981 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_total': 11010, 'train_imp_ratio': -9.23627, 'train_loss': 6334.564442, 'train_avg_loss': 0.575346}}\n",
      "2022-12-12 11:32:15,241 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_total': 22190, 'train_imp_ratio': 30.89382, 'train_loss': 11476.896548, 'train_avg_loss': 0.51721}}\n",
      "2022-12-12 11:32:17,117 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_total': 1010, 'train_imp_ratio': -57.095343, 'train_loss': 591.781043, 'train_avg_loss': 0.585922}}\n",
      "2022-12-12 11:32:19,963 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_total': 1880, 'train_imp_ratio': -6.697979, 'train_loss': 1271.070131, 'train_avg_loss': 0.676101}}\n",
      "2022-12-12 11:32:29,384 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #12', 'Round': 1, 'Results_raw': {'train_loss': 28796.451927, 'train_total': 6080, 'train_imp_ratio': -247.915085, 'train_avg_loss': 4.736259}}\n",
      "2022-12-12 11:32:50,500 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_total': 12490, 'train_imp_ratio': 61.514234, 'train_acc': 0.898479, 'train_loss': 3036.446148, 'train_avg_loss': 0.24311}}\n",
      "2022-12-12 11:35:24,569 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'train_loss': 481.255786, 'train_total': 109392, 'train_imp_ratio': 37.888325, 'train_avg_loss': 0.004399}}\n",
      "2022-12-12 11:37:11,570 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #13', 'Round': 1, 'Results_raw': {'train_loss': 338.945546, 'train_total': 70648, 'train_imp_ratio': -9.311149, 'train_avg_loss': 0.004798}}\n",
      "2022-12-12 11:37:23,823 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_total': 7770, 'train_imp_ratio': 57.351024, 'train_loss': 1983.549144, 'train_avg_loss': 0.255283}}\n",
      "2022-12-12 11:38:02,017 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_total': 22280, 'train_imp_ratio': 34.763072, 'train_loss': 9642.054071, 'train_avg_loss': 0.432767}}\n",
      "2022-12-12 11:38:04,908 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_total': 1810, 'train_imp_ratio': -21.135406, 'train_loss': 1149.759098, 'train_avg_loss': 0.635226}}\n",
      "2022-12-12 11:38:43,112 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_loss': 10743.618704, 'train_total': 22680, 'train_imp_ratio': 35.463563, 'train_avg_loss': 0.473705}}\n",
      "2022-12-12 11:42:17,181 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'train_loss': 4991.10594, 'train_total': 134706, 'train_imp_ratio': 37.41136, 'train_avg_loss': 0.037052}}\n",
      "2022-12-12 11:42:17,183 (server:480)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_total': 8350.846154, 'test_imp_ratio': -61431.700001, 'test_acc': 1.0, 'test_loss': 91531.434697, 'test_avg_loss': 4.145757, 'val_total': 8350.461538, 'val_imp_ratio': -53382.534193, 'val_acc': 0.615385, 'val_loss': 78920.17313, 'val_avg_loss': 3.980415}}\n",
      "2022-12-12 11:42:17,184 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-12-12 11:42:17,186 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-12-12 11:42:17,280 (laplacian_server_dom_sep:168)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-12-12 11:42:17,283 (laplacian_server_dom_sep:175)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-12-12 11:42:17,565 (client:410)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_total': 417, 'test_imp_ratio': 50.000006, 'test_acc': 0.868106, 'test_loss': 160.583973, 'test_avg_loss': 0.385093, 'val_total': 416, 'val_imp_ratio': -33.046313, 'val_acc': 0.649038, 'val_loss': 277.382587, 'val_avg_loss': 0.666785}}\n",
      "2022-12-12 11:42:17,566 (monitor:512)INFO: current_best=-33.046313, should_save=True\n",
      "2022-12-12 11:42:17,567 (client:431)INFO: Client: #1, val_imp_ratio: -33.046313. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model1.pth\n",
      "2022-12-12 11:42:17,687 (client:410)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'test_total': 61, 'test_imp_ratio': 3.773423, 'test_loss': 35.302318, 'test_avg_loss': 0.578727, 'val_total': 60, 'val_imp_ratio': -55.377619, 'val_loss': 45.290612, 'val_avg_loss': 0.754844}}\n",
      "2022-12-12 11:42:17,688 (monitor:512)INFO: current_best=-26.603986, should_save=False\n",
      "2022-12-12 11:42:18,135 (client:410)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'test_total': 740, 'test_imp_ratio': -34.601293, 'test_loss': 634.31964, 'test_avg_loss': 0.857189, 'val_total': 740, 'val_imp_ratio': 26.995909, 'val_loss': 431.46355, 'val_avg_loss': 0.583059}}\n",
      "2022-12-12 11:42:18,136 (monitor:512)INFO: current_best=26.995909, should_save=True\n",
      "2022-12-12 11:42:18,137 (client:431)INFO: Client: #3, val_imp_ratio: 26.995909. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model3.pth\n",
      "2022-12-12 11:42:18,247 (client:410)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'test_total': 34, 'test_imp_ratio': 83.333372, 'test_loss': 10.982238, 'test_avg_loss': 0.323007, 'val_total': 34, 'val_imp_ratio': -283.332439, 'val_loss': 38.832485, 'val_avg_loss': 1.142132}}\n",
      "2022-12-12 11:42:18,248 (monitor:512)INFO: current_best=-199.9993, should_save=False\n",
      "2022-12-12 11:42:18,343 (client:410)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'test_total': 63, 'test_imp_ratio': -100.0002, 'test_loss': 56.82463, 'test_avg_loss': 0.901978, 'val_total': 63, 'val_imp_ratio': -16.000116, 'val_loss': 50.39326, 'val_avg_loss': 0.799893}}\n",
      "2022-12-12 11:42:18,344 (monitor:512)INFO: current_best=-16.000116, should_save=True\n",
      "2022-12-12 11:42:18,345 (client:431)INFO: Client: #5, val_imp_ratio: -16.000116. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model5.pth\n",
      "2022-12-12 11:42:18,616 (client:410)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'test_total': 367, 'test_imp_ratio': -135.41701, 'test_loss': 314.859722, 'test_avg_loss': 0.857928, 'val_total': 367, 'val_imp_ratio': -3.12515, 'val_loss': 210.749909, 'val_avg_loss': 0.57425}}\n",
      "2022-12-12 11:42:18,617 (monitor:512)INFO: current_best=-3.12515, should_save=True\n",
      "2022-12-12 11:42:18,618 (client:431)INFO: Client: #6, val_imp_ratio: -3.12515. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model6.pth\n",
      "2022-12-12 11:42:19,092 (client:410)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'test_total': 743, 'test_imp_ratio': -2.818905, 'test_loss': 420.076438, 'test_avg_loss': 0.565379, 'val_total': 743, 'val_imp_ratio': 1.632129, 'val_loss': 441.593868, 'val_avg_loss': 0.594339}}\n",
      "2022-12-12 11:42:19,093 (monitor:512)INFO: current_best=1.632129, should_save=True\n",
      "2022-12-12 11:42:19,093 (client:431)INFO: Client: #7, val_imp_ratio: 1.632129. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model7.pth\n",
      "2022-12-12 11:42:19,322 (client:410)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'test_total': 260, 'test_imp_ratio': -329.091845, 'test_loss': 519.623893, 'test_avg_loss': 1.998553, 'val_total': 259, 'val_imp_ratio': 3.264092, 'val_loss': 118.740258, 'val_avg_loss': 0.458457}}\n",
      "2022-12-12 11:42:19,323 (monitor:512)INFO: current_best=8.73971, should_save=False\n",
      "2022-12-12 11:42:40,394 (client:410)INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'test_loss': 85480.49071, 'test_total': 44902, 'test_imp_ratio': -3115.78431, 'test_avg_loss': 1.903712, 'val_loss': 3358.2785, 'val_total': 44902, 'val_imp_ratio': -26.338772, 'val_avg_loss': 0.074791}}\n",
      "2022-12-12 11:42:40,395 (monitor:512)INFO: current_best=-26.338772, should_save=True\n",
      "2022-12-12 11:42:40,396 (client:431)INFO: Client: #9, val_imp_ratio: -26.338772. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model9.pth\n",
      "2022-12-12 11:42:55,573 (client:410)INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'test_loss': 8507.535586, 'test_total': 36465, 'test_imp_ratio': -3193.899473, 'test_avg_loss': 0.233307, 'val_loss': 1402.618408, 'val_total': 36464, 'val_imp_ratio': -443.072641, 'val_avg_loss': 0.038466}}\n",
      "2022-12-12 11:42:55,574 (monitor:512)INFO: current_best=-443.072641, should_save=True\n",
      "2022-12-12 11:42:55,575 (client:431)INFO: Client: #10, val_imp_ratio: -443.072641. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model10.pth\n",
      "2022-12-12 11:42:56,051 (client:410)INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'test_loss': 3674.308973, 'test_total': 756, 'test_imp_ratio': -562.142266, 'test_avg_loss': 4.860197, 'val_loss': 872.018413, 'val_total': 756, 'val_imp_ratio': -57.145258, 'val_avg_loss': 1.153464}}\n",
      "2022-12-12 11:42:56,052 (monitor:512)INFO: current_best=-57.145258, should_save=True\n",
      "2022-12-12 11:42:56,052 (client:431)INFO: Client: #11, val_imp_ratio: -57.145258. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model11.pth\n",
      "2022-12-12 11:42:56,238 (client:410)INFO: {'Role': 'Client #12', 'Round': 2, 'Results_raw': {'test_loss': 814.208886, 'test_total': 203, 'test_imp_ratio': -194.630522, 'test_avg_loss': 4.010881, 'val_loss': 927.752659, 'val_total': 203, 'val_imp_ratio': -235.717562, 'val_avg_loss': 4.57021}}\n",
      "2022-12-12 11:42:56,239 (monitor:512)INFO: current_best=-235.717562, should_save=True\n",
      "2022-12-12 11:42:56,239 (client:431)INFO: Client: #12, val_imp_ratio: -235.717562. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model12.pth\n",
      "2022-12-12 11:43:06,790 (client:410)INFO: {'Role': 'Client #13', 'Round': 2, 'Results_raw': {'test_loss': 12405.26026, 'test_total': 23550, 'test_imp_ratio': -11901.883443, 'test_avg_loss': 0.526763, 'val_loss': 6371.532866, 'val_total': 23549, 'val_imp_ratio': -6064.613441, 'val_avg_loss': 0.270565}}\n",
      "2022-12-12 11:43:06,790 (monitor:512)INFO: current_best=-6064.613441, should_save=True\n",
      "2022-12-12 11:43:06,791 (client:431)INFO: Client: #13, val_imp_ratio: -6064.613441. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model13.pth\n",
      "2022-12-12 11:43:45,116 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_loss': 8984.644329, 'train_total': 22680, 'train_imp_ratio': 46.029643, 'train_avg_loss': 0.396148}}\n",
      "2022-12-12 11:43:47,966 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_total': 1810, 'train_imp_ratio': -3.966608, 'train_loss': 1084.442953, 'train_avg_loss': 0.59914}}\n",
      "2022-12-12 11:44:25,988 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_total': 22280, 'train_imp_ratio': 41.160595, 'train_loss': 9017.785521, 'train_avg_loss': 0.404748}}\n",
      "2022-12-12 11:44:38,271 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_total': 7770, 'train_imp_ratio': 64.469327, 'train_loss': 1618.290881, 'train_avg_loss': 0.208274}}\n",
      "2022-12-12 11:45:17,257 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_total': 22190, 'train_imp_ratio': 34.71051, 'train_loss': 11039.690293, 'train_avg_loss': 0.497507}}\n",
      "2022-12-12 11:47:06,852 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #13', 'Round': 2, 'Results_raw': {'train_loss': 254.433394, 'train_total': 70648, 'train_imp_ratio': 17.944317, 'train_avg_loss': 0.003601}}\n",
      "2022-12-12 11:47:25,744 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_total': 11010, 'train_imp_ratio': 3.159581, 'train_loss': 6007.719642, 'train_avg_loss': 0.54566}}\n",
      "2022-12-12 11:47:35,507 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #12', 'Round': 2, 'Results_raw': {'train_loss': 15292.891966, 'train_total': 6080, 'train_imp_ratio': -84.766789, 'train_avg_loss': 2.515278}}\n",
      "2022-12-12 11:47:56,709 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_total': 12490, 'train_imp_ratio': 69.041419, 'train_acc': 0.918335, 'train_loss': 2576.89137, 'train_avg_loss': 0.206316}}\n",
      "2022-12-12 11:47:58,525 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_total': 1010, 'train_imp_ratio': -13.333069, 'train_loss': 526.034828, 'train_avg_loss': 0.520827}}\n",
      "2022-12-12 11:48:01,519 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_total': 1880, 'train_imp_ratio': 6.304162, 'train_loss': 1189.654127, 'train_avg_loss': 0.632795}}\n",
      "2022-12-12 11:50:35,202 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'train_loss': 372.871679, 'train_total': 109392, 'train_imp_ratio': 51.876585, 'train_avg_loss': 0.003409}}\n",
      "2022-12-12 11:54:07,994 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'train_loss': 4600.737179, 'train_total': 134706, 'train_imp_ratio': 42.3066, 'train_avg_loss': 0.034154}}\n",
      "2022-12-12 11:54:07,996 (server:480)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_total': 8350.846154, 'test_imp_ratio': -1494.858651, 'test_acc': 0.868106, 'test_loss': 8694.952097, 'test_avg_loss': 1.384824, 'val_total': 8350.461538, 'val_imp_ratio': -552.759783, 'val_acc': 0.649038, 'val_loss': 1118.972875, 'val_avg_loss': 0.898558}}\n",
      "2022-12-12 11:54:07,997 (monitor:512)INFO: current_best=-10000, should_save=False\n",
      "2022-12-12 11:54:07,998 (monitor:512)INFO: current_best=-552.759783, should_save=True\n",
      "2022-12-12 11:54:08,092 (laplacian_server_dom_sep:168)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-12-12 11:54:08,094 (laplacian_server_dom_sep:175)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-12-12 11:54:08,378 (client:410)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_total': 417, 'test_imp_ratio': 88.18182, 'test_acc': 0.968825, 'test_loss': 38.251875, 'test_avg_loss': 0.091731, 'val_total': 416, 'val_imp_ratio': -43.981626, 'val_acc': 0.620192, 'val_loss': 726.222641, 'val_avg_loss': 1.745728}}\n",
      "2022-12-12 11:54:08,379 (monitor:512)INFO: current_best=-33.046313, should_save=False\n",
      "2022-12-12 11:54:08,477 (client:410)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'test_total': 61, 'test_imp_ratio': -41.509672, 'test_loss': 40.895689, 'test_avg_loss': 0.670421, 'val_total': 60, 'val_imp_ratio': -78.396526, 'val_loss': 42.593994, 'val_avg_loss': 0.7099}}\n",
      "2022-12-12 11:54:08,478 (monitor:512)INFO: current_best=-26.603986, should_save=False\n",
      "2022-12-12 11:54:08,931 (client:410)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'test_total': 740, 'test_imp_ratio': -32.319915, 'test_loss': 678.29617, 'test_avg_loss': 0.916616, 'val_total': 740, 'val_imp_ratio': 28.516828, 'val_loss': 424.512563, 'val_avg_loss': 0.573666}}\n",
      "2022-12-12 11:54:08,932 (monitor:512)INFO: current_best=28.516828, should_save=True\n",
      "2022-12-12 11:54:08,933 (client:431)INFO: Client: #3, val_imp_ratio: 28.516828. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model3.pth\n",
      "2022-12-12 11:54:09,043 (client:410)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'test_total': 34, 'test_imp_ratio': 83.333372, 'test_loss': 13.452807, 'test_avg_loss': 0.395671, 'val_total': 34, 'val_imp_ratio': -233.332556, 'val_loss': 35.52627, 'val_avg_loss': 1.04489}}\n",
      "2022-12-12 11:54:09,043 (monitor:512)INFO: current_best=-199.9993, should_save=False\n",
      "2022-12-12 11:54:09,139 (client:410)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'test_total': 63, 'test_imp_ratio': -64.000164, 'test_loss': 51.464693, 'test_avg_loss': 0.8169, 'val_total': 63, 'val_imp_ratio': -4.000104, 'val_loss': 50.315361, 'val_avg_loss': 0.798657}}\n",
      "2022-12-12 11:54:09,140 (monitor:512)INFO: current_best=-4.000104, should_save=True\n",
      "2022-12-12 11:54:09,141 (client:431)INFO: Client: #5, val_imp_ratio: -4.000104. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model5.pth\n",
      "2022-12-12 11:54:09,413 (client:410)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'test_total': 367, 'test_imp_ratio': -172.917065, 'test_loss': 387.498366, 'test_avg_loss': 1.055854, 'val_total': 367, 'val_imp_ratio': 13.541541, 'val_loss': 187.314348, 'val_avg_loss': 0.510393}}\n",
      "2022-12-12 11:54:09,414 (monitor:512)INFO: current_best=13.541541, should_save=True\n",
      "2022-12-12 11:54:09,415 (client:431)INFO: Client: #6, val_imp_ratio: 13.541541. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model6.pth\n",
      "2022-12-12 11:54:09,896 (client:410)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'test_total': 743, 'test_imp_ratio': 1.632129, 'test_loss': 435.559828, 'test_avg_loss': 0.586218, 'val_total': 743, 'val_imp_ratio': 14.540131, 'val_loss': 412.328117, 'val_avg_loss': 0.55495}}\n",
      "2022-12-12 11:54:09,897 (monitor:512)INFO: current_best=14.540131, should_save=True\n",
      "2022-12-12 11:54:09,898 (client:431)INFO: Client: #7, val_imp_ratio: 14.540131. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model7.pth\n",
      "2022-12-12 11:54:10,108 (client:410)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'test_total': 260, 'test_imp_ratio': -356.364632, 'test_loss': 805.178608, 'test_avg_loss': 3.096841, 'val_total': 259, 'val_imp_ratio': 45.243826, 'val_loss': 101.971533, 'val_avg_loss': 0.393712}}\n",
      "2022-12-12 11:54:10,109 (monitor:512)INFO: current_best=45.243826, should_save=True\n",
      "2022-12-12 11:54:10,110 (client:431)INFO: Client: #8, val_imp_ratio: 45.243826. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model8.pth\n",
      "2022-12-12 11:54:31,252 (client:410)INFO: {'Role': 'Client #9', 'Round': 3, 'Results_raw': {'test_loss': 90501.924727, 'test_total': 44902, 'test_imp_ratio': -3304.691736, 'test_avg_loss': 2.015543, 'val_loss': 2460.402625, 'val_total': 44902, 'val_imp_ratio': 7.439408, 'val_avg_loss': 0.054795}}\n",
      "2022-12-12 11:54:31,253 (monitor:512)INFO: current_best=7.439408, should_save=True\n",
      "2022-12-12 11:54:31,254 (client:431)INFO: Client: #9, val_imp_ratio: 7.439408. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model9.pth\n",
      "2022-12-12 11:54:46,725 (client:410)INFO: {'Role': 'Client #10', 'Round': 3, 'Results_raw': {'test_loss': 6881.706813, 'test_total': 36465, 'test_imp_ratio': -2564.419978, 'test_avg_loss': 0.188721, 'val_loss': 249.815586, 'val_total': 36464, 'val_imp_ratio': 3.275175, 'val_avg_loss': 0.006851}}\n",
      "2022-12-12 11:54:46,726 (monitor:512)INFO: current_best=3.275175, should_save=True\n",
      "2022-12-12 11:54:46,727 (client:431)INFO: Client: #10, val_imp_ratio: 3.275175. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model10.pth\n",
      "2022-12-12 11:54:47,194 (client:410)INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'test_loss': 4455.533516, 'test_total': 756, 'test_imp_ratio': -702.925612, 'test_avg_loss': 5.893563, 'val_loss': 1009.505328, 'val_total': 756, 'val_imp_ratio': -81.921596, 'val_avg_loss': 1.335325}}\n",
      "2022-12-12 11:54:47,195 (monitor:512)INFO: current_best=-57.145258, should_save=False\n",
      "2022-12-12 11:54:47,366 (client:410)INFO: {'Role': 'Client #12', 'Round': 3, 'Results_raw': {'test_loss': 1380.55404, 'test_total': 203, 'test_imp_ratio': -399.568682, 'test_avg_loss': 6.800759, 'val_loss': 433.030885, 'val_total': 203, 'val_imp_ratio': -56.697001, 'val_avg_loss': 2.133157}}\n",
      "2022-12-12 11:54:47,367 (monitor:512)INFO: current_best=-56.697001, should_save=True\n",
      "2022-12-12 11:54:47,367 (client:431)INFO: Client: #12, val_imp_ratio: -56.697001. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model12.pth\n",
      "2022-12-12 11:54:58,040 (client:410)INFO: {'Role': 'Client #13', 'Round': 3, 'Results_raw': {'test_loss': 6997.579013, 'test_total': 23550, 'test_imp_ratio': -6670.040593, 'test_avg_loss': 0.297137, 'val_loss': 699.92433, 'val_total': 23549, 'val_imp_ratio': -577.193906, 'val_avg_loss': 0.029722}}\n",
      "2022-12-12 11:54:58,041 (monitor:512)INFO: current_best=-577.193906, should_save=True\n",
      "2022-12-12 11:54:58,041 (client:431)INFO: Client: #13, val_imp_ratio: -577.193906. model saved at exp/Laplacian_domain_sep_sum_MI_csd100.0_lam1_diff1_MI_lr_0.01_no_finetune_gin_on_cikm_cup_lr0.1_lstep10_/model13.pth\n",
      "2022-12-12 11:55:16,692 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'train_total': 11010, 'train_imp_ratio': 12.360983, 'train_loss': 5776.401763, 'train_avg_loss': 0.52465}}\n",
      "2022-12-12 11:55:19,584 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'train_total': 1880, 'train_imp_ratio': 16.491406, 'train_loss': 1123.123351, 'train_avg_loss': 0.597406}}\n",
      "2022-12-12 11:55:57,824 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'train_total': 22190, 'train_imp_ratio': 36.612515, 'train_loss': 10773.334118, 'train_avg_loss': 0.485504}}\n",
      "2022-12-12 11:56:35,440 (laplacian_with_domain_separation_MI_client:140)INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'train_loss': 7898.431148, 'train_total': 22680, 'train_imp_ratio': 52.554476, 'train_avg_loss': 0.348255}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [11], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m Fed_runner \u001B[38;5;241m=\u001B[39m FedRunner(data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m      2\u001B[0m                        server_class\u001B[38;5;241m=\u001B[39mLaplacianServerDomSep,\n\u001B[1;32m      3\u001B[0m                        client_class\u001B[38;5;241m=\u001B[39mLaplacianDomainSeparationMIClient,\n\u001B[1;32m      4\u001B[0m                        config\u001B[38;5;241m=\u001B[39mcfg\u001B[38;5;241m.\u001B[39mclone(),\n\u001B[1;32m      5\u001B[0m                        client_config\u001B[38;5;241m=\u001B[39mclient_cfg)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mFed_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:186\u001B[0m, in \u001B[0;36mFedRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    185\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mfinish_fed_runner(fl_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mbest_results\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:325\u001B[0m, in \u001B[0;36mFedRunner._handle_msg\u001B[0;34m(self, msg, rcv)\u001B[0m\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(download_bytes)\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 325\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m[\u001B[49m\u001B[43meach_receiver\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_handlers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[each_receiver]\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(\n\u001B[1;32m    327\u001B[0m         download_bytes)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/workers/laplacian_with_domain_separation_MI_client.py:131\u001B[0m, in \u001B[0;36mLaplacianDomainSeparationMIClient.callback_funcs_for_model_para\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m    126\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    127\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Normal FL Mode] Client #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mID\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has been locally \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mearly stopped. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe next FL update may result in negative effect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mlocal_converged()\n\u001B[0;32m--> 131\u001B[0m sample_size, model_para_all, omega_set, results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39mshare_local_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \\\n\u001B[1;32m    133\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39monline_aggr:\n\u001B[1;32m    134\u001B[0m     model_para_all \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(model_para_all)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/auxiliaries/decorators.py:28\u001B[0m, in \u001B[0;36muse_diff_laplacian.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     before_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m num_samples_train, model_para, omega, result_metric \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     after_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_with_summation_MI.py:254\u001B[0m, in \u001B[0;36mLaplacianDomainSeparationWithSummationMITrainer.train\u001B[0;34m(self, state, target_data_split_name, hooks_set)\u001B[0m\n\u001B[1;32m    250\u001B[0m hooks_set \u001B[38;5;241m=\u001B[39m hooks_set \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks_in_train\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcheck_data_split(target_data_split_name)\n\u001B[0;32m--> 254\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_routine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_data_split_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_round \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39malpha, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_para(\n\u001B[1;32m    258\u001B[0m ), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_omega_para(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39meval_metrics\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/trainers/trainer.py:276\u001B[0m, in \u001B[0;36mTrainer._run_routine\u001B[0;34m(self, mode, hooks_set, dataset_name)\u001B[0m\n\u001B[1;32m    274\u001B[0m     hook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx)\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 276\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcur_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_with_summation_MI.py:128\u001B[0m, in \u001B[0;36mLaplacianDomainSeparationWithSummationMITrainer._hook_on_batch_forward\u001B[0;34m(self, ctx)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtmp \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    127\u001B[0m batch \u001B[38;5;241m=\u001B[39m ctx\u001B[38;5;241m.\u001B[39mdata_batch\u001B[38;5;241m.\u001B[39mto(ctx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 128\u001B[0m pred, mi \u001B[38;5;241m=\u001B[39m \u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    129\u001B[0m ctx\u001B[38;5;241m.\u001B[39mmi \u001B[38;5;241m=\u001B[39m mi\n\u001B[1;32m    130\u001B[0m \u001B[38;5;66;03m# print(f\"negative mi: {-ctx.mi}\")\u001B[39;00m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/gfl/model/graph_level.py:168\u001B[0m, in \u001B[0;36mGNN_Net_Graph.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    165\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memb(edge_attr)\n\u001B[1;32m    166\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn_edge(edge_attr)\n\u001B[0;32m--> 168\u001B[0m x_local \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocal_gnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m x_global \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_gnn(x, edge_index, edge_attr)\n\u001B[1;32m    172\u001B[0m x_global \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling(x_global, batch)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/gfl/model/gine_no_jk.py:79\u001B[0m, in \u001B[0;36mGINE_NO_JK_Net.forward\u001B[0;34m(self, x, edge_index, edge_attr)\u001B[0m\n\u001B[1;32m     77\u001B[0m xs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs):\n\u001B[0;32m---> 79\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(F\u001B[38;5;241m.\u001B[39mdropout(x, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining))\n\u001B[1;32m     81\u001B[0m     xs\u001B[38;5;241m.\u001B[39mappend(x)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/gin_conv.py:172\u001B[0m, in \u001B[0;36mGINEConv.forward\u001B[0;34m(self, x, edge_index, edge_attr, size)\u001B[0m\n\u001B[1;32m    169\u001B[0m     x: OptPairTensor \u001B[38;5;241m=\u001B[39m (x, x)\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[0;32m--> 172\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m x_r \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x_r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:391\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    389\u001B[0m         aggr_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[0;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggregate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43maggr_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m    394\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (aggr_kwargs, ), out)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:514\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[0;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maggregate\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Tensor, index: Tensor,\n\u001B[1;32m    502\u001B[0m               ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    503\u001B[0m               dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;124;03m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[1;32m    506\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py:114\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dim_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()):\n\u001B[1;32m    110\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered invalid \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    111\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m but expected \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    112\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>= \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/aggr/basic.py:21\u001B[0m, in \u001B[0;36mSumAggregation.forward\u001B[0;34m(self, x, index, ptr, dim_size, dim)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor, index: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     19\u001B[0m             ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     20\u001B[0m             dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/aggr/base.py:153\u001B[0m, in \u001B[0;36mAggregation.reduce\u001B[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m segment_csr(x, ptr, reduce\u001B[38;5;241m=\u001B[39mreduce)\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/utils/scatter.py:64\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, out, dim_size, reduce)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter\u001B[39m(src: Tensor, index: Tensor, dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     62\u001B[0m             out: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     63\u001B[0m             reduce: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch_scatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_scatter/scatter.py:152\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, out, dim_size, reduce)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03m|\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;124;03m    torch.Size([10, 3, 64])\u001B[39;00m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmul\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scatter_mul(src, index, dim, out, dim_size)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_scatter/scatter.py:21\u001B[0m, in \u001B[0;36mscatter_sum\u001B[0;34m(src, index, dim, out, dim_size)\u001B[0m\n\u001B[1;32m     19\u001B[0m         size[dim] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     20\u001B[0m     out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(size, dtype\u001B[38;5;241m=\u001B[39msrc\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39msrc\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\u001B[38;5;241m.\u001B[39mscatter_add_(dim, index, src)\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:197\u001B[0m, in \u001B[0;36mformat_stack\u001B[0;34m(f, limit)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    196\u001B[0m     f \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39m_getframe()\u001B[38;5;241m.\u001B[39mf_back\n\u001B[0;32m--> 197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformat_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mextract_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:39\u001B[0m, in \u001B[0;36mformat_list\u001B[0;34m(extracted_list)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_list\u001B[39m(extracted_list):\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;124;03m\"\"\"Format a list of tuples or FrameSummary objects for printing.\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    Given a list of tuples or FrameSummary objects as returned by\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03m    whose source text line is not None.\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mStackSummary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mextracted_list\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:423\u001B[0m, in \u001B[0;36mStackSummary.format\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    422\u001B[0m row \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 423\u001B[0m \u001B[43mrow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m  File \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m, line \u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m, in \u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlineno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m frame\u001B[38;5;241m.\u001B[39mline:\n\u001B[1;32m    426\u001B[0m     row\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(frame\u001B[38;5;241m.\u001B[39mline\u001B[38;5;241m.\u001B[39mstrip()))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "Fed_runner = FedRunner(data=data,\n",
    "                       server_class=LaplacianServerDomSep,\n",
    "                       client_class=LaplacianDomainSeparationMIClient,\n",
    "                       config=cfg.clone(),\n",
    "                       client_config=client_cfg)\n",
    "Fed_runner.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-+/896*-Difference train_avg_loss: 125 -> 174\n",
    "1: 0.539109 -> 0.540\n",
    "2: 0.614181 -> 0.60414\n",
    "3: 0.680621 -> 0.675371\n",
    "4: 0.466614 -> 0.405735\n",
    "5: 0.64907 -> 0.648837\n",
    "6: 0.479263 -> 0.470293\n",
    "7: 0.668663 -> 0.662036\n",
    "8: 0.438008 -> 0.433998\n",
    "9: 0.107733 -> 0.118945\n",
    "10: 0.009074 -> 0.009043\n",
    "11: 1.128238 -> 1.126667\n",
    "12: 2.657362 -> 2.661828\n",
    "13: -> 0.007134\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "+"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ",,0After 10 rounds:\n",
    "\n",
    "diff: 0, csd: 0:\n",
    "server: -8\n",
    "c1 t/val: 0.375 /0.37\n",
    "c2 t/val: 0.678 /0.606\n",
    "c3 t/val: 0.699 /0.608\n",
    "c4 t/val: 0.599 /0.537\n",
    "\n",
    "diff: 0, csd: 0:\n",
    "server: -4.5\n",
    "c1 t/val: 0.372879 /0.328\n",
    "c2 t/val: 0.678992 /0.605809\n",
    "c3 t/val: 0.70166 /0.608609\n",
    "c4 t/val: 0.597455 /0.534253\n",
    "\n",
    "\n",
    "\n",
    "diff: 10, csd: 0:\n",
    "server: -35\n",
    "c1 t/val: 0.482/0.52\n",
    "c2 t/val: 0.694/0.65\n",
    "c3 t/val: 0.724/0.65\n",
    "c4 t/val: 0.674/0.575\n",
    "\n",
    "diff: 1, csd: 0:\n",
    "server: -9.6\n",
    "c1 t/val: 0.378194/0.319349\n",
    "c2 t/val: 0.67461/0.609163\n",
    "c3 t/val: 0.705559/0.615019\n",
    "c4 t/val: 0.605581/0.572086\n",
    "\n",
    "diff: 0, csd: 1e4:\n",
    "server: -18\n",
    "c1 t/val: 0.280962/0.23074\n",
    "c2 t/val: 0.682652/0.603175\n",
    "c3 t/val: 0.699094/0.67027\n",
    "c4 t/val: 0.594985/0.609611\n",
    "\n",
    "diff: 0 csd: 1e8\n",
    "server: -18\n",
    "c1 t/val: 0.2606/0.348(0.197)\n",
    "c2 t/val: 0.653/0.0.602\n",
    "c3 t/val: 0.691/0.597\n",
    "c4 t/val: 0.581/0.629\n",
    "\n",
    "diff: 0 csd: 1e8\n",
    "server: -12.7\n",
    "c1 t/val: 0.262647/0.249875\n",
    "c2 t/val: 0.649273/0.0.600435\n",
    "c3 t/val: 0.696132/0.615158\n",
    "c4 t/val: 0.586597/0.656992\n",
    "\n",
    "\n",
    "diff: 0.1 csd: 0\n",
    "server: -11\n",
    "c1 t/val: 0.2606/0.332837\n",
    "c2 t/val: 0.678326/0.0.610099\n",
    "c3 t/val: 0.704083/0.616179\n",
    "c4 t/val: 0.604177/0.559658\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCUBLAS_WORKSPACE_CONFIG\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
