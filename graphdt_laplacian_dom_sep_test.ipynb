{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from federatedscope.register import register_data\n",
    "from federatedscope.register import register_trainer\n",
    "from federatedscope.register import register_metric\n",
    "from federatedscope.register import register_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#from federatedscope.contrib.model.mnist_model import call_my_net\n",
    "#register_model(\"mynet\", call_my_net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n",
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/logger.py:23: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_KLD import call_laplacian_trainer\n",
    "\n",
    "register_trainer('laplacian_trainer', call_laplacian_trainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " 89.1### Register metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set data, model, trainer and metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from federatedscope.core.configs.config import global_cfg, CN\n",
    "cfg = global_cfg.clone()\n",
    "\n",
    "cfg.merge_from_file(\"scripts/B-FHTL_exp_scripts/Graph-DT/fed_dom_sep_KLD.yaml\")\n",
    "cfg.data.save_dir = 'test_dir'\n",
    "#cfg.data.type = 'cikm_cup'\n",
    "#cfg.data.root = 'data'\n",
    "#cfg.data.shuffle=True\n",
    "#cfg.data.transform = [['ToTensor'], ['Normalize', {'mean': [0.], 'std': [1]}]]\n",
    "#cfg.model.type = 'gin'\n",
    "#cfg.model.out_channels = 10\n",
    "#cfg.model.hidden = 64\n",
    "#cfg.model.task='graph'\n",
    "#cfg.model.dropout = 0.5\n",
    "#cfg.personalization.local_param = ['encoder_atom', 'encoder', 'clf']#['node_encoder', 'clf']\n",
    "#cfg.train.batch_or_epoch = \"epoch\"\n",
    "#cfg.trainer.type = 'laplacian_trainer'\n",
    "#cfg.data.batch_size = 64\n",
    "# cfg.eval.metric = ['mymetric']\n",
    "\n",
    "cfg.params = CN()\n",
    "cfg.params.alpha=0.1\n",
    "cfg.params.diff_importance = 0.\n",
    "cfg.params.csd_importance=1e2\n",
    "cfg.params.lam = 0.\n",
    "cfg.params.eps=1e-15\n",
    "cfg.params.p=0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### configure other options"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#cfg.use_gpu = True\n",
    "#cfg.best_res_update_round_wise_key = \"test_loss\"\n",
    "\n",
    "#cfg.federate.mode = 'standalone'\n",
    "cfg.federate.method = 'test'  # 'Laplacian_batch_all_clients_csd_1e3_new'\n",
    "#cfg.federate.local_update_steps = 20000000\n",
    "#cfg.personalization.local_update_steps = 20000000\n",
    "#cfg.finetune.local_update_steps = 20000000\n",
    "#cfg.train.local_update_steps = 1\n",
    "\n",
    "cfg.federate.total_round_num = 20000\n",
    "\n",
    "cfg.federate.client_num = 2\n",
    "cfg.early_stop.patience = 20000\n",
    "#cfg.train.optimizer.lr = 0.001\n",
    "#cfg.train.optimizer.weight_decay = 0.0005\n",
    "cfg.grad.grad_clip = 5.0\n",
    "#cfg.criterion.type = 'CrossEntropyLoss'\n",
    "#cfg.seed = 123\n",
    "cfg.model.dropout = 0.5\n",
    "cfg.eval.freq = 1\n",
    "cfg.eval.metrics = ['imp_ratio']\n",
    "cfg.eval.report = ['avg']\n",
    "cfg.eval.best_res_update_round_wise_key = 'val_imp_ratio'\n",
    "cfg.eval.count_flops = False\n",
    "cfg.model.hidden=64\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.manual_seed(0)\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.use_deterministic_algorithms(False)\n",
    "#import random\n",
    "#random.seed(0)\n",
    "#import numpy as np\n",
    "#np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from yacs.config import CfgNode\n",
    "client_cfg_file = \"scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client_ours_lr_local_steps.yaml\"\n",
    "client_cfg = CfgNode.load_cfg(open(client_cfg_file,\n",
    "                                       'r')) if client_cfg_file else None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start the FL prosess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:38:34,626 (trainer_builder:11)WARNING: No module named 'federatedscope.contrib.optimizer' in `federatedscope.contrib.trainer`, some modules are not available.\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "from federatedscope.core.fed_runner import FedRunner\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:38:34,634 (utils:129)INFO: the current machine is at 127.0.1.1\n",
      "2023-01-14 16:38:34,635 (utils:131)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2023-01-14 16:38:34,635 (utils:132)INFO: the output dir is exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "update_logger(cfg)\n",
    "data, modified_cfg = get_data(cfg)\n",
    "cfg.merge_from_other_cfg(modified_cfg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "server params: \n",
      "encoder_atom.atom_embedding_list.0.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "2023-01-14 16:38:37,672 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2023-01-14 16:38:37,685 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 2\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 20000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.9243\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: test_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 2\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: test\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 2\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 20000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 0.0\n",
      "  eps: 1e-15\n",
      "  lam: 0.0\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'mine']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 8\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-14 16:38:37,730 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_KLD.LaplacianDomainSeparationKLDTrainer'>\n",
      "2023-01-14 16:38:37,731 (fed_runner:302)INFO: Client 1 has been set up ... \n",
      "2023-01-14 16:38:37,748 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 2\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 20000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0265\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: test_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 2\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: test\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 2\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 20000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 0.0\n",
      "  eps: 1e-15\n",
      "  lam: 0.0\n",
      "  p: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'mine']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 5\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-14 16:38:37,782 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_KLD.LaplacianDomainSeparationKLDTrainer'>\n",
      "2023-01-14 16:38:37,783 (fed_runner:302)INFO: Client 2 has been set up ... \n",
      "2023-01-14 16:38:37,784 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2023-01-14 16:38:37,787 (trainer:332)INFO: Num of original para names: 136.\n",
      "2023-01-14 16:38:37,787 (trainer:333)INFO: Num of original trainable para names: 84.\n",
      "2023-01-14 16:38:37,788 (trainer:335)INFO: Num of preserved para names in local update: 66. \n",
      "Preserved para names in local update: {'bn_linear0_loc.running_var', 'global_gnn.convs.1.nn.norms.0.running_mean', 'bn_linear0_loc.weight', 'global_gnn.convs.1.eps', 'emb.bias', 'global_gnn.convs.0.nn.norms.0.num_batches_tracked', 'global_gnn.convs.1.nn.norms.0.running_var', 'global_gnn.convs.1.nn.linears.0.bias', 'bn_linear0_loc.running_mean', 'global_gnn.convs.0.eps', 'global_linear_out1.weight', 'global_gnn.convs.1.nn.norms.1.bias', 'global_gnn.convs.0.nn.norms.0.running_mean', 'global_gnn.convs.0.nn.norms.1.running_var', 'bn_edge.running_mean', 'bn_edge.weight', 'global_gnn.convs.0.nn.linears.0.weight', 'global_gnn.convs.0.nn.linears.1.weight', 'bn_edge.bias', 'global_gnn.convs.0.nn.norms.1.weight', 'bn_after_summation.bias', 'bn_linear2.weight', 'global_gnn.convs.0.nn.norms.0.bias', 'bn_node.num_batches_tracked', 'global_gnn.convs.0.nn.norms.1.num_batches_tracked', 'bn_linear0_loc.num_batches_tracked', 'global_gnn.convs.0.nn.norms.0.running_var', 'global_gnn.convs.1.nn.norms.1.running_mean', 'global_gnn.convs.1.nn.norms.1.running_var', 'global_gnn.convs.0.nn.linears.1.bias', 'global_gnn.convs.1.nn.norms.0.bias', 'global_gnn.convs.1.nn.norms.1.weight', 'global_gnn.convs.0.nn.linears.0.bias', 'global_gnn.convs.1.nn.norms.1.num_batches_tracked', 'bn_edge.num_batches_tracked', 'bn_linear2.bias', 'global_gnn.convs.0.nn.norms.0.weight', 'bn_after_summation.running_var', 'bn_linear1_loc.running_mean', 'bn_after_summation.running_mean', 'bn_linear1_loc.num_batches_tracked', 'bn_linear2.running_mean', 'bn_linear1_loc.weight', 'linear_out2.0.weight', 'bn_node.running_mean', 'bn_after_summation.num_batches_tracked', 'bn_node.running_var', 'global_linear_out1.bias', 'global_gnn.convs.1.nn.linears.0.weight', 'global_gnn.convs.0.nn.norms.1.bias', 'global_gnn.convs.1.nn.linears.1.bias', 'bn_edge.running_var', 'emb.weight', 'bn_after_summation.weight', 'bn_linear2.num_batches_tracked', 'bn_node.bias', 'global_gnn.convs.1.nn.norms.0.num_batches_tracked', 'bn_linear1_loc.bias', 'bn_linear1_loc.running_var', 'global_gnn.convs.0.nn.norms.1.running_mean', 'global_gnn.convs.1.nn.norms.0.weight', 'bn_linear0_loc.bias', 'bn_linear2.running_var', 'linear_out2.0.bias', 'bn_node.weight', 'global_gnn.convs.1.nn.linears.1.weight'}.\n",
      "2023-01-14 16:38:37,789 (trainer:339)INFO: Num of filtered para names in local update: 70. \n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.7.weight', 'mine.energy_loss.T.5.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.16.weight', 'local_gnn.convs.1.nn.linears.1.weight', 'mine.T.1.weight', 'encoder_atom.atom_embedding_list.21.weight', 'local_gnn.convs.0.eps', 'local_gnn.convs.0.nn.norms.1.weight', 'mine.T.3.bias', 'local_gnn.convs.1.nn.norms.1.num_batches_tracked', 'encoder_atom.atom_embedding_list.10.weight', 'local_gnn.convs.1.nn.norms.0.num_batches_tracked', 'encoder_atom.atom_embedding_list.18.weight', 'local_gnn.convs.0.nn.norms.0.running_var', 'local_gnn.convs.0.nn.norms.0.running_mean', 'encoder_atom.atom_embedding_list.0.weight', 'mine.energy_loss.T.3.weight', 'mine.T.5.bias', 'local_gnn.convs.1.nn.norms.0.running_mean', 'local_linear_out1.weight', 'local_gnn.convs.1.nn.linears.0.weight', 'local_gnn.convs.1.nn.linears.0.bias', 'local_gnn.convs.0.nn.norms.0.num_batches_tracked', 'local_gnn.convs.0.nn.norms.0.bias', 'local_gnn.convs.1.nn.linears.1.bias', 'local_gnn.convs.0.nn.norms.0.weight', 'local_gnn.convs.0.nn.norms.1.bias', 'mine.T.1.bias', 'encoder_atom.atom_embedding_list.9.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.3.weight', 'local_gnn.convs.1.nn.norms.0.running_var', 'mine.T.3.weight', 'encoder_atom.atom_embedding_list.12.weight', 'mine.energy_loss.T.5.bias', 'mine.energy_loss.T.1.weight', 'encoder_atom.atom_embedding_list.15.weight', 'local_gnn.convs.0.nn.norms.1.running_mean', 'local_gnn.convs.0.nn.linears.0.bias', 'mine.energy_loss.T.3.bias', 'encoder_atom.atom_embedding_list.5.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder.bias', 'local_gnn.convs.1.nn.norms.1.bias', 'local_gnn.convs.1.eps', 'local_gnn.convs.1.nn.norms.1.running_mean', 'local_gnn.convs.0.nn.linears.1.weight', 'encoder.weight', 'encoder_atom.atom_embedding_list.4.weight', 'encoder_atom.atom_embedding_list.11.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.1.weight', 'encoder_atom.atom_embedding_list.17.weight', 'mine.T.5.weight', 'local_gnn.convs.1.nn.norms.0.weight', 'local_gnn.convs.0.nn.linears.1.bias', 'local_gnn.convs.0.nn.norms.1.num_batches_tracked', 'encoder_atom.atom_embedding_list.19.weight', 'encoder_atom.atom_embedding_list.6.weight', 'local_gnn.convs.0.nn.linears.0.weight', 'local_gnn.convs.1.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.13.weight', 'local_linear_out1.bias', 'local_gnn.convs.1.nn.norms.1.running_var', 'mine.energy_loss.T.1.bias', 'local_gnn.convs.0.nn.norms.1.running_var', 'local_gnn.convs.1.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.14.weight', 'encoder_atom.atom_embedding_list.20.weight'}.\n",
      "2023-01-14 16:38:37,790 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2023-01-14 16:38:37,794 (server:628)INFO: ----------- Starting training (Round #0) -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_atom.atom_embedding_list.1.weight\n",
      "encoder_atom.atom_embedding_list.2.weight\n",
      "encoder_atom.atom_embedding_list.3.weight\n",
      "encoder_atom.atom_embedding_list.4.weight\n",
      "encoder_atom.atom_embedding_list.5.weight\n",
      "encoder_atom.atom_embedding_list.6.weight\n",
      "encoder_atom.atom_embedding_list.7.weight\n",
      "encoder_atom.atom_embedding_list.8.weight\n",
      "encoder_atom.atom_embedding_list.9.weight\n",
      "encoder_atom.atom_embedding_list.10.weight\n",
      "encoder_atom.atom_embedding_list.11.weight\n",
      "encoder_atom.atom_embedding_list.12.weight\n",
      "encoder_atom.atom_embedding_list.13.weight\n",
      "encoder_atom.atom_embedding_list.14.weight\n",
      "encoder_atom.atom_embedding_list.15.weight\n",
      "encoder_atom.atom_embedding_list.16.weight\n",
      "encoder_atom.atom_embedding_list.17.weight\n",
      "encoder_atom.atom_embedding_list.18.weight\n",
      "encoder_atom.atom_embedding_list.19.weight\n",
      "encoder_atom.atom_embedding_list.20.weight\n",
      "encoder_atom.atom_embedding_list.21.weight\n",
      "encoder.weight\n",
      "encoder.bias\n",
      "local_gnn.convs.0.nn.linears.0.weight\n",
      "local_gnn.convs.0.nn.linears.0.bias\n",
      "local_gnn.convs.0.nn.linears.1.weight\n",
      "local_gnn.convs.0.nn.linears.1.bias\n",
      "local_gnn.convs.0.nn.norms.0.weight\n",
      "local_gnn.convs.0.nn.norms.0.bias\n",
      "local_gnn.convs.0.nn.norms.1.weight\n",
      "local_gnn.convs.0.nn.norms.1.bias\n",
      "local_gnn.convs.1.nn.linears.0.weight\n",
      "local_gnn.convs.1.nn.linears.0.bias\n",
      "local_gnn.convs.1.nn.linears.1.weight\n",
      "local_gnn.convs.1.nn.linears.1.bias\n",
      "local_gnn.convs.1.nn.norms.0.weight\n",
      "local_gnn.convs.1.nn.norms.0.bias\n",
      "local_gnn.convs.1.nn.norms.1.weight\n",
      "local_gnn.convs.1.nn.norms.1.bias\n",
      "global_gnn.convs.0.nn.linears.0.weight\n",
      "global_gnn.convs.0.nn.linears.0.bias\n",
      "global_gnn.convs.0.nn.linears.1.weight\n",
      "global_gnn.convs.0.nn.linears.1.bias\n",
      "global_gnn.convs.0.nn.norms.0.weight\n",
      "global_gnn.convs.0.nn.norms.0.bias\n",
      "global_gnn.convs.0.nn.norms.1.weight\n",
      "global_gnn.convs.0.nn.norms.1.bias\n",
      "global_gnn.convs.1.nn.linears.0.weight\n",
      "global_gnn.convs.1.nn.linears.0.bias\n",
      "global_gnn.convs.1.nn.linears.1.weight\n",
      "global_gnn.convs.1.nn.linears.1.bias\n",
      "global_gnn.convs.1.nn.norms.0.weight\n",
      "global_gnn.convs.1.nn.norms.0.bias\n",
      "global_gnn.convs.1.nn.norms.1.weight\n",
      "global_gnn.convs.1.nn.norms.1.bias\n",
      "mine.T.1.weight\n",
      "mine.T.1.bias\n",
      "mine.T.3.weight\n",
      "mine.T.3.bias\n",
      "mine.T.5.weight\n",
      "mine.T.5.bias\n",
      "bn_edge.weight\n",
      "bn_edge.bias\n",
      "bn_node.weight\n",
      "bn_node.bias\n",
      "global_linear_out1.weight\n",
      "global_linear_out1.bias\n",
      "local_linear_out1.weight\n",
      "local_linear_out1.bias\n",
      "bn_linear0_loc.weight\n",
      "bn_linear0_loc.bias\n",
      "bn_linear1_loc.weight\n",
      "bn_linear1_loc.bias\n",
      "bn_after_summation.weight\n",
      "bn_after_summation.bias\n",
      "linear_out2.0.weight\n",
      "linear_out2.0.bias\n",
      "bn_linear2.weight\n",
      "bn_linear2.bias\n",
      "clf.weight\n",
      "clf.bias\n",
      "emb.weight\n",
      "emb.bias\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "round number: 1\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:38:43,333 (laplacian_with_domain_separation_KLD_client:140)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_total': 2560, 'train_loss': 3178.452629, 'train_imp_ratio': -4585.219279, 'train_avg_loss': 1.241583}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "round number: 1\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:38:58,546 (laplacian_with_domain_separation_KLD_client:140)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_total': 7208, 'train_loss': 34472.212246, 'train_imp_ratio': -417.417894, 'train_avg_loss': 4.782493}}\n",
      "2023-01-14 16:38:58,603 (laplacian_server:160)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2023-01-14 16:38:58,605 (laplacian_server:167)INFO: ----------- Starting a new training round (Round #1) -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff loss: 0.0\n",
      "round number: 1\n",
      "round number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:38:58,719 (client:410)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_total': 113, 'test_loss': 271.440764, 'test_imp_ratio': -159.886466, 'test_avg_loss': 2.402131, 'val_total': 113, 'val_loss': 264.593769, 'val_imp_ratio': -153.330922, 'val_avg_loss': 2.341538}}\n",
      "2023-01-14 16:38:58,720 (monitor:513)INFO: current_best=-153.330922, should_save=True\n",
      "2023-01-14 16:38:58,721 (client:431)INFO: Client: #1, val_imp_ratio: -153.330922. model saved at exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834/model1.pth\n",
      "2023-01-14 16:38:58,813 (client:410)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'test_total': 64, 'test_loss': 16.964237, 'test_imp_ratio': -900.249836, 'test_avg_loss': 0.265066, 'val_total': 63, 'val_loss': 19.477709, 'val_imp_ratio': -1066.678825, 'val_avg_loss': 0.30917}}\n",
      "2023-01-14 16:38:58,814 (monitor:513)INFO: current_best=-1066.678825, should_save=True\n",
      "2023-01-14 16:38:58,815 (client:431)INFO: Client: #2, val_imp_ratio: -1066.678825. model saved at exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834/model2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round number: 1\n",
      "round number: 1\n",
      "round number: 1\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:39:13,982 (laplacian_with_domain_separation_KLD_client:140)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_total': 7208, 'train_loss': 19779.11379, 'train_imp_ratio': -196.878722, 'train_avg_loss': 2.74405}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "round number: 1\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:39:18,968 (laplacian_with_domain_separation_KLD_client:140)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_total': 2560, 'train_loss': 983.880112, 'train_imp_ratio': -1350.295043, 'train_avg_loss': 0.384328}}\n",
      "2023-01-14 16:39:18,971 (server:480)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_total': 88.5, 'test_loss': 144.2025, 'test_imp_ratio': -530.068151, 'test_avg_loss': 1.333598, 'val_total': 88.0, 'val_loss': 142.035739, 'val_imp_ratio': -610.004873, 'val_avg_loss': 1.325354}}\n",
      "2023-01-14 16:39:18,971 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-14 16:39:18,972 (monitor:513)INFO: current_best=-610.004873, should_save=True\n",
      "2023-01-14 16:39:19,038 (laplacian_server:160)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2023-01-14 16:39:19,040 (laplacian_server:167)INFO: ----------- Starting a new training round (Round #2) -------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff loss: 0.0\n",
      "round number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 16:39:19,164 (client:410)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_total': 113, 'test_loss': 240.696835, 'test_imp_ratio': -130.451199, 'test_avg_loss': 2.13006, 'val_total': 113, 'val_loss': 162.524177, 'val_imp_ratio': -55.606092, 'val_avg_loss': 1.438267}}\n",
      "2023-01-14 16:39:19,165 (monitor:513)INFO: current_best=-55.606092, should_save=True\n",
      "2023-01-14 16:39:19,166 (client:431)INFO: Client: #1, val_imp_ratio: -55.606092. model saved at exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834/model1.pth\n",
      "2023-01-14 16:39:19,298 (client:410)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'test_total': 64, 'test_loss': 10.616761, 'test_imp_ratio': -525.988223, 'test_avg_loss': 0.165887, 'val_total': 63, 'val_loss': 16.351588, 'val_imp_ratio': -879.430383, 'val_avg_loss': 0.259549}}\n",
      "2023-01-14 16:39:19,299 (monitor:513)INFO: current_best=-879.430383, should_save=True\n",
      "2023-01-14 16:39:19,300 (client:431)INFO: Client: #2, val_imp_ratio: -879.430383. model saved at exp/test_dir/test_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230114163834/model2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round number: 1\n",
      "round number: 1\n",
      "round number: 1\n",
      "round number: 2\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: -0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n",
      "diff loss: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 9\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfederatedscope\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontrib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mworkers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlaplacian_server\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LaplacianServer\n\u001B[1;32m      4\u001B[0m Fed_runner \u001B[38;5;241m=\u001B[39m FedRunner(data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m      5\u001B[0m                        server_class\u001B[38;5;241m=\u001B[39mLaplacianServer,\n\u001B[1;32m      6\u001B[0m                        client_class\u001B[38;5;241m=\u001B[39mLaplacianDomainSeparation_KLD_Client,\n\u001B[1;32m      7\u001B[0m                        config\u001B[38;5;241m=\u001B[39mcfg\u001B[38;5;241m.\u001B[39mclone(),\n\u001B[1;32m      8\u001B[0m                        client_config\u001B[38;5;241m=\u001B[39mclient_cfg)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mFed_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:186\u001B[0m, in \u001B[0;36mFedRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    185\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mfinish_fed_runner(fl_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mbest_results\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:325\u001B[0m, in \u001B[0;36mFedRunner._handle_msg\u001B[0;34m(self, msg, rcv)\u001B[0m\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(download_bytes)\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 325\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m[\u001B[49m\u001B[43meach_receiver\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_handlers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[each_receiver]\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(\n\u001B[1;32m    327\u001B[0m         download_bytes)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/workers/laplacian_with_domain_separation_KLD_client.py:131\u001B[0m, in \u001B[0;36mLaplacianDomainSeparation_KLD_Client.callback_funcs_for_model_para\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m    126\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    127\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Normal FL Mode] Client #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mID\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has been locally \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mearly stopped. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe next FL update may result in negative effect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mlocal_converged()\n\u001B[0;32m--> 131\u001B[0m sample_size, model_para_all, omega_set, results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39mshare_local_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \\\n\u001B[1;32m    133\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39monline_aggr:\n\u001B[1;32m    134\u001B[0m     model_para_all \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(model_para_all)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/auxiliaries/decorators.py:28\u001B[0m, in \u001B[0;36muse_diff_laplacian.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     before_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m num_samples_train, model_para, omega, result_metric \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     after_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_KLD.py:212\u001B[0m, in \u001B[0;36mLaplacianDomainSeparationKLDTrainer.train\u001B[0;34m(self, state, target_data_split_name, hooks_set)\u001B[0m\n\u001B[1;32m    208\u001B[0m hooks_set \u001B[38;5;241m=\u001B[39m hooks_set \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks_in_train\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcheck_data_split(target_data_split_name)\n\u001B[0;32m--> 212\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_routine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_data_split_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_round \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39malpha, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_para(\n\u001B[1;32m    216\u001B[0m ), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_omega_para(), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39meval_metrics\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/trainers/trainer.py:279\u001B[0m, in \u001B[0;36mTrainer._run_routine\u001B[0;34m(self, mode, hooks_set, dataset_name)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcur_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 279\u001B[0m         \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    281\u001B[0m     hook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_KLD.py:194\u001B[0m, in \u001B[0;36mLaplacianDomainSeparationKLDTrainer._hook_on_batch_backward\u001B[0;34m(self, ctx)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ctx\u001B[38;5;241m.\u001B[39mgrad_clip \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    192\u001B[0m     torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(ctx\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mparameters(),\n\u001B[1;32m    193\u001B[0m                                    ctx\u001B[38;5;241m.\u001B[39mgrad_clip)\n\u001B[0;32m--> 194\u001B[0m prox_loss_change \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_prox_loss_change\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    195\u001B[0m ctx\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, param \u001B[38;5;129;01min\u001B[39;00m prox_loss_change\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_KLD.py:234\u001B[0m, in \u001B[0;36mLaplacianDomainSeparationKLDTrainer.get_prox_loss_change\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    232\u001B[0m lam \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39mlam\n\u001B[1;32m    233\u001B[0m lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mtrain\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mlr\n\u001B[0;32m--> 234\u001B[0m model_params \u001B[38;5;241m=\u001B[39m \u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_mu\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;66;03m# print(\"model params: \")\u001B[39;00m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m model_params:\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;66;03m# print(key)\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.9/copy.py:146\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/usr/lib/python3.9/copy.py:230\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    228\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 230\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m/usr/lib/python3.9/copy.py:153\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    151\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 153\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/_tensor.py:149\u001B[0m, in \u001B[0;36mTensor.__deepcopy__\u001B[0;34m(self, memo)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(new_tensor) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe default implementation of __deepcopy__() for non-wrapper subclasses \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    144\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monly works for subclass types that implement new_empty() and for which \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthat function returns another instance of the same subclass. You should \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    146\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meither properly implement new_empty() for your subclass or override \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    147\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__() if it is intended behavior for new_empty() to return \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    148\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man instance of a different type.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 149\u001B[0m new_tensor\u001B[38;5;241m.\u001B[39mset_(new_storage, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstorage_offset(), \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride())\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_conj():\n\u001B[1;32m    151\u001B[0m     new_tensor \u001B[38;5;241m=\u001B[39m new_tensor\u001B[38;5;241m.\u001B[39mconj_physical()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from federatedscope.contrib.workers.laplacian_with_domain_separation_KLD_client import LaplacianDomainSeparation_KLD_Client\n",
    "from federatedscope.contrib.workers.laplacian_server import LaplacianServer\n",
    "\n",
    "Fed_runner = FedRunner(data=data,\n",
    "                       server_class=LaplacianServer,\n",
    "                       client_class=LaplacianDomainSeparation_KLD_Client,\n",
    "                       config=cfg.clone(),\n",
    "                       client_config=client_cfg)\n",
    "Fed_runner.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: {},\n 2: {'train': <torch_geometric.loader.dataloader.DataLoader at 0x7f1e1de251c0>,\n  'val': <torch_geometric.loader.dataloader.DataLoader at 0x7f1e9d72b040>,\n  'test': <torch_geometric.loader.dataloader.DataLoader at 0x7f1ec872d850>,\n  'num_label': 0}}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
