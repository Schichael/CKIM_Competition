{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "# The train split of client 1\n",
    "cl_num = 0\n",
    "train_data_client = torch.load(f'./data/graph_dt/processed/{cl_num}/train.pt')\n",
    "val_data_client = torch.load(f'./data/graph_dt/processed/{cl_num}/val.pt')\n",
    "test_data_client = torch.load(f'./data/graph_dt/processed/{cl_num}/test.pt')\n",
    "print(len(train_data_client) + len(val_data_client) + len(test_data_client))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1: ESOL(12)\n",
    "2: FreeSolv(11)\n",
    "3: Lipophilicity (13)\n",
    "4: BACE (7)\n",
    "5: BBBP (8)\n",
    "6: ClinTox (6)\n",
    "7: MUTAG (1)\n",
    "8: PTC_MR (3)\n",
    "9: PTC_MM (2)\n",
    "10:  PTC_FM (4)\n",
    "11: PTC_FR (5) Zu viele Datem: 1440\n",
    "12: NCI109 (10)\n",
    "13: NCI1 (9)\n",
    "14: alchemy_full (15)\n",
    "15: ZINC_full (16)\n",
    "16: QM9 (14) (zu viele Daten? 130831)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(train_data_client)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n",
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/logger.py:23: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n",
      "2022-12-25 15:29:54,201 (trainer_builder:11)WARNING: No module named 'federatedscope.contrib.optimizer' in `federatedscope.contrib.trainer`, some modules are not available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# from federatedscope.core.cmd_args import parse_args\n",
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\n",
    "from federatedscope.core.configs.config import global_cfg\n",
    "from federatedscope.core.fed_runner import FedRunner\n",
    "from yacs.config import CfgNode\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "if os.environ.get('https_proxy'):\n",
    "    del os.environ['https_proxy']\n",
    "if os.environ.get('http_proxy'):\n",
    "    del os.environ['http_proxy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def train(client, lr):\n",
    "    cfg_file = 'scripts/B-FHTL_exp_scripts/Graph-DT/isolated.yaml'\n",
    "    cfg_client = 'scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client_isolated.yaml'\n",
    "    #'scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client.yaml'\n",
    "\n",
    "    init_cfg = global_cfg.clone()\n",
    "    init_cfg.merge_from_file(cfg_file)\n",
    "\n",
    "    # init_cfg.data.subdirectory = 'graph_dt_backup/processed'\n",
    "    # init_cfg.merge_from_list(args.opts)\n",
    "    init_cfg.data.client = client\n",
    "    init_cfg.train.optimizer.lr = lr\n",
    "    update_logger(init_cfg)\n",
    "    setup_seed(init_cfg.seed)\n",
    "\n",
    "    # federated dataset might change the number of clients\n",
    "    # thus, we allow the creation procedure of dataset to modify the global cfg object\n",
    "    data, modified_cfg = get_data(config=init_cfg.clone())\n",
    "    init_cfg.merge_from_other_cfg(modified_cfg)\n",
    "\n",
    "    init_cfg.freeze()\n",
    "\n",
    "    # allow different settings for different clients\n",
    "    # cfg_client.merge_from_file(args.cfg_client)\n",
    "    if cfg_client is None:\n",
    "        cfg_client = None\n",
    "    else:\n",
    "        cfg_client = CfgNode.load_cfg(open(cfg_client, 'r')).clone()\n",
    "    runner = FedRunner(data=data,\n",
    "                   server_class=get_server_cls(init_cfg),\n",
    "                   client_class=get_client_cls(init_cfg),\n",
    "                   config=init_cfg.clone(),\n",
    "                   client_config=cfg_client)\n",
    "    _ = runner.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 15:29:54,228 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:29:54,229 (utils:130)INFO: the current machine is at 127.0.1.1\n",
      "2022-12-25 15:29:54,230 (utils:132)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2022-12-25 15:29:54,231 (utils:133)INFO: the output dir is exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225152954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: 3,\tlr: 0.01\n",
      "training run: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 15:29:57,667 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:29:57,668 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:29:57,676 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 3\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.0\n",
      "  best_res_update_round_wise_key: val_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: []\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 0\n",
      "  task: graph\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225152954\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "2022-12-25 15:29:57,771 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-12-25 15:29:57,773 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:29:57,773 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:29:57,782 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 3\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.954\n",
      "  best_res_update_round_wise_key: val_avg_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['loss']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225152954\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-25 15:29:57,792 (fed_runner:304)INFO: Client 1 has been set up ... \n",
      "2022-12-25 15:29:57,793 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-12-25 15:29:57,794 (trainer:332)INFO: Num of original para names: 58.\n",
      "2022-12-25 15:29:57,794 (trainer:333)INFO: Num of original trainable para names: 44.\n",
      "2022-12-25 15:29:57,795 (trainer:335)INFO: Num of preserved para names in local update: 0. \n",
      "Preserved para names in local update: set().\n",
      "2022-12-25 15:29:57,795 (trainer:339)INFO: Num of filtered para names in local update: 58. \n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.21.weight', 'gnn.convs.1.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.13.weight', 'encoder_atom.atom_embedding_list.15.weight', 'encoder_atom.atom_embedding_list.10.weight', 'gnn.convs.0.nn.norms.0.weight', 'linear.0.bias', 'gnn.convs.0.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.1.weight', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.running_mean', 'encoder.weight', 'gnn.convs.1.eps', 'encoder_atom.atom_embedding_list.3.weight', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.eps', 'encoder_atom.atom_embedding_list.4.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.18.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.9.weight', 'gnn.convs.1.nn.norms.0.bias', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.17.weight', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.1.running_mean', 'encoder_atom.atom_embedding_list.11.weight', 'linear.0.weight', 'encoder.bias', 'encoder_atom.atom_embedding_list.16.weight', 'encoder_atom.atom_embedding_list.19.weight', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.1.nn.linears.1.bias', 'gnn.convs.0.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.14.weight', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.5.weight', 'gnn.convs.0.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.20.weight', 'gnn.convs.1.nn.norms.0.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.12.weight', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.0.nn.linears.1.bias'}.\n",
      "2022-12-25 15:29:57,796 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-12-25 15:29:57,801 (server:644)INFO: ----------- Starting training (Round #0) -------------\n",
      "2022-12-25 15:29:59,570 (client:260)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 2.721796, 'train_loss': 9145.233189, 'train_total': 3360}}\n",
      "2022-12-25 15:29:59,571 (server:323)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-12-25 15:29:59,571 (server:330)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-12-25 15:29:59,626 (client:415)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_avg_loss': 1.30783, 'test_loss': 549.288727, 'test_total': 420, 'val_avg_loss': 1.253839, 'val_loss': 526.612328, 'val_total': 420}}\n",
      "2022-12-25 15:29:59,627 (monitor:940)INFO: Current best: {'test_avg_loss': 1.30783, 'test_loss': 549.288727, 'test_total': 420, 'val_avg_loss': 1.253839, 'val_loss': 526.612328, 'val_total': 420}\n",
      "2022-12-25 15:29:59,977 (client:260)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.392491, 'train_loss': 4678.768585, 'train_total': 3360}}\n",
      "2022-12-25 15:29:59,979 (server:496)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_avg_loss': 1.30783, 'test_loss': 549.288727, 'test_total': 420.0, 'val_avg_loss': 1.253839, 'val_loss': 526.612328, 'val_total': 420.0}}\n",
      "2022-12-25 15:29:59,979 (monitor:940)INFO: Current best: {'test_avg_loss': [1.30783], 'test_loss': [549.288727], 'test_total': [420.0], 'val_avg_loss': [1.253839], 'val_loss': [526.612328], 'val_total': [420.0]}\n",
      "2022-12-25 15:29:59,981 (monitor:940)INFO: Current best: {'test_avg_loss': 1.30783, 'test_loss': 549.288727, 'test_total': 420.0, 'val_avg_loss': 1.253839, 'val_loss': 526.612328, 'val_total': 420.0}\n",
      "2022-12-25 15:29:59,983 (server:323)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-12-25 15:29:59,984 (server:330)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-12-25 15:30:00,049 (client:415)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420}}\n",
      "2022-12-25 15:30:00,050 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420}\n",
      "2022-12-25 15:30:00,406 (client:260)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.33228, 'train_loss': 4476.462337, 'train_total': 3360}}\n",
      "2022-12-25 15:30:00,408 (server:496)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:00,409 (monitor:940)INFO: Current best: {'test_avg_loss': [1.272722], 'test_loss': [534.543234], 'test_total': [420.0], 'val_avg_loss': [1.202148], 'val_loss': [504.902334], 'val_total': [420.0]}\n",
      "2022-12-25 15:30:00,410 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:00,411 (server:323)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-12-25 15:30:00,412 (server:330)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-12-25 15:30:00,475 (client:415)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_avg_loss': 1.578169, 'test_loss': 662.831183, 'test_total': 420, 'val_avg_loss': 1.485432, 'val_loss': 623.881478, 'val_total': 420}}\n",
      "2022-12-25 15:30:00,476 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420}\n",
      "2022-12-25 15:30:00,821 (client:260)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.308487, 'train_loss': 4396.517788, 'train_total': 3360}}\n",
      "2022-12-25 15:30:00,822 (server:496)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_avg_loss': 1.578169, 'test_loss': 662.831183, 'test_total': 420.0, 'val_avg_loss': 1.485432, 'val_loss': 623.881478, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:00,823 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:00,824 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:00,826 (server:323)INFO: Server #0: Starting evaluation at the end of round 3.\n",
      "2022-12-25 15:30:00,827 (server:330)INFO: ----------- Starting a new training round (Round #4) -------------\n",
      "2022-12-25 15:30:00,892 (client:415)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'test_avg_loss': 1.542199, 'test_loss': 647.723429, 'test_total': 420, 'val_avg_loss': 1.44517, 'val_loss': 606.971478, 'val_total': 420}}\n",
      "2022-12-25 15:30:00,893 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420}\n",
      "2022-12-25 15:30:01,225 (client:260)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.324268, 'train_loss': 4449.540081, 'train_total': 3360}}\n",
      "2022-12-25 15:30:01,226 (server:496)INFO: {'Role': 'Server #', 'Round': 4, 'Results_avg': {'test_avg_loss': 1.542199, 'test_loss': 647.723429, 'test_total': 420.0, 'val_avg_loss': 1.44517, 'val_loss': 606.971478, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:01,227 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:01,228 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:01,229 (server:323)INFO: Server #0: Starting evaluation at the end of round 4.\n",
      "2022-12-25 15:30:01,230 (server:330)INFO: ----------- Starting a new training round (Round #5) -------------\n",
      "2022-12-25 15:30:01,298 (client:415)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'test_avg_loss': 1.326583, 'test_loss': 557.164707, 'test_total': 420, 'val_avg_loss': 1.229989, 'val_loss': 516.595193, 'val_total': 420}}\n",
      "2022-12-25 15:30:01,299 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420}\n",
      "2022-12-25 15:30:01,302 (client:239)INFO: [Local/Global mode] Client #1 has been early stopped, we will skip the local training\n",
      "2022-12-25 15:30:01,303 (server:496)INFO: {'Role': 'Server #', 'Round': 5, 'Results_avg': {'test_avg_loss': 1.326583, 'test_loss': 557.164707, 'test_total': 420.0, 'val_avg_loss': 1.229989, 'val_loss': 516.595193, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:01,304 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:01,305 (monitor:940)INFO: Current best: {'test_avg_loss': 1.272722, 'test_loss': 534.543234, 'test_total': 420.0, 'val_avg_loss': 1.202148, 'val_loss': 504.902334, 'val_total': 420.0}\n",
      "2022-12-25 15:30:01,306 (server:395)INFO: Server #0: Final evaluation is finished! Starting merging results.\n",
      "2022-12-25 15:30:01,306 (server:425)INFO: {'Role': 'Server #', 'Round': 'Final', 'Results_raw': {'client_best_individual': {'val_loss': 504.902334}, 'client_summarized_avg': {'val_loss': 504.902334}}}\n",
      "2022-12-25 15:30:01,307 (server:446)INFO: {'Role': 'Client #1', 'Round': 10001, 'Results_raw': {'test_avg_loss': 1.326583, 'test_loss': 557.164707, 'test_total': 420, 'val_avg_loss': 1.229989, 'val_loss': 516.595193, 'val_total': 420}}\n",
      "2022-12-25 15:30:01,308 (monitor:125)INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 0.05896, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 720, 'total_download_bytes': 4392, 'global_convergence_round': 5, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0.05892, 'local_convergence_time_minutes': 0}\n",
      "2022-12-25 15:30:01,311 (client:448)INFO: ================= client 1 received finish message =================\n",
      "2022-12-25 15:30:01,313 (monitor:125)INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 0.058692, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 5440, 'total_download_bytes': 720, 'global_convergence_round': 5, 'local_convergence_round': 5, 'global_convergence_time_minutes': 0.058655, 'local_convergence_time_minutes': 0.05852}\n",
      "2022-12-25 15:30:01,314 (monitor:286)INFO: We will compress the file eval_results.raw into a .gz file, and delete the old one\n",
      "2022-12-25 15:30:01,317 (monitor:199)INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 0.058826, 'sys_avg/total_model_size': '148.66K', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '3.01K', 'sys_avg/total_download_bytes': '2.5K', 'sys_avg/global_convergence_round': 5.0, 'sys_avg/local_convergence_round': 2.5, 'sys_avg/global_convergence_time_minutes': 0.058787, 'sys_avg/local_convergence_time_minutes': 0.02926})\n",
      "2022-12-25 15:30:01,318 (monitor:202)INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.000134, 'sys_std/total_model_size': '148.66K', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '2.3K', 'sys_std/total_download_bytes': '1.79K', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 2.5, 'sys_std/global_convergence_time_minutes': 0.000133, 'sys_std/local_convergence_time_minutes': 0.02926})\n",
      "2022-12-25 15:30:01,329 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:01,331 (utils:130)INFO: the current machine is at 127.0.1.1\n",
      "2022-12-25 15:30:01,332 (utils:132)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2022-12-25 15:30:01,333 (utils:133)INFO: the output dir is exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225153001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training run: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 15:30:04,967 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:04,968 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:04,987 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 3\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.0\n",
      "  best_res_update_round_wise_key: val_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: []\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 0\n",
      "  task: graph\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225153001\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-25 15:30:05,119 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-12-25 15:30:05,122 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:05,122 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:05,138 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 3\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.954\n",
      "  best_res_update_round_wise_key: val_avg_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['loss']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225153001\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-25 15:30:05,148 (fed_runner:304)INFO: Client 1 has been set up ... \n",
      "2022-12-25 15:30:05,149 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-12-25 15:30:05,150 (trainer:332)INFO: Num of original para names: 58.\n",
      "2022-12-25 15:30:05,150 (trainer:333)INFO: Num of original trainable para names: 44.\n",
      "2022-12-25 15:30:05,151 (trainer:335)INFO: Num of preserved para names in local update: 0. \n",
      "Preserved para names in local update: set().\n",
      "2022-12-25 15:30:05,151 (trainer:339)INFO: Num of filtered para names in local update: 58. \n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.21.weight', 'gnn.convs.1.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.13.weight', 'encoder_atom.atom_embedding_list.15.weight', 'encoder_atom.atom_embedding_list.10.weight', 'gnn.convs.0.nn.norms.0.weight', 'linear.0.bias', 'gnn.convs.0.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.1.weight', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.running_mean', 'encoder.weight', 'gnn.convs.1.eps', 'encoder_atom.atom_embedding_list.3.weight', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.eps', 'encoder_atom.atom_embedding_list.4.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.18.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.9.weight', 'gnn.convs.1.nn.norms.0.bias', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.17.weight', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.1.running_mean', 'encoder_atom.atom_embedding_list.11.weight', 'linear.0.weight', 'encoder.bias', 'encoder_atom.atom_embedding_list.16.weight', 'encoder_atom.atom_embedding_list.19.weight', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.1.nn.linears.1.bias', 'gnn.convs.0.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.14.weight', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.5.weight', 'gnn.convs.0.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.20.weight', 'gnn.convs.1.nn.norms.0.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.12.weight', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.0.nn.linears.1.bias'}.\n",
      "2022-12-25 15:30:05,152 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-12-25 15:30:05,153 (server:644)INFO: ----------- Starting training (Round #0) -------------\n",
      "2022-12-25 15:30:05,523 (client:260)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 2.721815, 'train_loss': 9145.298126, 'train_total': 3360}}\n",
      "2022-12-25 15:30:05,525 (server:323)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-12-25 15:30:05,526 (server:330)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-12-25 15:30:05,597 (client:415)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_avg_loss': 1.300573, 'test_loss': 546.240475, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.20372, 'val_total': 420}}\n",
      "2022-12-25 15:30:05,598 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240475, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.20372, 'val_total': 420}\n",
      "2022-12-25 15:30:05,961 (client:260)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.389928, 'train_loss': 4670.15976, 'train_total': 3360}}\n",
      "2022-12-25 15:30:05,962 (server:496)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_avg_loss': 1.300573, 'test_loss': 546.240475, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.20372, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:05,963 (monitor:940)INFO: Current best: {'test_avg_loss': [1.300573], 'test_loss': [546.240475], 'test_total': [420.0], 'val_avg_loss': [1.245723], 'val_loss': [523.20372], 'val_total': [420.0]}\n",
      "2022-12-25 15:30:05,964 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240475, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.20372, 'val_total': 420.0}\n",
      "2022-12-25 15:30:05,966 (server:323)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-12-25 15:30:05,967 (server:330)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-12-25 15:30:06,035 (client:415)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420}}\n",
      "2022-12-25 15:30:06,036 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420}\n",
      "2022-12-25 15:30:06,443 (client:260)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.330501, 'train_loss': 4470.484982, 'train_total': 3360}}\n",
      "2022-12-25 15:30:06,445 (server:496)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:06,446 (monitor:940)INFO: Current best: {'test_avg_loss': [1.306266], 'test_loss': [548.631882], 'test_total': [420.0], 'val_avg_loss': [1.227144], 'val_loss': [515.400597], 'val_total': [420.0]}\n",
      "2022-12-25 15:30:06,448 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:06,450 (server:323)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-12-25 15:30:06,451 (server:330)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-12-25 15:30:06,512 (client:415)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_avg_loss': 1.291235, 'test_loss': 542.318495, 'test_total': 420, 'val_avg_loss': 1.245513, 'val_loss': 523.115604, 'val_total': 420}}\n",
      "2022-12-25 15:30:06,513 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420}\n",
      "2022-12-25 15:30:06,848 (client:260)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.290369, 'train_loss': 4335.639858, 'train_total': 3360}}\n",
      "2022-12-25 15:30:06,849 (server:496)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_avg_loss': 1.291235, 'test_loss': 542.318495, 'test_total': 420.0, 'val_avg_loss': 1.245513, 'val_loss': 523.115604, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:06,850 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:06,851 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:06,853 (server:323)INFO: Server #0: Starting evaluation at the end of round 3.\n",
      "2022-12-25 15:30:06,853 (server:330)INFO: ----------- Starting a new training round (Round #4) -------------\n",
      "2022-12-25 15:30:06,911 (client:415)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'test_avg_loss': 1.457019, 'test_loss': 611.948066, 'test_total': 420, 'val_avg_loss': 1.371254, 'val_loss': 575.92688, 'val_total': 420}}\n",
      "2022-12-25 15:30:06,912 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420}\n",
      "2022-12-25 15:30:07,230 (client:260)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.293233, 'train_loss': 4345.262379, 'train_total': 3360}}\n",
      "2022-12-25 15:30:07,232 (server:496)INFO: {'Role': 'Server #', 'Round': 4, 'Results_avg': {'test_avg_loss': 1.457019, 'test_loss': 611.948066, 'test_total': 420.0, 'val_avg_loss': 1.371254, 'val_loss': 575.92688, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:07,234 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:07,236 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:07,238 (server:323)INFO: Server #0: Starting evaluation at the end of round 4.\n",
      "2022-12-25 15:30:07,239 (server:330)INFO: ----------- Starting a new training round (Round #5) -------------\n",
      "2022-12-25 15:30:07,299 (client:415)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'test_avg_loss': 1.535949, 'test_loss': 645.098426, 'test_total': 420, 'val_avg_loss': 1.439078, 'val_loss': 604.412865, 'val_total': 420}}\n",
      "2022-12-25 15:30:07,300 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420}\n",
      "2022-12-25 15:30:07,302 (client:239)INFO: [Local/Global mode] Client #1 has been early stopped, we will skip the local training\n",
      "2022-12-25 15:30:07,304 (server:496)INFO: {'Role': 'Server #', 'Round': 5, 'Results_avg': {'test_avg_loss': 1.535949, 'test_loss': 645.098426, 'test_total': 420.0, 'val_avg_loss': 1.439078, 'val_loss': 604.412865, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:07,305 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:07,307 (monitor:940)INFO: Current best: {'test_avg_loss': 1.306266, 'test_loss': 548.631882, 'test_total': 420.0, 'val_avg_loss': 1.227144, 'val_loss': 515.400597, 'val_total': 420.0}\n",
      "2022-12-25 15:30:07,308 (server:395)INFO: Server #0: Final evaluation is finished! Starting merging results.\n",
      "2022-12-25 15:30:07,309 (server:425)INFO: {'Role': 'Server #', 'Round': 'Final', 'Results_raw': {'client_best_individual': {'val_loss': 515.400597}, 'client_summarized_avg': {'val_loss': 515.400597}}}\n",
      "2022-12-25 15:30:07,310 (server:446)INFO: {'Role': 'Client #1', 'Round': 10001, 'Results_raw': {'test_avg_loss': 1.535949, 'test_loss': 645.098426, 'test_total': 420, 'val_avg_loss': 1.439078, 'val_loss': 604.412865, 'val_total': 420}}\n",
      "2022-12-25 15:30:07,312 (monitor:125)INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 0.036557, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 720, 'total_download_bytes': 4392, 'global_convergence_round': 5, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0.03649, 'local_convergence_time_minutes': 0}\n",
      "2022-12-25 15:30:07,315 (client:448)INFO: ================= client 1 received finish message =================\n",
      "2022-12-25 15:30:07,317 (monitor:125)INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 0.036153, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 5440, 'total_download_bytes': 720, 'global_convergence_round': 5, 'local_convergence_round': 5, 'global_convergence_time_minutes': 0.03611, 'local_convergence_time_minutes': 0.035925}\n",
      "2022-12-25 15:30:07,318 (monitor:286)INFO: We will compress the file eval_results.raw into a .gz file, and delete the old one\n",
      "2022-12-25 15:30:07,320 (monitor:199)INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 0.036355, 'sys_avg/total_model_size': '148.66K', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '3.01K', 'sys_avg/total_download_bytes': '2.5K', 'sys_avg/global_convergence_round': 5.0, 'sys_avg/local_convergence_round': 2.5, 'sys_avg/global_convergence_time_minutes': 0.0363, 'sys_avg/local_convergence_time_minutes': 0.017963})\n",
      "2022-12-25 15:30:07,321 (monitor:202)INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.000202, 'sys_std/total_model_size': '148.66K', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '2.3K', 'sys_std/total_download_bytes': '1.79K', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 2.5, 'sys_std/global_convergence_time_minutes': 0.00019, 'sys_std/local_convergence_time_minutes': 0.017963})\n",
      "2022-12-25 15:30:07,330 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:07,332 (utils:130)INFO: the current machine is at 127.0.1.1\n",
      "2022-12-25 15:30:07,333 (utils:132)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2022-12-25 15:30:07,334 (utils:133)INFO: the output dir is exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225153007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training run: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 15:30:10,849 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:10,850 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:10,858 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 3\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.0\n",
      "  best_res_update_round_wise_key: val_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: []\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 0\n",
      "  task: graph\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225153007\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-25 15:30:10,988 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-12-25 15:30:10,990 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:10,990 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-25 15:30:11,001 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 3\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.954\n",
      "  best_res_update_round_wise_key: val_avg_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['loss']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_3/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221225153007\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-25 15:30:11,012 (fed_runner:304)INFO: Client 1 has been set up ... \n",
      "2022-12-25 15:30:11,013 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-12-25 15:30:11,015 (trainer:332)INFO: Num of original para names: 58.\n",
      "2022-12-25 15:30:11,015 (trainer:333)INFO: Num of original trainable para names: 44.\n",
      "2022-12-25 15:30:11,016 (trainer:335)INFO: Num of preserved para names in local update: 0. \n",
      "Preserved para names in local update: set().\n",
      "2022-12-25 15:30:11,017 (trainer:339)INFO: Num of filtered para names in local update: 58. \n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.21.weight', 'gnn.convs.1.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.13.weight', 'encoder_atom.atom_embedding_list.15.weight', 'encoder_atom.atom_embedding_list.10.weight', 'gnn.convs.0.nn.norms.0.weight', 'linear.0.bias', 'gnn.convs.0.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.1.weight', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.running_mean', 'encoder.weight', 'gnn.convs.1.eps', 'encoder_atom.atom_embedding_list.3.weight', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.eps', 'encoder_atom.atom_embedding_list.4.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.18.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.9.weight', 'gnn.convs.1.nn.norms.0.bias', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.17.weight', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.1.running_mean', 'encoder_atom.atom_embedding_list.11.weight', 'linear.0.weight', 'encoder.bias', 'encoder_atom.atom_embedding_list.16.weight', 'encoder_atom.atom_embedding_list.19.weight', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.1.nn.linears.1.bias', 'gnn.convs.0.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.14.weight', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.5.weight', 'gnn.convs.0.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.20.weight', 'gnn.convs.1.nn.norms.0.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.12.weight', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.0.nn.linears.1.bias'}.\n",
      "2022-12-25 15:30:11,019 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-12-25 15:30:11,021 (server:644)INFO: ----------- Starting training (Round #0) -------------\n",
      "2022-12-25 15:30:11,355 (client:260)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 2.721815, 'train_loss': 9145.298199, 'train_total': 3360}}\n",
      "2022-12-25 15:30:11,356 (server:323)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-12-25 15:30:11,357 (server:330)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-12-25 15:30:11,409 (client:415)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420}}\n",
      "2022-12-25 15:30:11,410 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420}\n",
      "2022-12-25 15:30:11,771 (client:260)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.38792, 'train_loss': 4663.41264, 'train_total': 3360}}\n",
      "2022-12-25 15:30:11,773 (server:496)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:11,774 (monitor:940)INFO: Current best: {'test_avg_loss': [1.300573], 'test_loss': [546.240471], 'test_total': [420.0], 'val_avg_loss': [1.245723], 'val_loss': [523.203714], 'val_total': [420.0]}\n",
      "2022-12-25 15:30:11,777 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:11,780 (server:323)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-12-25 15:30:11,781 (server:330)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-12-25 15:30:11,835 (client:415)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_avg_loss': 1.291517, 'test_loss': 542.436942, 'test_total': 420, 'val_avg_loss': 1.245909, 'val_loss': 523.281663, 'val_total': 420}}\n",
      "2022-12-25 15:30:11,836 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420}\n",
      "2022-12-25 15:30:12,166 (client:260)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.337055, 'train_loss': 4492.505589, 'train_total': 3360}}\n",
      "2022-12-25 15:30:12,168 (server:496)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_avg_loss': 1.291517, 'test_loss': 542.436942, 'test_total': 420.0, 'val_avg_loss': 1.245909, 'val_loss': 523.281663, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:12,169 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:12,170 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:12,172 (server:323)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-12-25 15:30:12,172 (server:330)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-12-25 15:30:12,222 (client:415)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_avg_loss': 1.382339, 'test_loss': 580.58247, 'test_total': 420, 'val_avg_loss': 1.316079, 'val_loss': 552.753181, 'val_total': 420}}\n",
      "2022-12-25 15:30:12,223 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420}\n",
      "2022-12-25 15:30:12,628 (client:260)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.264818, 'train_loss': 4249.787407, 'train_total': 3360}}\n",
      "2022-12-25 15:30:12,629 (server:496)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_avg_loss': 1.382339, 'test_loss': 580.58247, 'test_total': 420.0, 'val_avg_loss': 1.316079, 'val_loss': 552.753181, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:12,631 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:12,632 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:12,633 (server:323)INFO: Server #0: Starting evaluation at the end of round 3.\n",
      "2022-12-25 15:30:12,634 (server:330)INFO: ----------- Starting a new training round (Round #4) -------------\n",
      "2022-12-25 15:30:12,788 (client:415)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'test_avg_loss': 1.388562, 'test_loss': 583.195978, 'test_total': 420, 'val_avg_loss': 1.314122, 'val_loss': 551.931152, 'val_total': 420}}\n",
      "2022-12-25 15:30:12,789 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420}\n",
      "2022-12-25 15:30:12,791 (client:239)INFO: [Local/Global mode] Client #1 has been early stopped, we will skip the local training\n",
      "2022-12-25 15:30:12,792 (server:496)INFO: {'Role': 'Server #', 'Round': 4, 'Results_avg': {'test_avg_loss': 1.388562, 'test_loss': 583.195978, 'test_total': 420.0, 'val_avg_loss': 1.314122, 'val_loss': 551.931152, 'val_total': 420.0}}\n",
      "2022-12-25 15:30:12,793 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:12,795 (monitor:940)INFO: Current best: {'test_avg_loss': 1.300573, 'test_loss': 546.240471, 'test_total': 420.0, 'val_avg_loss': 1.245723, 'val_loss': 523.203714, 'val_total': 420.0}\n",
      "2022-12-25 15:30:12,796 (server:395)INFO: Server #0: Final evaluation is finished! Starting merging results.\n",
      "2022-12-25 15:30:12,797 (server:425)INFO: {'Role': 'Server #', 'Round': 'Final', 'Results_raw': {'client_best_individual': {'val_loss': 523.203714}, 'client_summarized_avg': {'val_loss': 523.203714}}}\n",
      "2022-12-25 15:30:12,798 (server:446)INFO: {'Role': 'Client #1', 'Round': 10001, 'Results_raw': {'test_avg_loss': 1.388562, 'test_loss': 583.195978, 'test_total': 420, 'val_avg_loss': 1.314122, 'val_loss': 551.931152, 'val_total': 420}}\n",
      "2022-12-25 15:30:12,800 (monitor:125)INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 0.030203, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 592, 'total_download_bytes': 3336, 'global_convergence_round': 4, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0.030138, 'local_convergence_time_minutes': 0}\n",
      "2022-12-25 15:30:12,803 (client:448)INFO: ================= client 1 received finish message =================\n",
      "2022-12-25 15:30:12,804 (monitor:125)INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 0.029877, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 4384, 'total_download_bytes': 592, 'global_convergence_round': 4, 'local_convergence_round': 4, 'global_convergence_time_minutes': 0.029844, 'local_convergence_time_minutes': 0.029664}\n",
      "2022-12-25 15:30:12,805 (monitor:286)INFO: We will compress the file eval_results.raw into a .gz file, and delete the old one\n",
      "2022-12-25 15:30:12,807 (monitor:199)INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 0.03004, 'sys_avg/total_model_size': '148.66K', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '2.43K', 'sys_avg/total_download_bytes': '1.92K', 'sys_avg/global_convergence_round': 4.0, 'sys_avg/local_convergence_round': 2.0, 'sys_avg/global_convergence_time_minutes': 0.029991, 'sys_avg/local_convergence_time_minutes': 0.014832})\n",
      "2022-12-25 15:30:12,809 (monitor:202)INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.000163, 'sys_std/total_model_size': '148.66K', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '1.85K', 'sys_std/total_download_bytes': '1.34K', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 2.0, 'sys_std/global_convergence_time_minutes': 0.000147, 'sys_std/local_convergence_time_minutes': 0.014832})\n"
     ]
    }
   ],
   "source": [
    "clients = range(3, 3+1)\n",
    "lrs = [0.01]\n",
    "num_trainings = 3\n",
    "for client in clients:\n",
    "    clear_output(wait=True)\n",
    "    for lr in lrs:\n",
    "        print(f\"Client: {client},\\tlr: {lr}\")\n",
    "        for i in range(num_trainings):\n",
    "            print(f\"training run: {i+1}\")\n",
    "            train(client, lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:47:21,690 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-22 19:47:21,692 (utils:130)INFO: the current machine is at 127.0.1.1\n",
      "2022-12-22 19:47:21,693 (utils:132)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2022-12-22 19:47:21,693 (utils:133)INFO: the output dir is exp/CLIENT_5/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221222194721\n",
      "2022-12-22 19:47:23,631 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-22 19:47:23,632 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-22 19:47:23,641 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 5\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 50\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.0\n",
      "  best_res_update_round_wise_key: val_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: []\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 0\n",
      "  task: graph\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_5/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221222194721\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n"
     ]
    }
   ],
   "source": [
    "cfg_file = 'scripts/B-FHTL_exp_scripts/Graph-DT/isolated.yaml'\n",
    "cfg_client = 'scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client_isolated.yaml'\n",
    "#'scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client.yaml'\n",
    "\n",
    "init_cfg = global_cfg.clone()\n",
    "init_cfg.merge_from_file(cfg_file)\n",
    "\n",
    "# init_cfg.data.subdirectory = 'graph_dt_backup/processed'\n",
    "# init_cfg.merge_from_list(args.opts)\n",
    "init_cfg.data.client = 5\n",
    "init_cfg.train.optgraph_level_defaultimizer.lr = 0.01\n",
    "update_logger(init_cfg)\n",
    "setup_seed(init_cfg.seed)\n",
    "\n",
    "# federated dataset might change the number of clients\n",
    "# thus, we allow the creation procedure of dataset to modify the global cfg object\n",
    "data, modified_cfg = get_data(config=init_cfg.clone())\n",
    "init_cfg.merge_from_other_cfg(modified_cfg)\n",
    "\n",
    "init_cfg.freeze()\n",
    "\n",
    "# allow different settings for different clients\n",
    "# cfg_client.merge_from_file(args.cfg_client)\n",
    "if cfg_client is None:\n",
    "    cfg_client = None\n",
    "else:\n",
    "    cfg_client = CfgNode.load_cfg(open(cfg_client, 'r')).clone()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "2022-12-22 19:47:23,727 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2022-12-22 19:47:23,731 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-22 19:47:23,732 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \n",
      "2022-12-22 19:47:23,747 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 1\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  client: 5\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 50\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  base: 0.766\n",
      "  best_res_update_round_wise_key: val_avg_loss\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['loss', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: local_gin_on_graph-dt_lr0.01_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 1\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: local\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 10000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/CLIENT_5/local_gin_on_graph-dt_lr0.01_lstep1_/sub_exp_20221222194721\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\n",
      "  local_update_steps: 1\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: graphminibatch_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2022-12-22 19:47:23,757 (fed_runner:304)INFO: Client 1 has been set up ... \n",
      "2022-12-22 19:47:23,758 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2022-12-22 19:47:23,759 (trainer:332)INFO: Num of original para names: 91.\n",
      "2022-12-22 19:47:23,760 (trainer:333)INFO: Num of original trainable para names: 62.\n",
      "2022-12-22 19:47:23,761 (trainer:335)INFO: Num of preserved para names in local update: 0. \n",
      "Preserved para names in local update: set().\n",
      "2022-12-22 19:47:23,761 (trainer:339)INFO: Num of filtered para names in local update: 91. \n",
      "Filtered para names in local update: {'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.1.nn.norms.0.bias', 'bn_edge.num_batches_tracked', 'gnn.convs.0.nn.norms.1.running_mean', 'linear_out1_loc.0.weight', 'gnn.convs.0.nn.norms.1.weight', 'bn_linear2.bias', 'linear_out2.0.weight', 'bn_linear1.weight', 'encoder.weight', 'gnn.convs.0.nn.norms.0.weight', 'bn_linear0.running_var', 'bn_linear1.num_batches_tracked', 'gnn.convs.0.lin.bias', 'encoder_atom.atom_embedding_list.10.weight', 'encoder_atom.atom_embedding_list.11.weight', 'bn_linear1.running_mean', 'emb.weight', 'bn_linear2.weight', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'encoder_atom.atom_embedding_list.14.weight', 'encoder_atom.atom_embedding_list.15.weight', 'bn_linear2.num_batches_tracked', 'gnn.convs.1.nn.norms.1.running_var', 'bn_edge.weight', 'bn_node.running_mean', 'gnn.convs.1.nn.linears.1.weight', 'bn_linear0.num_batches_tracked', 'encoder.bias', 'encoder_atom.atom_embedding_list.13.weight', 'gnn.convs.1.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.8.weight', 'gnn.convs.1.lin.weight', 'linear_out1_loc.0.bias', 'encoder_atom.atom_embedding_list.7.weight', 'linear_out2.0.bias', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_var', 'bn_linear0.weight', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.1.eps', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.0.running_mean', 'clf.weight', 'encoder_atom.atom_embedding_list.17.weight', 'bn_linear1.running_var', 'gnn.convs.1.nn.linears.1.bias', 'bn_linear0.bias', 'clf.bias', 'gnn.convs.0.lin.weight', 'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.3.weight', 'gnn.convs.1.nn.norms.0.running_var', 'encoder_atom.atom_embedding_list.21.weight', 'bn_linear1.bias', 'encoder_atom.atom_embedding_list.20.weight', 'bn_edge.running_var', 'gnn.convs.1.nn.norms.1.weight', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'bn_edge.running_mean', 'gnn.convs.0.nn.linears.1.weight', 'bn_node.num_batches_tracked', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.4.weight', 'encoder_atom.atom_embedding_list.12.weight', 'gnn.convs.1.nn.norms.0.weight', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'encoder_atom.atom_embedding_list.16.weight', 'bn_edge.bias', 'bn_node.bias', 'gnn.convs.0.nn.linears.1.bias', 'gnn.convs.0.nn.norms.0.bias', 'bn_node.running_var', 'emb.bias', 'gnn.convs.0.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.19.weight', 'encoder_atom.atom_embedding_list.1.weight', 'encoder_atom.atom_embedding_list.18.weight', 'gnn.convs.1.lin.bias', 'bn_node.weight', 'bn_linear0.running_mean', 'encoder_atom.atom_embedding_list.2.weight', 'gnn.convs.0.eps', 'encoder_atom.atom_embedding_list.5.weight', 'bn_linear2.running_mean', 'encoder_atom.atom_embedding_list.9.weight', 'bn_linear2.running_var'}.\n",
      "2022-12-22 19:47:23,762 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2022-12-22 19:47:23,769 (server:644)INFO: ----------- Starting training (Round #0) -------------\n",
      "2022-12-22 19:47:25,565 (client:260)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.651096, 'train_loss': 1061.938019, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:25,567 (server:323)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2022-12-22 19:47:25,567 (server:330)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2022-12-22 19:47:25,605 (client:415)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_avg_loss': 0.633577, 'test_loss': 129.249637, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.625372, 'val_loss': 127.575803, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:25,606 (monitor:936)INFO: Current best: {'test_avg_loss': 0.633577, 'test_loss': 129.249637, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.625372, 'val_loss': 127.575803, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:25,782 (client:260)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.612188, 'train_loss': 998.478622, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:25,784 (server:496)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_avg_loss': 0.633577, 'test_loss': 129.249637, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.625372, 'val_loss': 127.575803, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:25,785 (monitor:936)INFO: Current best: {'test_avg_loss': [0.633577], 'test_loss': [129.249637], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.625372], 'val_loss': [127.575803], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:25,786 (monitor:936)INFO: Current best: {'test_avg_loss': 0.633577, 'test_loss': 129.249637, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.625372, 'val_loss': 127.575803, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:25,787 (server:323)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2022-12-22 19:47:25,788 (server:330)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2022-12-22 19:47:25,842 (client:415)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_avg_loss': 0.607029, 'test_loss': 123.833888, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.594259, 'val_loss': 121.228841, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:25,843 (monitor:936)INFO: Current best: {'test_avg_loss': 0.607029, 'test_loss': 123.833888, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.594259, 'val_loss': 121.228841, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,042 (client:260)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.586583, 'train_loss': 956.716221, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:26,043 (server:496)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_avg_loss': 0.607029, 'test_loss': 123.833888, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.594259, 'val_loss': 121.228841, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,044 (monitor:936)INFO: Current best: {'test_avg_loss': [0.607029], 'test_loss': [123.833888], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.594259], 'val_loss': [121.228841], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:26,045 (monitor:936)INFO: Current best: {'test_avg_loss': 0.607029, 'test_loss': 123.833888, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.594259, 'val_loss': 121.228841, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,048 (server:323)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2022-12-22 19:47:26,048 (server:330)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2022-12-22 19:47:26,103 (client:415)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.58932, 'test_loss': 120.221221, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.572229, 'val_loss': 116.734676, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,104 (monitor:936)INFO: Current best: {'test_avg_loss': 0.58932, 'test_loss': 120.221221, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.572229, 'val_loss': 116.734676, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,257 (client:260)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.568904, 'train_loss': 927.88284, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:26,258 (server:496)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_avg_loss': 0.58932, 'test_loss': 120.221221, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.572229, 'val_loss': 116.734676, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,259 (monitor:936)INFO: Current best: {'test_avg_loss': [0.58932], 'test_loss': [120.221221], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.572229], 'val_loss': [116.734676], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:26,260 (monitor:936)INFO: Current best: {'test_avg_loss': 0.58932, 'test_loss': 120.221221, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.572229, 'val_loss': 116.734676, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,261 (server:323)INFO: Server #0: Starting evaluation at the end of round 3.\n",
      "2022-12-22 19:47:26,262 (server:330)INFO: ----------- Starting a new training round (Round #4) -------------\n",
      "2022-12-22 19:47:26,308 (client:415)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'test_avg_loss': 0.578436, 'test_loss': 118.001045, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.557828, 'val_loss': 113.796929, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,309 (monitor:936)INFO: Current best: {'test_avg_loss': 0.578436, 'test_loss': 118.001045, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.557828, 'val_loss': 113.796929, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,456 (client:260)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.558063, 'train_loss': 910.201138, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:26,457 (server:496)INFO: {'Role': 'Server #', 'Round': 4, 'Results_avg': {'test_avg_loss': 0.578436, 'test_loss': 118.001045, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.557828, 'val_loss': 113.796929, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,458 (monitor:936)INFO: Current best: {'test_avg_loss': [0.578436], 'test_loss': [118.001045], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.557828], 'val_loss': [113.796929], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:26,459 (monitor:936)INFO: Current best: {'test_avg_loss': 0.578436, 'test_loss': 118.001045, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.557828, 'val_loss': 113.796929, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,461 (server:323)INFO: Server #0: Starting evaluation at the end of round 4.\n",
      "2022-12-22 19:47:26,461 (server:330)INFO: ----------- Starting a new training round (Round #5) -------------\n",
      "2022-12-22 19:47:26,507 (client:415)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'test_avg_loss': 0.57166, 'test_loss': 116.618584, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.548283, 'val_loss': 111.849632, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,508 (monitor:936)INFO: Current best: {'test_avg_loss': 0.57166, 'test_loss': 116.618584, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.548283, 'val_loss': 111.849632, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,655 (client:260)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.550827, 'train_loss': 898.398381, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:26,657 (server:496)INFO: {'Role': 'Server #', 'Round': 5, 'Results_avg': {'test_avg_loss': 0.57166, 'test_loss': 116.618584, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.548283, 'val_loss': 111.849632, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,658 (monitor:936)INFO: Current best: {'test_avg_loss': [0.57166], 'test_loss': [116.618584], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.548283], 'val_loss': [111.849632], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:26,658 (monitor:936)INFO: Current best: {'test_avg_loss': 0.57166, 'test_loss': 116.618584, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.548283, 'val_loss': 111.849632, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,660 (server:323)INFO: Server #0: Starting evaluation at the end of round 5.\n",
      "2022-12-22 19:47:26,661 (server:330)INFO: ----------- Starting a new training round (Round #6) -------------\n",
      "2022-12-22 19:47:26,707 (client:415)INFO: {'Role': 'Client #1', 'Round': 6, 'Results_raw': {'test_avg_loss': 0.567327, 'test_loss': 115.734792, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.54156, 'val_loss': 110.478212, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,708 (monitor:936)INFO: Current best: {'test_avg_loss': 0.567327, 'test_loss': 115.734792, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.54156, 'val_loss': 110.478212, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,860 (client:260)INFO: {'Role': 'Client #1', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.545352, 'train_loss': 889.469533, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:26,861 (server:496)INFO: {'Role': 'Server #', 'Round': 6, 'Results_avg': {'test_avg_loss': 0.567327, 'test_loss': 115.734792, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.54156, 'val_loss': 110.478212, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,862 (monitor:936)INFO: Current best: {'test_avg_loss': [0.567327], 'test_loss': [115.734792], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.54156], 'val_loss': [110.478212], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:26,863 (monitor:936)INFO: Current best: {'test_avg_loss': 0.567327, 'test_loss': 115.734792, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.54156, 'val_loss': 110.478212, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:26,865 (server:323)INFO: Server #0: Starting evaluation at the end of round 6.\n",
      "2022-12-22 19:47:26,866 (server:330)INFO: ----------- Starting a new training round (Round #7) -------------\n",
      "2022-12-22 19:47:26,911 (client:415)INFO: {'Role': 'Client #1', 'Round': 7, 'Results_raw': {'test_avg_loss': 0.564502, 'test_loss': 115.15839, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.536666, 'val_loss': 109.479766, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:26,912 (monitor:936)INFO: Current best: {'test_avg_loss': 0.564502, 'test_loss': 115.15839, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.536666, 'val_loss': 109.479766, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,060 (client:260)INFO: {'Role': 'Client #1', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.54168, 'train_loss': 883.479587, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:27,061 (server:496)INFO: {'Role': 'Server #', 'Round': 7, 'Results_avg': {'test_avg_loss': 0.564502, 'test_loss': 115.15839, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.536666, 'val_loss': 109.479766, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,062 (monitor:936)INFO: Current best: {'test_avg_loss': [0.564502], 'test_loss': [115.15839], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.536666], 'val_loss': [109.479766], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:27,063 (monitor:936)INFO: Current best: {'test_avg_loss': 0.564502, 'test_loss': 115.15839, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.536666, 'val_loss': 109.479766, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,065 (server:323)INFO: Server #0: Starting evaluation at the end of round 7.\n",
      "2022-12-22 19:47:27,065 (server:330)INFO: ----------- Starting a new training round (Round #8) -------------\n",
      "2022-12-22 19:47:27,110 (client:415)INFO: {'Role': 'Client #1', 'Round': 8, 'Results_raw': {'test_avg_loss': 0.562685, 'test_loss': 114.78783, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.533042, 'val_loss': 108.740619, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,111 (monitor:936)INFO: Current best: {'test_avg_loss': 0.562685, 'test_loss': 114.78783, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.533042, 'val_loss': 108.740619, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,282 (client:260)INFO: {'Role': 'Client #1', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.538639, 'train_loss': 878.520955, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:27,284 (server:496)INFO: {'Role': 'Server #', 'Round': 8, 'Results_avg': {'test_avg_loss': 0.562685, 'test_loss': 114.78783, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.533042, 'val_loss': 108.740619, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,284 (monitor:936)INFO: Current best: {'test_avg_loss': [0.562685], 'test_loss': [114.78783], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.533042], 'val_loss': [108.740619], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:27,285 (monitor:936)INFO: Current best: {'test_avg_loss': 0.562685, 'test_loss': 114.78783, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.533042, 'val_loss': 108.740619, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,288 (server:323)INFO: Server #0: Starting evaluation at the end of round 8.\n",
      "2022-12-22 19:47:27,289 (server:330)INFO: ----------- Starting a new training round (Round #9) -------------\n",
      "2022-12-22 19:47:27,334 (client:415)INFO: {'Role': 'Client #1', 'Round': 9, 'Results_raw': {'test_avg_loss': 0.561475, 'test_loss': 114.54091, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.530269, 'val_loss': 108.174905, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,334 (monitor:936)INFO: Current best: {'test_avg_loss': 0.561475, 'test_loss': 114.54091, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.530269, 'val_loss': 108.174905, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,521 (client:260)INFO: {'Role': 'Client #1', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.536883, 'train_loss': 875.656175, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:27,522 (server:496)INFO: {'Role': 'Server #', 'Round': 9, 'Results_avg': {'test_avg_loss': 0.561475, 'test_loss': 114.54091, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.530269, 'val_loss': 108.174905, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,523 (monitor:936)INFO: Current best: {'test_avg_loss': [0.561475], 'test_loss': [114.54091], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.530269], 'val_loss': [108.174905], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:27,524 (monitor:936)INFO: Current best: {'test_avg_loss': 0.561475, 'test_loss': 114.54091, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.530269, 'val_loss': 108.174905, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,526 (server:323)INFO: Server #0: Starting evaluation at the end of round 9.\n",
      "2022-12-22 19:47:27,527 (server:330)INFO: ----------- Starting a new training round (Round #10) -------------\n",
      "2022-12-22 19:47:27,572 (client:415)INFO: {'Role': 'Client #1', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.560609, 'test_loss': 114.364216, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.528027, 'val_loss': 107.717516, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,573 (monitor:936)INFO: Current best: {'test_avg_loss': 0.560609, 'test_loss': 114.364216, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.528027, 'val_loss': 107.717516, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,772 (client:260)INFO: {'Role': 'Client #1', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.535409, 'train_loss': 873.252452, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:27,774 (server:496)INFO: {'Role': 'Server #', 'Round': 10, 'Results_avg': {'test_avg_loss': 0.560609, 'test_loss': 114.364216, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.528027, 'val_loss': 107.717516, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,775 (monitor:936)INFO: Current best: {'test_avg_loss': [0.560609], 'test_loss': [114.364216], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.528027], 'val_loss': [107.717516], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:27,776 (monitor:936)INFO: Current best: {'test_avg_loss': 0.560609, 'test_loss': 114.364216, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.528027, 'val_loss': 107.717516, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,778 (server:323)INFO: Server #0: Starting evaluation at the end of round 10.\n",
      "2022-12-22 19:47:27,779 (server:330)INFO: ----------- Starting a new training round (Round #11) -------------\n",
      "2022-12-22 19:47:27,828 (client:415)INFO: {'Role': 'Client #1', 'Round': 11, 'Results_raw': {'test_avg_loss': 0.559983, 'test_loss': 114.236625, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.526412, 'val_loss': 107.388092, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,829 (monitor:936)INFO: Current best: {'test_avg_loss': 0.559983, 'test_loss': 114.236625, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.526412, 'val_loss': 107.388092, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,994 (client:260)INFO: {'Role': 'Client #1', 'Round': 11, 'Results_raw': {'train_avg_loss': 0.533607, 'train_loss': 870.313314, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:27,996 (server:496)INFO: {'Role': 'Server #', 'Round': 11, 'Results_avg': {'test_avg_loss': 0.559983, 'test_loss': 114.236625, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.526412, 'val_loss': 107.388092, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:27,996 (monitor:936)INFO: Current best: {'test_avg_loss': [0.559983], 'test_loss': [114.236625], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.526412], 'val_loss': [107.388092], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:27,997 (monitor:936)INFO: Current best: {'test_avg_loss': 0.559983, 'test_loss': 114.236625, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.526412, 'val_loss': 107.388092, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:27,999 (server:323)INFO: Server #0: Starting evaluation at the end of round 11.\n",
      "2022-12-22 19:47:27,999 (server:330)INFO: ----------- Starting a new training round (Round #12) -------------\n",
      "2022-12-22 19:47:28,043 (client:415)INFO: {'Role': 'Client #1', 'Round': 12, 'Results_raw': {'test_avg_loss': 0.55923, 'test_loss': 114.082923, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.524839, 'val_loss': 107.067069, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,044 (monitor:936)INFO: Current best: {'test_avg_loss': 0.55923, 'test_loss': 114.082923, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.524839, 'val_loss': 107.067069, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,221 (client:260)INFO: {'Role': 'Client #1', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.532569, 'train_loss': 868.620808, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:28,222 (server:496)INFO: {'Role': 'Server #', 'Round': 12, 'Results_avg': {'test_avg_loss': 0.55923, 'test_loss': 114.082923, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.524839, 'val_loss': 107.067069, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,223 (monitor:936)INFO: Current best: {'test_avg_loss': [0.55923], 'test_loss': [114.082923], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.524839], 'val_loss': [107.067069], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:28,225 (monitor:936)INFO: Current best: {'test_avg_loss': 0.55923, 'test_loss': 114.082923, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.524839, 'val_loss': 107.067069, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,227 (server:323)INFO: Server #0: Starting evaluation at the end of round 12.\n",
      "2022-12-22 19:47:28,228 (server:330)INFO: ----------- Starting a new training round (Round #13) -------------\n",
      "2022-12-22 19:47:28,280 (client:415)INFO: {'Role': 'Client #1', 'Round': 13, 'Results_raw': {'test_avg_loss': 0.558537, 'test_loss': 113.941523, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.523338, 'val_loss': 106.761031, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,282 (monitor:936)INFO: Current best: {'test_avg_loss': 0.558537, 'test_loss': 113.941523, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.523338, 'val_loss': 106.761031, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,472 (client:260)INFO: {'Role': 'Client #1', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.531539, 'train_loss': 866.939458, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:28,474 (server:496)INFO: {'Role': 'Server #', 'Round': 13, 'Results_avg': {'test_avg_loss': 0.558537, 'test_loss': 113.941523, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.523338, 'val_loss': 106.761031, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,475 (monitor:936)INFO: Current best: {'test_avg_loss': [0.558537], 'test_loss': [113.941523], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.523338], 'val_loss': [106.761031], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:28,476 (monitor:936)INFO: Current best: {'test_avg_loss': 0.558537, 'test_loss': 113.941523, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.523338, 'val_loss': 106.761031, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,477 (server:323)INFO: Server #0: Starting evaluation at the end of round 13.\n",
      "2022-12-22 19:47:28,478 (server:330)INFO: ----------- Starting a new training round (Round #14) -------------\n",
      "2022-12-22 19:47:28,523 (client:415)INFO: {'Role': 'Client #1', 'Round': 14, 'Results_raw': {'test_avg_loss': 0.557616, 'test_loss': 113.753654, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.522153, 'val_loss': 106.519261, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,523 (monitor:936)INFO: Current best: {'test_avg_loss': 0.557616, 'test_loss': 113.753654, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.522153, 'val_loss': 106.519261, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,716 (client:260)INFO: {'Role': 'Client #1', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.529963, 'train_loss': 864.370096, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:28,718 (server:496)INFO: {'Role': 'Server #', 'Round': 14, 'Results_avg': {'test_avg_loss': 0.557616, 'test_loss': 113.753654, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.522153, 'val_loss': 106.519261, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,719 (monitor:936)INFO: Current best: {'test_avg_loss': [0.557616], 'test_loss': [113.753654], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.522153], 'val_loss': [106.519261], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:28,720 (monitor:936)INFO: Current best: {'test_avg_loss': 0.557616, 'test_loss': 113.753654, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.522153, 'val_loss': 106.519261, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,722 (server:323)INFO: Server #0: Starting evaluation at the end of round 14.\n",
      "2022-12-22 19:47:28,723 (server:330)INFO: ----------- Starting a new training round (Round #15) -------------\n",
      "2022-12-22 19:47:28,771 (client:415)INFO: {'Role': 'Client #1', 'Round': 15, 'Results_raw': {'test_avg_loss': 0.556666, 'test_loss': 113.559865, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.520832, 'val_loss': 106.249658, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,771 (monitor:936)INFO: Current best: {'test_avg_loss': 0.556666, 'test_loss': 113.559865, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.520832, 'val_loss': 106.249658, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,982 (client:260)INFO: {'Role': 'Client #1', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.528169, 'train_loss': 861.443437, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:28,984 (server:496)INFO: {'Role': 'Server #', 'Round': 15, 'Results_avg': {'test_avg_loss': 0.556666, 'test_loss': 113.559865, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.520832, 'val_loss': 106.249658, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:28,985 (monitor:936)INFO: Current best: {'test_avg_loss': [0.556666], 'test_loss': [113.559865], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.520832], 'val_loss': [106.249658], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:28,986 (monitor:936)INFO: Current best: {'test_avg_loss': 0.556666, 'test_loss': 113.559865, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.520832, 'val_loss': 106.249658, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:28,988 (server:323)INFO: Server #0: Starting evaluation at the end of round 15.\n",
      "2022-12-22 19:47:28,988 (server:330)INFO: ----------- Starting a new training round (Round #16) -------------\n",
      "2022-12-22 19:47:29,034 (client:415)INFO: {'Role': 'Client #1', 'Round': 16, 'Results_raw': {'test_avg_loss': 0.555656, 'test_loss': 113.353727, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.519224, 'val_loss': 105.921768, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,035 (monitor:936)INFO: Current best: {'test_avg_loss': 0.555656, 'test_loss': 113.353727, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.519224, 'val_loss': 105.921768, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,226 (client:260)INFO: {'Role': 'Client #1', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.527031, 'train_loss': 859.588157, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:29,227 (server:496)INFO: {'Role': 'Server #', 'Round': 16, 'Results_avg': {'test_avg_loss': 0.555656, 'test_loss': 113.353727, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.519224, 'val_loss': 105.921768, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,228 (monitor:936)INFO: Current best: {'test_avg_loss': [0.555656], 'test_loss': [113.353727], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.519224], 'val_loss': [105.921768], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:29,230 (monitor:936)INFO: Current best: {'test_avg_loss': 0.555656, 'test_loss': 113.353727, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.519224, 'val_loss': 105.921768, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,232 (server:323)INFO: Server #0: Starting evaluation at the end of round 16.\n",
      "2022-12-22 19:47:29,233 (server:330)INFO: ----------- Starting a new training round (Round #17) -------------\n",
      "2022-12-22 19:47:29,280 (client:415)INFO: {'Role': 'Client #1', 'Round': 17, 'Results_raw': {'test_avg_loss': 0.554569, 'test_loss': 113.132139, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.517937, 'val_loss': 105.659201, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,280 (monitor:936)INFO: Current best: {'test_avg_loss': 0.554569, 'test_loss': 113.132139, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.517937, 'val_loss': 105.659201, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,465 (client:260)INFO: {'Role': 'Client #1', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.525248, 'train_loss': 856.679657, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:29,467 (server:496)INFO: {'Role': 'Server #', 'Round': 17, 'Results_avg': {'test_avg_loss': 0.554569, 'test_loss': 113.132139, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.517937, 'val_loss': 105.659201, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,468 (monitor:936)INFO: Current best: {'test_avg_loss': [0.554569], 'test_loss': [113.132139], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.517937], 'val_loss': [105.659201], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:29,471 (monitor:936)INFO: Current best: {'test_avg_loss': 0.554569, 'test_loss': 113.132139, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.517937, 'val_loss': 105.659201, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,472 (server:323)INFO: Server #0: Starting evaluation at the end of round 17.\n",
      "2022-12-22 19:47:29,474 (server:330)INFO: ----------- Starting a new training round (Round #18) -------------\n",
      "2022-12-22 19:47:29,521 (client:415)INFO: {'Role': 'Client #1', 'Round': 18, 'Results_raw': {'test_avg_loss': 0.553415, 'test_loss': 112.89675, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.516351, 'val_loss': 105.335692, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,522 (monitor:936)INFO: Current best: {'test_avg_loss': 0.553415, 'test_loss': 112.89675, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.516351, 'val_loss': 105.335692, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,709 (client:260)INFO: {'Role': 'Client #1', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.524347, 'train_loss': 855.209602, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:29,711 (server:496)INFO: {'Role': 'Server #', 'Round': 18, 'Results_avg': {'test_avg_loss': 0.553415, 'test_loss': 112.89675, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.516351, 'val_loss': 105.335692, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,712 (monitor:936)INFO: Current best: {'test_avg_loss': [0.553415], 'test_loss': [112.89675], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.516351], 'val_loss': [105.335692], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:29,713 (monitor:936)INFO: Current best: {'test_avg_loss': 0.553415, 'test_loss': 112.89675, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.516351, 'val_loss': 105.335692, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,715 (server:323)INFO: Server #0: Starting evaluation at the end of round 18.\n",
      "2022-12-22 19:47:29,716 (server:330)INFO: ----------- Starting a new training round (Round #19) -------------\n",
      "2022-12-22 19:47:29,762 (client:415)INFO: {'Role': 'Client #1', 'Round': 19, 'Results_raw': {'test_avg_loss': 0.552187, 'test_loss': 112.646108, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.514732, 'val_loss': 105.005306, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,763 (monitor:936)INFO: Current best: {'test_avg_loss': 0.552187, 'test_loss': 112.646108, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.514732, 'val_loss': 105.005306, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,953 (client:260)INFO: {'Role': 'Client #1', 'Round': 19, 'Results_raw': {'train_avg_loss': 0.521296, 'train_loss': 850.234125, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:29,954 (server:496)INFO: {'Role': 'Server #', 'Round': 19, 'Results_avg': {'test_avg_loss': 0.552187, 'test_loss': 112.646108, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.514732, 'val_loss': 105.005306, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:29,955 (monitor:936)INFO: Current best: {'test_avg_loss': [0.552187], 'test_loss': [112.646108], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.514732], 'val_loss': [105.005306], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:29,957 (monitor:936)INFO: Current best: {'test_avg_loss': 0.552187, 'test_loss': 112.646108, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.514732, 'val_loss': 105.005306, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:29,959 (server:323)INFO: Server #0: Starting evaluation at the end of round 19.\n",
      "2022-12-22 19:47:29,959 (server:330)INFO: ----------- Starting a new training round (Round #20) -------------\n",
      "2022-12-22 19:47:30,006 (client:415)INFO: {'Role': 'Client #1', 'Round': 20, 'Results_raw': {'test_avg_loss': 0.550713, 'test_loss': 112.345477, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.513027, 'val_loss': 104.657543, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,006 (monitor:936)INFO: Current best: {'test_avg_loss': 0.550713, 'test_loss': 112.345477, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.513027, 'val_loss': 104.657543, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,198 (client:260)INFO: {'Role': 'Client #1', 'Round': 20, 'Results_raw': {'train_avg_loss': 0.5193, 'train_loss': 846.977805, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:30,200 (server:496)INFO: {'Role': 'Server #', 'Round': 20, 'Results_avg': {'test_avg_loss': 0.550713, 'test_loss': 112.345477, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.513027, 'val_loss': 104.657543, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,201 (monitor:936)INFO: Current best: {'test_avg_loss': [0.550713], 'test_loss': [112.345477], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.513027], 'val_loss': [104.657543], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:30,203 (monitor:936)INFO: Current best: {'test_avg_loss': 0.550713, 'test_loss': 112.345477, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.513027, 'val_loss': 104.657543, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,204 (server:323)INFO: Server #0: Starting evaluation at the end of round 20.\n",
      "2022-12-22 19:47:30,205 (server:330)INFO: ----------- Starting a new training round (Round #21) -------------\n",
      "2022-12-22 19:47:30,252 (client:415)INFO: {'Role': 'Client #1', 'Round': 21, 'Results_raw': {'test_avg_loss': 0.549287, 'test_loss': 112.054506, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.511116, 'val_loss': 104.267573, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,253 (monitor:936)INFO: Current best: {'test_avg_loss': 0.549287, 'test_loss': 112.054506, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.511116, 'val_loss': 104.267573, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,445 (client:260)INFO: {'Role': 'Client #1', 'Round': 21, 'Results_raw': {'train_avg_loss': 0.517208, 'train_loss': 843.566956, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:30,447 (server:496)INFO: {'Role': 'Server #', 'Round': 21, 'Results_avg': {'test_avg_loss': 0.549287, 'test_loss': 112.054506, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.511116, 'val_loss': 104.267573, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,448 (monitor:936)INFO: Current best: {'test_avg_loss': [0.549287], 'test_loss': [112.054506], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.511116], 'val_loss': [104.267573], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:30,449 (monitor:936)INFO: Current best: {'test_avg_loss': 0.549287, 'test_loss': 112.054506, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.511116, 'val_loss': 104.267573, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,451 (server:323)INFO: Server #0: Starting evaluation at the end of round 21.\n",
      "2022-12-22 19:47:30,452 (server:330)INFO: ----------- Starting a new training round (Round #22) -------------\n",
      "2022-12-22 19:47:30,496 (client:415)INFO: {'Role': 'Client #1', 'Round': 22, 'Results_raw': {'test_avg_loss': 0.547829, 'test_loss': 111.757165, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.509175, 'val_loss': 103.87165, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,497 (monitor:936)INFO: Current best: {'test_avg_loss': 0.547829, 'test_loss': 111.757165, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.509175, 'val_loss': 103.87165, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,695 (client:260)INFO: {'Role': 'Client #1', 'Round': 22, 'Results_raw': {'train_avg_loss': 0.515322, 'train_loss': 840.49081, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:30,697 (server:496)INFO: {'Role': 'Server #', 'Round': 22, 'Results_avg': {'test_avg_loss': 0.547829, 'test_loss': 111.757165, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.509175, 'val_loss': 103.87165, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,698 (monitor:936)INFO: Current best: {'test_avg_loss': [0.547829], 'test_loss': [111.757165], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.509175], 'val_loss': [103.87165], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:30,699 (monitor:936)INFO: Current best: {'test_avg_loss': 0.547829, 'test_loss': 111.757165, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.509175, 'val_loss': 103.87165, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,702 (server:323)INFO: Server #0: Starting evaluation at the end of round 22.\n",
      "2022-12-22 19:47:30,703 (server:330)INFO: ----------- Starting a new training round (Round #23) -------------\n",
      "2022-12-22 19:47:30,751 (client:415)INFO: {'Role': 'Client #1', 'Round': 23, 'Results_raw': {'test_avg_loss': 0.546007, 'test_loss': 111.385463, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.507356, 'val_loss': 103.500613, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,753 (monitor:936)INFO: Current best: {'test_avg_loss': 0.546007, 'test_loss': 111.385463, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.507356, 'val_loss': 103.500613, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,944 (client:260)INFO: {'Role': 'Client #1', 'Round': 23, 'Results_raw': {'train_avg_loss': 0.51435, 'train_loss': 838.905219, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:30,945 (server:496)INFO: {'Role': 'Server #', 'Round': 23, 'Results_avg': {'test_avg_loss': 0.546007, 'test_loss': 111.385463, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.507356, 'val_loss': 103.500613, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,946 (monitor:936)INFO: Current best: {'test_avg_loss': [0.546007], 'test_loss': [111.385463], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.507356], 'val_loss': [103.500613], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:30,948 (monitor:936)INFO: Current best: {'test_avg_loss': 0.546007, 'test_loss': 111.385463, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.507356, 'val_loss': 103.500613, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:30,949 (server:323)INFO: Server #0: Starting evaluation at the end of round 23.\n",
      "2022-12-22 19:47:30,950 (server:330)INFO: ----------- Starting a new training round (Round #24) -------------\n",
      "2022-12-22 19:47:30,995 (client:415)INFO: {'Role': 'Client #1', 'Round': 24, 'Results_raw': {'test_avg_loss': 0.544331, 'test_loss': 111.043616, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.505171, 'val_loss': 103.054829, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:30,996 (monitor:936)INFO: Current best: {'test_avg_loss': 0.544331, 'test_loss': 111.043616, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.505171, 'val_loss': 103.054829, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,185 (client:260)INFO: {'Role': 'Client #1', 'Round': 24, 'Results_raw': {'train_avg_loss': 0.510899, 'train_loss': 833.277083, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:31,186 (server:496)INFO: {'Role': 'Server #', 'Round': 24, 'Results_avg': {'test_avg_loss': 0.544331, 'test_loss': 111.043616, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.505171, 'val_loss': 103.054829, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,187 (monitor:936)INFO: Current best: {'test_avg_loss': [0.544331], 'test_loss': [111.043616], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.505171], 'val_loss': [103.054829], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:31,188 (monitor:936)INFO: Current best: {'test_avg_loss': 0.544331, 'test_loss': 111.043616, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.505171, 'val_loss': 103.054829, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,190 (server:323)INFO: Server #0: Starting evaluation at the end of round 24.\n",
      "2022-12-22 19:47:31,191 (server:330)INFO: ----------- Starting a new training round (Round #25) -------------\n",
      "2022-12-22 19:47:31,237 (client:415)INFO: {'Role': 'Client #1', 'Round': 25, 'Results_raw': {'test_avg_loss': 0.542455, 'test_loss': 110.660853, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.503114, 'val_loss': 102.635226, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,237 (monitor:936)INFO: Current best: {'test_avg_loss': 0.542455, 'test_loss': 110.660853, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.503114, 'val_loss': 102.635226, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,435 (client:260)INFO: {'Role': 'Client #1', 'Round': 25, 'Results_raw': {'train_avg_loss': 0.508631, 'train_loss': 829.577466, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:31,436 (server:496)INFO: {'Role': 'Server #', 'Round': 25, 'Results_avg': {'test_avg_loss': 0.542455, 'test_loss': 110.660853, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.503114, 'val_loss': 102.635226, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,437 (monitor:936)INFO: Current best: {'test_avg_loss': [0.542455], 'test_loss': [110.660853], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.503114], 'val_loss': [102.635226], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:31,438 (monitor:936)INFO: Current best: {'test_avg_loss': 0.542455, 'test_loss': 110.660853, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.503114, 'val_loss': 102.635226, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,440 (server:323)INFO: Server #0: Starting evaluation at the end of round 25.\n",
      "2022-12-22 19:47:31,440 (server:330)INFO: ----------- Starting a new training round (Round #26) -------------\n",
      "2022-12-22 19:47:31,486 (client:415)INFO: {'Role': 'Client #1', 'Round': 26, 'Results_raw': {'test_avg_loss': 0.540679, 'test_loss': 110.298501, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.500676, 'val_loss': 102.137995, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,486 (monitor:936)INFO: Current best: {'test_avg_loss': 0.540679, 'test_loss': 110.298501, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.500676, 'val_loss': 102.137995, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,677 (client:260)INFO: {'Role': 'Client #1', 'Round': 26, 'Results_raw': {'train_avg_loss': 0.50661, 'train_loss': 826.280455, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:31,678 (server:496)INFO: {'Role': 'Server #', 'Round': 26, 'Results_avg': {'test_avg_loss': 0.540679, 'test_loss': 110.298501, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.500676, 'val_loss': 102.137995, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,679 (monitor:936)INFO: Current best: {'test_avg_loss': [0.540679], 'test_loss': [110.298501], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.500676], 'val_loss': [102.137995], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:31,680 (monitor:936)INFO: Current best: {'test_avg_loss': 0.540679, 'test_loss': 110.298501, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.500676, 'val_loss': 102.137995, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,681 (server:323)INFO: Server #0: Starting evaluation at the end of round 26.\n",
      "2022-12-22 19:47:31,681 (server:330)INFO: ----------- Starting a new training round (Round #27) -------------\n",
      "2022-12-22 19:47:31,715 (client:415)INFO: {'Role': 'Client #1', 'Round': 27, 'Results_raw': {'test_avg_loss': 0.538718, 'test_loss': 109.898558, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.498198, 'val_loss': 101.632439, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,716 (monitor:936)INFO: Current best: {'test_avg_loss': 0.538718, 'test_loss': 109.898558, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.498198, 'val_loss': 101.632439, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,910 (client:260)INFO: {'Role': 'Client #1', 'Round': 27, 'Results_raw': {'train_avg_loss': 0.503453, 'train_loss': 821.132595, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:31,911 (server:496)INFO: {'Role': 'Server #', 'Round': 27, 'Results_avg': {'test_avg_loss': 0.538718, 'test_loss': 109.898558, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.498198, 'val_loss': 101.632439, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,911 (monitor:936)INFO: Current best: {'test_avg_loss': [0.538718], 'test_loss': [109.898558], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.498198], 'val_loss': [101.632439], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:31,912 (monitor:936)INFO: Current best: {'test_avg_loss': 0.538718, 'test_loss': 109.898558, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.498198, 'val_loss': 101.632439, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:31,913 (server:323)INFO: Server #0: Starting evaluation at the end of round 27.\n",
      "2022-12-22 19:47:31,914 (server:330)INFO: ----------- Starting a new training round (Round #28) -------------\n",
      "2022-12-22 19:47:31,948 (client:415)INFO: {'Role': 'Client #1', 'Round': 28, 'Results_raw': {'test_avg_loss': 0.536835, 'test_loss': 109.514356, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.49547, 'val_loss': 101.07578, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:31,949 (monitor:936)INFO: Current best: {'test_avg_loss': 0.536835, 'test_loss': 109.514356, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.49547, 'val_loss': 101.07578, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,131 (client:260)INFO: {'Role': 'Client #1', 'Round': 28, 'Results_raw': {'train_avg_loss': 0.499207, 'train_loss': 814.206861, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:32,133 (server:496)INFO: {'Role': 'Server #', 'Round': 28, 'Results_avg': {'test_avg_loss': 0.536835, 'test_loss': 109.514356, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.49547, 'val_loss': 101.07578, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,133 (monitor:936)INFO: Current best: {'test_avg_loss': [0.536835], 'test_loss': [109.514356], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.49547], 'val_loss': [101.07578], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:32,135 (monitor:936)INFO: Current best: {'test_avg_loss': 0.536835, 'test_loss': 109.514356, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.49547, 'val_loss': 101.07578, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,137 (server:323)INFO: Server #0: Starting evaluation at the end of round 28.\n",
      "2022-12-22 19:47:32,138 (server:330)INFO: ----------- Starting a new training round (Round #29) -------------\n",
      "2022-12-22 19:47:32,184 (client:415)INFO: {'Role': 'Client #1', 'Round': 29, 'Results_raw': {'test_avg_loss': 0.534398, 'test_loss': 109.017264, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.493177, 'val_loss': 100.608064, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,185 (monitor:936)INFO: Current best: {'test_avg_loss': 0.534398, 'test_loss': 109.017264, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.493177, 'val_loss': 100.608064, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,360 (client:260)INFO: {'Role': 'Client #1', 'Round': 29, 'Results_raw': {'train_avg_loss': 0.497284, 'train_loss': 811.069771, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:32,361 (server:496)INFO: {'Role': 'Server #', 'Round': 29, 'Results_avg': {'test_avg_loss': 0.534398, 'test_loss': 109.017264, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.493177, 'val_loss': 100.608064, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,362 (monitor:936)INFO: Current best: {'test_avg_loss': [0.534398], 'test_loss': [109.017264], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.493177], 'val_loss': [100.608064], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:32,363 (monitor:936)INFO: Current best: {'test_avg_loss': 0.534398, 'test_loss': 109.017264, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.493177, 'val_loss': 100.608064, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,364 (server:323)INFO: Server #0: Starting evaluation at the end of round 29.\n",
      "2022-12-22 19:47:32,365 (server:330)INFO: ----------- Starting a new training round (Round #30) -------------\n",
      "2022-12-22 19:47:32,408 (client:415)INFO: {'Role': 'Client #1', 'Round': 30, 'Results_raw': {'test_avg_loss': 0.532245, 'test_loss': 108.577978, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.49054, 'val_loss': 100.070095, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,409 (monitor:936)INFO: Current best: {'test_avg_loss': 0.532245, 'test_loss': 108.577978, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.49054, 'val_loss': 100.070095, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,598 (client:260)INFO: {'Role': 'Client #1', 'Round': 30, 'Results_raw': {'train_avg_loss': 0.491876, 'train_loss': 802.24947, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:32,600 (server:496)INFO: {'Role': 'Server #', 'Round': 30, 'Results_avg': {'test_avg_loss': 0.532245, 'test_loss': 108.577978, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.49054, 'val_loss': 100.070095, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,600 (monitor:936)INFO: Current best: {'test_avg_loss': [0.532245], 'test_loss': [108.577978], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.49054], 'val_loss': [100.070095], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:32,601 (monitor:936)INFO: Current best: {'test_avg_loss': 0.532245, 'test_loss': 108.577978, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.49054, 'val_loss': 100.070095, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,603 (server:323)INFO: Server #0: Starting evaluation at the end of round 30.\n",
      "2022-12-22 19:47:32,604 (server:330)INFO: ----------- Starting a new training round (Round #31) -------------\n",
      "2022-12-22 19:47:32,647 (client:415)INFO: {'Role': 'Client #1', 'Round': 31, 'Results_raw': {'test_avg_loss': 0.529789, 'test_loss': 108.076884, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.487935, 'val_loss': 99.538647, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,647 (monitor:936)INFO: Current best: {'test_avg_loss': 0.529789, 'test_loss': 108.076884, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.487935, 'val_loss': 99.538647, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,840 (client:260)INFO: {'Role': 'Client #1', 'Round': 31, 'Results_raw': {'train_avg_loss': 0.491748, 'train_loss': 802.04049, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:32,842 (server:496)INFO: {'Role': 'Server #', 'Round': 31, 'Results_avg': {'test_avg_loss': 0.529789, 'test_loss': 108.076884, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.487935, 'val_loss': 99.538647, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,843 (monitor:936)INFO: Current best: {'test_avg_loss': [0.529789], 'test_loss': [108.076884], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.487935], 'val_loss': [99.538647], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:32,844 (monitor:936)INFO: Current best: {'test_avg_loss': 0.529789, 'test_loss': 108.076884, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.487935, 'val_loss': 99.538647, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:32,847 (server:323)INFO: Server #0: Starting evaluation at the end of round 31.\n",
      "2022-12-22 19:47:32,848 (server:330)INFO: ----------- Starting a new training round (Round #32) -------------\n",
      "2022-12-22 19:47:32,894 (client:415)INFO: {'Role': 'Client #1', 'Round': 32, 'Results_raw': {'test_avg_loss': 0.527392, 'test_loss': 107.587891, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.484969, 'val_loss': 98.933611, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:32,895 (monitor:936)INFO: Current best: {'test_avg_loss': 0.527392, 'test_loss': 107.587891, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.484969, 'val_loss': 98.933611, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,087 (client:260)INFO: {'Role': 'Client #1', 'Round': 32, 'Results_raw': {'train_avg_loss': 0.486374, 'train_loss': 793.27678, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:33,089 (server:496)INFO: {'Role': 'Server #', 'Round': 32, 'Results_avg': {'test_avg_loss': 0.527392, 'test_loss': 107.587891, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.484969, 'val_loss': 98.933611, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,090 (monitor:936)INFO: Current best: {'test_avg_loss': [0.527392], 'test_loss': [107.587891], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.484969], 'val_loss': [98.933611], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:33,091 (monitor:936)INFO: Current best: {'test_avg_loss': 0.527392, 'test_loss': 107.587891, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.484969, 'val_loss': 98.933611, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,093 (server:323)INFO: Server #0: Starting evaluation at the end of round 32.\n",
      "2022-12-22 19:47:33,094 (server:330)INFO: ----------- Starting a new training round (Round #33) -------------\n",
      "2022-12-22 19:47:33,141 (client:415)INFO: {'Role': 'Client #1', 'Round': 33, 'Results_raw': {'test_avg_loss': 0.525578, 'test_loss': 107.218001, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.482788, 'val_loss': 98.488777, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,142 (monitor:936)INFO: Current best: {'test_avg_loss': 0.525578, 'test_loss': 107.218001, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.482788, 'val_loss': 98.488777, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,328 (client:260)INFO: {'Role': 'Client #1', 'Round': 33, 'Results_raw': {'train_avg_loss': 0.484386, 'train_loss': 790.03277, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:33,329 (server:496)INFO: {'Role': 'Server #', 'Round': 33, 'Results_avg': {'test_avg_loss': 0.525578, 'test_loss': 107.218001, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.482788, 'val_loss': 98.488777, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,331 (monitor:936)INFO: Current best: {'test_avg_loss': [0.525578], 'test_loss': [107.218001], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.482788], 'val_loss': [98.488777], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:33,333 (monitor:936)INFO: Current best: {'test_avg_loss': 0.525578, 'test_loss': 107.218001, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.482788, 'val_loss': 98.488777, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,335 (server:323)INFO: Server #0: Starting evaluation at the end of round 33.\n",
      "2022-12-22 19:47:33,335 (server:330)INFO: ----------- Starting a new training round (Round #34) -------------\n",
      "2022-12-22 19:47:33,382 (client:415)INFO: {'Role': 'Client #1', 'Round': 34, 'Results_raw': {'test_avg_loss': 0.523502, 'test_loss': 106.794502, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.480317, 'val_loss': 97.984613, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,383 (monitor:936)INFO: Current best: {'test_avg_loss': 0.523502, 'test_loss': 106.794502, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.480317, 'val_loss': 97.984613, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,563 (client:260)INFO: {'Role': 'Client #1', 'Round': 34, 'Results_raw': {'train_avg_loss': 0.479245, 'train_loss': 781.647808, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:33,565 (server:496)INFO: {'Role': 'Server #', 'Round': 34, 'Results_avg': {'test_avg_loss': 0.523502, 'test_loss': 106.794502, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.480317, 'val_loss': 97.984613, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,567 (monitor:936)INFO: Current best: {'test_avg_loss': [0.523502], 'test_loss': [106.794502], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.480317], 'val_loss': [97.984613], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:33,567 (monitor:936)INFO: Current best: {'test_avg_loss': 0.523502, 'test_loss': 106.794502, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.480317, 'val_loss': 97.984613, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,569 (server:323)INFO: Server #0: Starting evaluation at the end of round 34.\n",
      "2022-12-22 19:47:33,570 (server:330)INFO: ----------- Starting a new training round (Round #35) -------------\n",
      "2022-12-22 19:47:33,602 (client:415)INFO: {'Role': 'Client #1', 'Round': 35, 'Results_raw': {'test_avg_loss': 0.521318, 'test_loss': 106.348793, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.478035, 'val_loss': 97.519097, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,603 (monitor:936)INFO: Current best: {'test_avg_loss': 0.521318, 'test_loss': 106.348793, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.478035, 'val_loss': 97.519097, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,807 (client:260)INFO: {'Role': 'Client #1', 'Round': 35, 'Results_raw': {'train_avg_loss': 0.475107, 'train_loss': 774.899984, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:33,809 (server:496)INFO: {'Role': 'Server #', 'Round': 35, 'Results_avg': {'test_avg_loss': 0.521318, 'test_loss': 106.348793, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.478035, 'val_loss': 97.519097, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,810 (monitor:936)INFO: Current best: {'test_avg_loss': [0.521318], 'test_loss': [106.348793], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.478035], 'val_loss': [97.519097], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:33,811 (monitor:936)INFO: Current best: {'test_avg_loss': 0.521318, 'test_loss': 106.348793, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.478035, 'val_loss': 97.519097, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:33,814 (server:323)INFO: Server #0: Starting evaluation at the end of round 35.\n",
      "2022-12-22 19:47:33,815 (server:330)INFO: ----------- Starting a new training round (Round #36) -------------\n",
      "2022-12-22 19:47:33,860 (client:415)INFO: {'Role': 'Client #1', 'Round': 36, 'Results_raw': {'test_avg_loss': 0.520285, 'test_loss': 106.138234, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.475368, 'val_loss': 96.975044, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:33,861 (monitor:936)INFO: Current best: {'test_avg_loss': 0.520285, 'test_loss': 106.138234, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.475368, 'val_loss': 96.975044, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,039 (client:260)INFO: {'Role': 'Client #1', 'Round': 36, 'Results_raw': {'train_avg_loss': 0.472324, 'train_loss': 770.359658, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:34,042 (server:496)INFO: {'Role': 'Server #', 'Round': 36, 'Results_avg': {'test_avg_loss': 0.520285, 'test_loss': 106.138234, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.475368, 'val_loss': 96.975044, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,043 (monitor:936)INFO: Current best: {'test_avg_loss': [0.520285], 'test_loss': [106.138234], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.475368], 'val_loss': [96.975044], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:34,044 (monitor:936)INFO: Current best: {'test_avg_loss': 0.520285, 'test_loss': 106.138234, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.475368, 'val_loss': 96.975044, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,047 (server:323)INFO: Server #0: Starting evaluation at the end of round 36.\n",
      "2022-12-22 19:47:34,048 (server:330)INFO: ----------- Starting a new training round (Round #37) -------------\n",
      "2022-12-22 19:47:34,093 (client:415)INFO: {'Role': 'Client #1', 'Round': 37, 'Results_raw': {'test_avg_loss': 0.517192, 'test_loss': 105.507146, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.473725, 'val_loss': 96.639946, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,094 (monitor:936)INFO: Current best: {'test_avg_loss': 0.517192, 'test_loss': 105.507146, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.473725, 'val_loss': 96.639946, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,287 (client:260)INFO: {'Role': 'Client #1', 'Round': 37, 'Results_raw': {'train_avg_loss': 0.468775, 'train_loss': 764.571495, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:34,288 (server:496)INFO: {'Role': 'Server #', 'Round': 37, 'Results_avg': {'test_avg_loss': 0.517192, 'test_loss': 105.507146, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.473725, 'val_loss': 96.639946, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,289 (monitor:936)INFO: Current best: {'test_avg_loss': [0.517192], 'test_loss': [105.507146], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.473725], 'val_loss': [96.639946], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:34,290 (monitor:936)INFO: Current best: {'test_avg_loss': 0.517192, 'test_loss': 105.507146, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.473725, 'val_loss': 96.639946, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,291 (server:323)INFO: Server #0: Starting evaluation at the end of round 37.\n",
      "2022-12-22 19:47:34,292 (server:330)INFO: ----------- Starting a new training round (Round #38) -------------\n",
      "2022-12-22 19:47:34,328 (client:415)INFO: {'Role': 'Client #1', 'Round': 38, 'Results_raw': {'test_avg_loss': 0.515967, 'test_loss': 105.257347, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.471201, 'val_loss': 96.124967, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,329 (monitor:936)INFO: Current best: {'test_avg_loss': 0.515967, 'test_loss': 105.257347, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.471201, 'val_loss': 96.124967, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,528 (client:260)INFO: {'Role': 'Client #1', 'Round': 38, 'Results_raw': {'train_avg_loss': 0.465432, 'train_loss': 759.119132, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:34,529 (server:496)INFO: {'Role': 'Server #', 'Round': 38, 'Results_avg': {'test_avg_loss': 0.515967, 'test_loss': 105.257347, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.471201, 'val_loss': 96.124967, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,530 (monitor:936)INFO: Current best: {'test_avg_loss': [0.515967], 'test_loss': [105.257347], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.471201], 'val_loss': [96.124967], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:34,532 (monitor:936)INFO: Current best: {'test_avg_loss': 0.515967, 'test_loss': 105.257347, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.471201, 'val_loss': 96.124967, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,535 (server:323)INFO: Server #0: Starting evaluation at the end of round 38.\n",
      "2022-12-22 19:47:34,536 (server:330)INFO: ----------- Starting a new training round (Round #39) -------------\n",
      "2022-12-22 19:47:34,568 (client:415)INFO: {'Role': 'Client #1', 'Round': 39, 'Results_raw': {'test_avg_loss': 0.512557, 'test_loss': 104.561537, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.468239, 'val_loss': 95.520739, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,569 (monitor:936)INFO: Current best: {'test_avg_loss': 0.512557, 'test_loss': 104.561537, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.468239, 'val_loss': 95.520739, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,726 (client:260)INFO: {'Role': 'Client #1', 'Round': 39, 'Results_raw': {'train_avg_loss': 0.462362, 'train_loss': 754.113016, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:34,727 (server:496)INFO: {'Role': 'Server #', 'Round': 39, 'Results_avg': {'test_avg_loss': 0.512557, 'test_loss': 104.561537, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.468239, 'val_loss': 95.520739, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,728 (monitor:936)INFO: Current best: {'test_avg_loss': [0.512557], 'test_loss': [104.561537], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.468239], 'val_loss': [95.520739], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:34,729 (monitor:936)INFO: Current best: {'test_avg_loss': 0.512557, 'test_loss': 104.561537, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.468239, 'val_loss': 95.520739, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,731 (server:323)INFO: Server #0: Starting evaluation at the end of round 39.\n",
      "2022-12-22 19:47:34,732 (server:330)INFO: ----------- Starting a new training round (Round #40) -------------\n",
      "2022-12-22 19:47:34,777 (client:415)INFO: {'Role': 'Client #1', 'Round': 40, 'Results_raw': {'test_avg_loss': 0.509939, 'test_loss': 104.027618, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.467748, 'val_loss': 95.420533, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,779 (monitor:936)INFO: Current best: {'test_avg_loss': 0.509939, 'test_loss': 104.027618, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.467748, 'val_loss': 95.420533, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,925 (client:260)INFO: {'Role': 'Client #1', 'Round': 40, 'Results_raw': {'train_avg_loss': 0.459697, 'train_loss': 749.765636, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:34,927 (server:496)INFO: {'Role': 'Server #', 'Round': 40, 'Results_avg': {'test_avg_loss': 0.509939, 'test_loss': 104.027618, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.467748, 'val_loss': 95.420533, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,927 (monitor:936)INFO: Current best: {'test_avg_loss': [0.509939], 'test_loss': [104.027618], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.467748], 'val_loss': [95.420533], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:34,928 (monitor:936)INFO: Current best: {'test_avg_loss': 0.509939, 'test_loss': 104.027618, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.467748, 'val_loss': 95.420533, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:34,930 (server:323)INFO: Server #0: Starting evaluation at the end of round 40.\n",
      "2022-12-22 19:47:34,931 (server:330)INFO: ----------- Starting a new training round (Round #41) -------------\n",
      "2022-12-22 19:47:34,964 (client:415)INFO: {'Role': 'Client #1', 'Round': 41, 'Results_raw': {'test_avg_loss': 0.508926, 'test_loss': 103.820847, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.463532, 'val_loss': 94.560558, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:34,965 (monitor:936)INFO: Current best: {'test_avg_loss': 0.508926, 'test_loss': 103.820847, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.463532, 'val_loss': 94.560558, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,116 (client:260)INFO: {'Role': 'Client #1', 'Round': 41, 'Results_raw': {'train_avg_loss': 0.455916, 'train_loss': 743.598929, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:35,118 (server:496)INFO: {'Role': 'Server #', 'Round': 41, 'Results_avg': {'test_avg_loss': 0.508926, 'test_loss': 103.820847, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.463532, 'val_loss': 94.560558, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,118 (monitor:936)INFO: Current best: {'test_avg_loss': [0.508926], 'test_loss': [103.820847], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.463532], 'val_loss': [94.560558], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:35,120 (monitor:936)INFO: Current best: {'test_avg_loss': 0.508926, 'test_loss': 103.820847, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.463532, 'val_loss': 94.560558, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,122 (server:323)INFO: Server #0: Starting evaluation at the end of round 41.\n",
      "2022-12-22 19:47:35,124 (server:330)INFO: ----------- Starting a new training round (Round #42) -------------\n",
      "2022-12-22 19:47:35,167 (client:415)INFO: {'Role': 'Client #1', 'Round': 42, 'Results_raw': {'test_avg_loss': 0.506401, 'test_loss': 103.30574, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.462551, 'val_loss': 94.360307, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,168 (monitor:936)INFO: Current best: {'test_avg_loss': 0.506401, 'test_loss': 103.30574, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.462551, 'val_loss': 94.360307, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,357 (client:260)INFO: {'Role': 'Client #1', 'Round': 42, 'Results_raw': {'train_avg_loss': 0.456846, 'train_loss': 745.115262, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:35,359 (server:496)INFO: {'Role': 'Server #', 'Round': 42, 'Results_avg': {'test_avg_loss': 0.506401, 'test_loss': 103.30574, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.462551, 'val_loss': 94.360307, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,360 (monitor:936)INFO: Current best: {'test_avg_loss': [0.506401], 'test_loss': [103.30574], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.462551], 'val_loss': [94.360307], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:35,361 (monitor:936)INFO: Current best: {'test_avg_loss': 0.506401, 'test_loss': 103.30574, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.462551, 'val_loss': 94.360307, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,363 (server:323)INFO: Server #0: Starting evaluation at the end of round 42.\n",
      "2022-12-22 19:47:35,364 (server:330)INFO: ----------- Starting a new training round (Round #43) -------------\n",
      "2022-12-22 19:47:35,409 (client:415)INFO: {'Role': 'Client #1', 'Round': 43, 'Results_raw': {'test_avg_loss': 0.506549, 'test_loss': 103.335958, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.4593, 'val_loss': 93.697297, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,410 (monitor:936)INFO: Current best: {'test_avg_loss': 0.506549, 'test_loss': 103.335958, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.4593, 'val_loss': 93.697297, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,598 (client:260)INFO: {'Role': 'Client #1', 'Round': 43, 'Results_raw': {'train_avg_loss': 0.451711, 'train_loss': 736.74087, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:35,599 (server:496)INFO: {'Role': 'Server #', 'Round': 43, 'Results_avg': {'test_avg_loss': 0.506549, 'test_loss': 103.335958, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.4593, 'val_loss': 93.697297, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,600 (monitor:936)INFO: Current best: {'test_avg_loss': [0.506549], 'test_loss': [103.335958], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.4593], 'val_loss': [93.697297], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:35,601 (monitor:936)INFO: Current best: {'test_avg_loss': 0.506549, 'test_loss': 103.335958, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.4593, 'val_loss': 93.697297, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,603 (server:323)INFO: Server #0: Starting evaluation at the end of round 43.\n",
      "2022-12-22 19:47:35,604 (server:330)INFO: ----------- Starting a new training round (Round #44) -------------\n",
      "2022-12-22 19:47:35,638 (client:415)INFO: {'Role': 'Client #1', 'Round': 44, 'Results_raw': {'test_avg_loss': 0.503048, 'test_loss': 102.621812, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.458717, 'val_loss': 93.578253, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,638 (monitor:936)INFO: Current best: {'test_avg_loss': 0.503048, 'test_loss': 102.621812, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.458717, 'val_loss': 93.578253, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,828 (client:260)INFO: {'Role': 'Client #1', 'Round': 44, 'Results_raw': {'train_avg_loss': 0.45033, 'train_loss': 734.488491, 'train_total': 1631, 'train_acc': 0.766401}}\n",
      "2022-12-22 19:47:35,830 (server:496)INFO: {'Role': 'Server #', 'Round': 44, 'Results_avg': {'test_avg_loss': 0.503048, 'test_loss': 102.621812, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.458717, 'val_loss': 93.578253, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,830 (monitor:936)INFO: Current best: {'test_avg_loss': [0.503048], 'test_loss': [102.621812], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.458717], 'val_loss': [93.578253], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:35,832 (monitor:936)INFO: Current best: {'test_avg_loss': 0.503048, 'test_loss': 102.621812, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.458717, 'val_loss': 93.578253, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:35,834 (server:323)INFO: Server #0: Starting evaluation at the end of round 44.\n",
      "2022-12-22 19:47:35,835 (server:330)INFO: ----------- Starting a new training round (Round #45) -------------\n",
      "2022-12-22 19:47:35,881 (client:415)INFO: {'Role': 'Client #1', 'Round': 45, 'Results_raw': {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:35,881 (monitor:936)INFO: Current best: {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:36,072 (client:260)INFO: {'Role': 'Client #1', 'Round': 45, 'Results_raw': {'train_avg_loss': 0.447701, 'train_loss': 730.20001, 'train_total': 1631, 'train_acc': 0.767014}}\n",
      "2022-12-22 19:47:36,073 (server:496)INFO: {'Role': 'Server #', 'Round': 45, 'Results_avg': {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:36,074 (monitor:936)INFO: Current best: {'test_avg_loss': [0.505135], 'test_loss': [103.047592], 'test_total': [204.0], 'test_acc': [0.745098], 'val_avg_loss': [0.45472], 'val_loss': [92.762793], 'val_total': [204.0], 'val_acc': [0.77451]}\n",
      "2022-12-22 19:47:36,075 (monitor:936)INFO: Current best: {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:36,076 (server:323)INFO: Server #0: Starting evaluation at the end of round 45.\n",
      "2022-12-22 19:47:36,077 (server:330)INFO: ----------- Starting a new training round (Round #46) -------------\n",
      "2022-12-22 19:47:36,117 (client:415)INFO: {'Role': 'Client #1', 'Round': 46, 'Results_raw': {'test_avg_loss': 0.503317, 'test_loss': 102.676577, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.454844, 'val_loss': 92.788249, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:36,118 (monitor:936)INFO: Current best: {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:36,309 (client:260)INFO: {'Role': 'Client #1', 'Round': 46, 'Results_raw': {'train_avg_loss': 0.443174, 'train_loss': 722.817426, 'train_total': 1631, 'train_acc': 0.765175}}\n",
      "2022-12-22 19:47:36,311 (server:496)INFO: {'Role': 'Server #', 'Round': 46, 'Results_avg': {'test_avg_loss': 0.503317, 'test_loss': 102.676577, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.454844, 'val_loss': 92.788249, 'val_total': 204.0, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:36,311 (monitor:936)INFO: Current best: {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:36,312 (monitor:936)INFO: Current best: {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204.0, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204.0, 'val_acc': 0.77451}\n",
      "2022-12-22 19:47:36,314 (server:323)INFO: Server #0: Starting evaluation at the end of round 46.\n",
      "2022-12-22 19:47:36,314 (server:330)INFO: ----------- Starting a new training round (Round #47) -------------\n",
      "2022-12-22 19:47:36,346 (client:415)INFO: {'Role': 'Client #1', 'Round': 47, 'Results_raw': {'test_avg_loss': 0.499271, 'test_loss': 101.851317, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.454731, 'val_loss': 92.765061, 'val_total': 204, 'val_acc': 0.77451}}\n",
      "2022-12-22 19:47:36,347 (monitor:936)INFO: Current best: {'test_avg_loss': 0.505135, 'test_loss': 103.047592, 'test_total': 204, 'test_acc': 0.745098, 'val_avg_loss': 0.45472, 'val_loss': 92.762793, 'val_total': 204, 'val_acc': 0.77451}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m runner \u001B[38;5;241m=\u001B[39m FedRunner(data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m      2\u001B[0m                    server_class\u001B[38;5;241m=\u001B[39mget_server_cls(init_cfg),\n\u001B[1;32m      3\u001B[0m                    client_class\u001B[38;5;241m=\u001B[39mget_client_cls(init_cfg),\n\u001B[1;32m      4\u001B[0m                    config\u001B[38;5;241m=\u001B[39minit_cfg\u001B[38;5;241m.\u001B[39mclone(),\n\u001B[1;32m      5\u001B[0m                    client_config\u001B[38;5;241m=\u001B[39mcfg_client)\n\u001B[0;32m----> 6\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:186\u001B[0m, in \u001B[0;36mFedRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    185\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mfinish_fed_runner(fl_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mbest_results\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:327\u001B[0m, in \u001B[0;36mFedRunner._handle_msg\u001B[0;34m(self, msg, rcv)\u001B[0m\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(download_bytes)\n\u001B[1;32m    326\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 327\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m[\u001B[49m\u001B[43meach_receiver\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_handlers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[each_receiver]\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(\n\u001B[1;32m    329\u001B[0m         download_bytes)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/worker/client.py:251\u001B[0m, in \u001B[0;36mClient.callback_funcs_for_model_para\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m    246\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    247\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Normal FL Mode] Client #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mID\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has been locally \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    248\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mearly stopped. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    249\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe next FL update may result in negative effect\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mlocal_converged()\n\u001B[0;32m--> 251\u001B[0m sample_size, model_para_all, results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39mshare_local_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \\\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39monline_aggr:\n\u001B[1;32m    254\u001B[0m     model_para_all \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(model_para_all)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/auxiliaries/decorators.py:7\u001B[0m, in \u001B[0;36muse_diff.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     before_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m num_samples_train, model_para, result_metric \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     after_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/trainers/trainer.py:219\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, target_data_split_name, hooks_set)\u001B[0m\n\u001B[1;32m    215\u001B[0m hooks_set \u001B[38;5;241m=\u001B[39m hooks_set \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhooks_in_train\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcheck_data_split(target_data_split_name)\n\u001B[0;32m--> 219\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_routine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_data_split_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mnum_samples_train, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_para(\n\u001B[1;32m    222\u001B[0m ), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39meval_metrics\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/trainers/trainer.py:276\u001B[0m, in \u001B[0;36mTrainer._run_routine\u001B[0;34m(self, mode, hooks_set, dataset_name)\u001B[0m\n\u001B[1;32m    274\u001B[0m     hook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx)\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 276\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcur_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_backward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/gfl/trainer/graphtrainer.py:21\u001B[0m, in \u001B[0;36mGraphMiniBatchTrainer._hook_on_batch_forward\u001B[0;34m(self, ctx)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_hook_on_batch_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, ctx):\n\u001B[1;32m     20\u001B[0m     batch \u001B[38;5;241m=\u001B[39m ctx\u001B[38;5;241m.\u001B[39mdata_batch\u001B[38;5;241m.\u001B[39mto(ctx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 21\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# TODO: deal with the type of data within the dataloader or dataset\u001B[39;00m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ctx\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtask\u001B[38;5;241m.\u001B[39mlower():\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/gfl/model/graph_level.py:137\u001B[0m, in \u001B[0;36mGNN_Net_Graph.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    134\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memb(edge_attr)\n\u001B[1;32m    136\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgnn(x, edge_index, edge_attr)\n\u001B[0;32m--> 137\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpooling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_out1_loc(x)\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[1;32m    139\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_out2(x)\u001B[38;5;241m.\u001B[39mrelu()\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/nn/pool/glob.py:57\u001B[0m, in \u001B[0;36mglobal_mean_pool\u001B[0;34m(x, batch, size)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 57\u001B[0m size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m size\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scatter(x, batch, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m, dim_size\u001B[38;5;241m=\u001B[39msize, reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "runner = FedRunner(data=data,\n",
    "                   server_class=get_server_cls(init_cfg),\n",
    "                   client_class=get_client_cls(init_cfg),\n",
    "                   config=init_cfg.clone(),\n",
    "                   client_config=cfg_client)\n",
    "_ = runner.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_5']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_6']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_7']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_8']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_9']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_10']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_11']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_12']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_13']['eval']['metrics']=['mse']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cl_list = ['client_' + str(i) for i in range(1,17)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cl_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client['client_13']['train']['local_update_steps']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for el in cl_list:\n",
    "    cfg_client[el]['train']['local_update_steps']=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg_client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
