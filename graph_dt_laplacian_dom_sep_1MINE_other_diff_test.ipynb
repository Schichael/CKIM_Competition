{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from federatedscope.register import register_data\n",
    "from federatedscope.register import register_trainer\n",
    "from federatedscope.register import register_metric\n",
    "from federatedscope.register import register_model\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#from federatedscope.contrib.model.mnist_model import call_my_net\n",
    "#register_model(\"mynet\", call_my_net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n",
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch_geometric/graphgym/logger.py:23: UserWarning: Please install 'pytorch_lightning' for using the GraphGym experiment manager via 'pip install pytorch_lightning'\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' for using the GraphGym \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE import call_laplacian_trainer\n",
    "\n",
    "register_trainer('laplacian_trainer', call_laplacian_trainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Register metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set data, model, trainer and metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from federatedscope.core.configs.config import global_cfg, CN\n",
    "cfg = global_cfg.clone()\n",
    "\n",
    "cfg.merge_from_file(\"scripts/B-FHTL_exp_scripts/Graph-DT/fed_dom_sep_MI.yaml\")\n",
    "cfg.data.save_dir = 'test_dir'\n",
    "# cfg.data.type = 'cikm_cup'\n",
    "#cfg.data.root = 'data'\n",
    "#cfg.data.shuffle=True\n",
    "#cfg.data.transform = [['ToTensor'], ['Normalize', {'mean': [0.], 'std': [1]}]]\n",
    "#cfg.model.type = 'gin'\n",
    "#cfg.model.out_channels = 10\n",
    "#cfg.model.hidden = 64\n",
    "#cfg.model.task='graph'\n",
    "#cfg.model.dropout = 0.5\n",
    "#cfg.personalization.local_param = ['encoder_atom', 'encoder', 'clf']#['node_encoder', 'clf']\n",
    "#cfg.train.batch_or_epoch = \"epoch\"\n",
    "cfg.trainer.type = 'laplacian_trainer'\n",
    "cfg.data.batch_size = 64\n",
    "# cfg.eval.metric = ['mymetric']\n",
    "cfg.params = CN()\n",
    "cfg.params.alpha=0.1\n",
    "cfg.params.csd_importance= 1e2\n",
    "cfg.params.diff_importance = 1\n",
    "cfg.params.mine_lr = 0.01\n",
    "cfg.params.eps=1e-20\n",
    "cfg.params.p=0.\n",
    "cfg.params.lam = 0.01\n",
    "cfg.params.recon_importance = 0.\n",
    "cfg.params.kld_importance = 0.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### configure other options"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#cfg.use_gpu = True 0.05 [0.02-0.03] 0.04-0.06\n",
    "#cfg.best_res_update_round_wise_key = \"test_loss\"\n",
    "\n",
    "#cfg.federate.mode = 'standalone'\n",
    "\n",
    "cfg.federate.method = \\\n",
    "    f'Laplacian_MINE_VAE_test_no_KLD'\n",
    "\n",
    "#cfg.federate.local_update_steps = 20000000\n",
    "cfg.personalization.local_update_steps = 20000000\n",
    "#cfg.finetune.local_update_steps = 20000000\n",
    "#cfg.train.local_update_steps = 1\n",
    "\n",
    "cfg.federate.total_round_num = 2000\n",
    "cfg.federate.client_num = 16\n",
    "cfg.early_stop.patience = 3000\n",
    "#cfg.train.optimizer.lr = 0.001\n",
    "#cfg.train.optimizer.weight_decay = 0.0005\n",
    "#cfg.grad.grad_clip = 2.0\n",
    "cfg.criterion.type = 'CrossEntropyLoss'\n",
    "#cfg.seed = 123\n",
    "cfg.eval.freq = 1\n",
    "cfg.eval.metrics = ['imp_ratio']\n",
    "cfg.eval.report = ['avg']\n",
    "cfg.eval.best_res_update_round_wise_key = 'val_imp_ratio'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.manual_seed(0)\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.use_deterministic_algorithms(F/home/michael/Desktop/backup files/FederatedScope/data/CIKM22Competitionalse)\n",
    "#import random\n",
    "#random.seed(0)\n",
    "#import numpy as np\n",
    "#np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from yacs.config import CfgNode\n",
    "client_cfg_file = \"scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client_theirs.yaml\"# \"scripts/B-FHTL_exp_scripts/Graph-DT/cfg_per_client_ours_lr_local_steps.yaml\"\n",
    "client_cfg = CfgNode.load_cfg(open(client_cfg_file,\n",
    "                                       'r')) if client_cfg_file else None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start the FL prosess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 20:25:54,818 (trainer_builder:11)WARNING: No module named 'federatedscope.contrib.optimizer' in `federatedscope.contrib.trainer`, some modules are not available.\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "from federatedscope.core.fed_runner import FedRunner\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 20:25:54,828 (utils:129)INFO: the current machine is at 127.0.1.1\n",
      "2023-01-10 20:25:54,829 (utils:131)INFO: the current dir is /home/michael/Master-Thesis/CKIM_Competition\n",
      "2023-01-10 20:25:54,829 (utils:132)INFO: the output dir is exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.contrib.workers.laplacian_with_domain_separation_MI_client import LaplacianDomainSeparationMIClient\n",
    "from federatedscope.contrib.workers.laplacian_server_dom_sep import LaplacianServerDomSep\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "update_logger(cfg)\n",
    "data, modified_cfg = get_data(cfg)\n",
    "cfg.merge_from_other_cfg(modified_cfg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "server params: \n",
      "encoder_atom.atom_embedding_list.0.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "2023-01-10 20:33:23,089 (fed_runner:249)INFO: Server #0 has been set up ... \n",
      "2023-01-10 20:33:23,103 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.9243\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,130 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,131 (fed_runner:302)INFO: Client 1 has been set up ... \n",
      "2023-01-10 20:33:23,141 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0265\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,170 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,171 (fed_runner:302)INFO: Client 2 has been set up ... \n",
      "2023-01-10 20:33:23,187 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.5591\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,218 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,219 (fed_runner:302)INFO: Client 3 has been set up ... \n",
      "2023-01-10 20:33:23,229 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.8026\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,254 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,255 (fed_runner:302)INFO: Client 4 has been set up ... \n",
      "2023-01-10 20:33:23,265 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.8301\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_atom.atom_embedding_list.1.weight\n",
      "encoder_atom.atom_embedding_list.2.weight\n",
      "encoder_atom.atom_embedding_list.3.weight\n",
      "encoder_atom.atom_embedding_list.4.weight\n",
      "encoder_atom.atom_embedding_list.5.weight\n",
      "encoder_atom.atom_embedding_list.6.weight\n",
      "encoder_atom.atom_embedding_list.7.weight\n",
      "encoder_atom.atom_embedding_list.8.weight\n",
      "encoder_atom.atom_embedding_list.9.weight\n",
      "encoder_atom.atom_embedding_list.10.weight\n",
      "encoder_atom.atom_embedding_list.11.weight\n",
      "encoder_atom.atom_embedding_list.12.weight\n",
      "encoder_atom.atom_embedding_list.13.weight\n",
      "encoder_atom.atom_embedding_list.14.weight\n",
      "encoder_atom.atom_embedding_list.15.weight\n",
      "encoder_atom.atom_embedding_list.16.weight\n",
      "encoder_atom.atom_embedding_list.17.weight\n",
      "encoder_atom.atom_embedding_list.18.weight\n",
      "encoder_atom.atom_embedding_list.19.weight\n",
      "encoder_atom.atom_embedding_list.20.weight\n",
      "encoder_atom.atom_embedding_list.21.weight\n",
      "encoder.weight\n",
      "encoder.bias\n",
      "local_gnn.convs.0.nn.linears.0.weight\n",
      "local_gnn.convs.0.nn.linears.0.bias\n",
      "local_gnn.convs.0.nn.linears.1.weight\n",
      "local_gnn.convs.0.nn.linears.1.bias\n",
      "local_gnn.convs.0.nn.norms.0.weight\n",
      "local_gnn.convs.0.nn.norms.0.bias\n",
      "local_gnn.convs.0.nn.norms.1.weight\n",
      "local_gnn.convs.0.nn.norms.1.bias\n",
      "local_gnn.convs.1.nn.linears.0.weight\n",
      "local_gnn.convs.1.nn.linears.0.bias\n",
      "local_gnn.convs.1.nn.linears.1.weight\n",
      "local_gnn.convs.1.nn.linears.1.bias\n",
      "local_gnn.convs.1.nn.norms.0.weight\n",
      "local_gnn.convs.1.nn.norms.0.bias\n",
      "local_gnn.convs.1.nn.norms.1.weight\n",
      "local_gnn.convs.1.nn.norms.1.bias\n",
      "global_gnn.convs.0.nn.linears.0.weight\n",
      "global_gnn.convs.0.nn.linears.0.bias\n",
      "global_gnn.convs.0.nn.linears.1.weight\n",
      "global_gnn.convs.0.nn.linears.1.bias\n",
      "global_gnn.convs.0.nn.norms.0.weight\n",
      "global_gnn.convs.0.nn.norms.0.bias\n",
      "global_gnn.convs.0.nn.norms.1.weight\n",
      "global_gnn.convs.0.nn.norms.1.bias\n",
      "global_gnn.convs.1.nn.linears.0.weight\n",
      "global_gnn.convs.1.nn.linears.0.bias\n",
      "global_gnn.convs.1.nn.linears.1.weight\n",
      "global_gnn.convs.1.nn.linears.1.bias\n",
      "global_gnn.convs.1.nn.norms.0.weight\n",
      "global_gnn.convs.1.nn.norms.0.bias\n",
      "global_gnn.convs.1.nn.norms.1.weight\n",
      "global_gnn.convs.1.nn.norms.1.bias\n",
      "fixed_gnn.convs.0.nn.linears.0.weight\n",
      "fixed_gnn.convs.0.nn.linears.0.bias\n",
      "fixed_gnn.convs.0.nn.linears.1.weight\n",
      "fixed_gnn.convs.0.nn.linears.1.bias\n",
      "fixed_gnn.convs.0.nn.norms.0.weight\n",
      "fixed_gnn.convs.0.nn.norms.0.bias\n",
      "fixed_gnn.convs.0.nn.norms.1.weight\n",
      "fixed_gnn.convs.0.nn.norms.1.bias\n",
      "fixed_gnn.convs.1.nn.linears.0.weight\n",
      "fixed_gnn.convs.1.nn.linears.0.bias\n",
      "fixed_gnn.convs.1.nn.linears.1.weight\n",
      "fixed_gnn.convs.1.nn.linears.1.bias\n",
      "fixed_gnn.convs.1.nn.norms.0.weight\n",
      "fixed_gnn.convs.1.nn.norms.0.bias\n",
      "fixed_gnn.convs.1.nn.norms.1.weight\n",
      "fixed_gnn.convs.1.nn.norms.1.bias\n",
      "mine.T.1.weight\n",
      "mine.T.1.bias\n",
      "mine.T.3.weight\n",
      "mine.T.3.bias\n",
      "mine.T.5.weight\n",
      "mine.T.5.bias\n",
      "global_linear_out1.weight\n",
      "global_linear_out1.bias\n",
      "local_linear_out1.weight\n",
      "local_linear_out1.bias\n",
      "bn_linear0_loc.weight\n",
      "bn_linear0_loc.bias\n",
      "bn_linear1_loc.weight\n",
      "bn_linear1_loc.bias\n",
      "bn_after_summation.weight\n",
      "bn_after_summation.bias\n",
      "linear_out2.0.weight\n",
      "linear_out2.0.bias\n",
      "bn_linear2.weight\n",
      "bn_linear2.bias\n",
      "clf.weight\n",
      "clf.bias\n",
      "emb.weight\n",
      "emb.bias\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 20:33:23,288 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,289 (fed_runner:302)INFO: Client 5 has been set up ... \n",
      "2023-01-10 20:33:23,299 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.954\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,323 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,324 (fed_runner:302)INFO: Client 6 has been set up ... \n",
      "2023-01-10 20:33:23,340 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.8947\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,364 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,365 (fed_runner:302)INFO: Client 7 has been set up ... \n",
      "2023-01-10 20:33:23,377 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.956\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.0001\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,398 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,400 (fed_runner:302)INFO: Client 8 has been set up ... \n",
      "2023-01-10 20:33:23,412 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.8333\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,437 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,438 (fed_runner:302)INFO: Client 9 has been set up ... \n",
      "2023-01-10 20:33:23,450 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.6381\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,471 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,472 (fed_runner:302)INFO: Client 10 has been set up ... \n",
      "2023-01-10 20:33:23,485 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.9005\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 20:33:23,510 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,512 (fed_runner:302)INFO: Client 11 has been set up ... \n",
      "2023-01-10 20:33:23,525 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.7684\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,559 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,560 (fed_runner:302)INFO: Client 12 has been set up ... \n",
      "2023-01-10 20:33:23,573 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: CrossEntropyLoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.7956\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio', 'acc']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 2\n",
      "  task: graphClassification\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,604 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,605 (fed_runner:302)INFO: Client 13 has been set up ... \n",
      "2023-01-10 20:33:23,616 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0078\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 12\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,649 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,650 (fed_runner:302)INFO: Client 14 has been set up ... \n",
      "2023-01-10 20:33:23,660 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0403\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,690 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,691 (fed_runner:302)INFO: Client 15 has been set up ... \n",
      "2023-01-10 20:33:23,703 (config:261)INFO: the used configs are: \n",
      "asyn:\n",
      "  min_received_num: 16\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data/\n",
      "  save_dir: test_dir\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: ooxx\n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: graph-dt\n",
      "device: 0\n",
      "distribute:\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 3000\n",
      "  the_smaller_the_better: False\n",
      "eval:\n",
      "  base: 0.0042\n",
      "  best_res_update_round_wise_key: val_imp_ratio\n",
      "  count_flops: False\n",
      "  freq: 1\n",
      "  metrics: ['imp_ratio']\n",
      "  monitoring: []\n",
      "  report: ['avg']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_\n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 16\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: Laplacian_MINE_VAE_test_no_KLD\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: 16\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 2000\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  use: False\n",
      "fedprox:\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: 5.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "maml:\n",
      "  use: False\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 64\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 19\n",
      "  task: graphRegression\n",
      "  type: gin\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  use: False\n",
      "outdir: exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554\n",
      "params:\n",
      "  alpha: 0.1\n",
      "  csd_importance: 100.0\n",
      "  diff_importance: 1\n",
      "  eps: 1e-20\n",
      "  kld_importance: 0.0\n",
      "  lam: 0.01\n",
      "  mine_lr: 0.01\n",
      "  p: 0.0\n",
      "  recon_importance: 0.0\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf', 'local', 'fixed']\n",
      "  local_update_steps: 20000000\n",
      "  lr: 0.1\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: epoch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.05\n",
      "    type: SGD\n",
      "    weight_decay: 0.0005\n",
      "trainer:\n",
      "  type: laplacian_trainer\n",
      "use_gpu: True\n",
      "verbose: 1\n",
      "vertical:\n",
      "  use: False\n",
      "wandb:\n",
      "  use: False\n",
      "2023-01-10 20:33:23,724 (trainer:50)WARNING: Will not use monitor in trainer with class <class 'federatedscope.contrib.trainer.laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.LaplacianDomainSeparation1MINE_Other_Diff_VAETrainer'>\n",
      "2023-01-10 20:33:23,725 (fed_runner:302)INFO: Client 16 has been set up ... \n",
      "2023-01-10 20:33:23,726 (trainer:324)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\n",
      "2023-01-10 20:33:23,728 (trainer:332)INFO: Num of original para names: 156.\n",
      "2023-01-10 20:33:23,729 (trainer:333)INFO: Num of original trainable para names: 96.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n",
      "rho: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 20:33:23,730 (trainer:335)INFO: Num of preserved para names in local update: 68. \n",
      "Preserved para names in local update: {'global_gnn.convs.0.nn.norms.1.running_mean', 'global_gnn.convs.0.nn.norms.0.bias', 'bn_linear0_loc.bias', 'bn_linear0_loc.running_mean', 'bn_after_summation.bias', 'linear_out2.0.bias', 'global_linear_out1.weight', 'global_gnn.convs.1.nn.linears.1.bias', 'bn_linear1_loc.running_var', 'linear_out2.0.weight', 'global_gnn.convs.0.nn.norms.0.weight', 'global_gnn.convs.1.nn.linears.0.weight', 'global_gnn.convs.0.nn.norms.0.running_mean', 'global_gnn.convs.0.nn.linears.1.weight', 'bn_after_summation.weight', 'bn_linear1_loc.bias', 'global_gnn.convs.1.nn.norms.1.weight', 'global_gnn.convs.1.nn.norms.0.weight', 'mine.T.3.weight', 'global_gnn.convs.0.nn.linears.0.weight', 'bn_after_summation.running_var', 'emb.bias', 'global_gnn.convs.1.nn.norms.0.bias', 'bn_linear2.running_mean', 'mine.energy_loss.T.5.weight', 'global_gnn.convs.1.nn.linears.1.weight', 'mine.energy_loss.T.3.bias', 'bn_linear2.running_var', 'mine.T.1.weight', 'mine.T.1.bias', 'global_gnn.convs.1.eps', 'global_gnn.convs.0.nn.linears.0.bias', 'bn_linear1_loc.num_batches_tracked', 'global_gnn.convs.1.nn.norms.1.num_batches_tracked', 'mine.T.3.bias', 'global_gnn.convs.1.nn.norms.1.bias', 'mine.energy_loss.T.1.weight', 'bn_after_summation.running_mean', 'bn_linear2.bias', 'bn_linear0_loc.weight', 'mine.energy_loss.T.5.bias', 'global_gnn.convs.0.nn.norms.1.weight', 'global_gnn.convs.0.nn.norms.0.num_batches_tracked', 'global_gnn.convs.1.nn.norms.0.num_batches_tracked', 'global_gnn.convs.0.nn.norms.1.running_var', 'global_gnn.convs.0.nn.linears.1.bias', 'global_gnn.convs.1.nn.norms.1.running_var', 'mine.energy_loss.T.1.bias', 'global_linear_out1.bias', 'bn_linear2.weight', 'global_gnn.convs.0.nn.norms.0.running_var', 'bn_after_summation.num_batches_tracked', 'bn_linear1_loc.weight', 'global_gnn.convs.0.nn.norms.1.num_batches_tracked', 'mine.T.5.weight', 'global_gnn.convs.0.eps', 'global_gnn.convs.1.nn.norms.0.running_var', 'bn_linear1_loc.running_mean', 'global_gnn.convs.1.nn.norms.0.running_mean', 'bn_linear0_loc.running_var', 'mine.energy_loss.T.3.weight', 'global_gnn.convs.1.nn.norms.1.running_mean', 'bn_linear0_loc.num_batches_tracked', 'emb.weight', 'global_gnn.convs.0.nn.norms.1.bias', 'bn_linear2.num_batches_tracked', 'mine.T.5.bias', 'global_gnn.convs.1.nn.linears.0.bias'}.\n",
      "2023-01-10 20:33:23,731 (trainer:339)INFO: Num of filtered para names in local update: 88. \n",
      "Filtered para names in local update: {'fixed_gnn.convs.1.nn.linears.0.weight', 'encoder_atom.atom_embedding_list.4.weight', 'encoder.weight', 'fixed_gnn.convs.1.nn.norms.1.num_batches_tracked', 'encoder_atom.atom_embedding_list.3.weight', 'fixed_gnn.convs.0.nn.linears.1.weight', 'fixed_gnn.convs.1.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.20.weight', 'local_gnn.convs.1.nn.norms.0.bias', 'fixed_gnn.convs.0.nn.norms.0.num_batches_tracked', 'local_gnn.convs.0.nn.norms.0.num_batches_tracked', 'local_gnn.convs.1.nn.norms.0.running_mean', 'fixed_gnn.convs.0.nn.norms.0.running_mean', 'fixed_gnn.convs.1.nn.norms.0.running_var', 'fixed_gnn.convs.0.nn.norms.0.weight', 'local_gnn.convs.1.nn.norms.0.weight', 'fixed_gnn.convs.1.nn.norms.0.running_mean', 'clf.bias', 'encoder_atom.atom_embedding_list.21.weight', 'fixed_gnn.convs.1.nn.norms.1.running_mean', 'fixed_gnn.convs.0.nn.norms.1.bias', 'local_gnn.convs.0.nn.norms.0.running_mean', 'clf.weight', 'fixed_gnn.convs.1.nn.norms.1.weight', 'encoder_atom.atom_embedding_list.18.weight', 'local_gnn.convs.1.nn.norms.1.bias', 'local_gnn.convs.1.nn.linears.0.bias', 'encoder_atom.atom_embedding_list.5.weight', 'local_gnn.convs.0.nn.linears.1.bias', 'local_linear_out1.weight', 'fixed_gnn.convs.0.nn.norms.1.num_batches_tracked', 'encoder_atom.atom_embedding_list.13.weight', 'local_gnn.convs.0.nn.norms.0.bias', 'local_gnn.convs.1.nn.norms.1.weight', 'fixed_gnn.convs.0.nn.norms.0.running_var', 'encoder_atom.atom_embedding_list.6.weight', 'encoder.bias', 'fixed_gnn.convs.1.eps', 'fixed_gnn.convs.0.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.2.weight', 'fixed_gnn.convs.0.nn.linears.0.weight', 'encoder_atom.atom_embedding_list.12.weight', 'local_gnn.convs.0.nn.linears.0.bias', 'fixed_gnn.convs.0.nn.linears.0.bias', 'local_gnn.convs.0.nn.norms.1.running_mean', 'local_gnn.convs.0.nn.norms.1.running_var', 'local_gnn.convs.0.nn.linears.1.weight', 'local_linear_out1.bias', 'encoder_atom.atom_embedding_list.1.weight', 'encoder_atom.atom_embedding_list.14.weight', 'encoder_atom.atom_embedding_list.11.weight', 'encoder_atom.atom_embedding_list.10.weight', 'local_gnn.convs.0.nn.linears.0.weight', 'fixed_gnn.convs.1.nn.linears.1.bias', 'fixed_gnn.convs.1.nn.norms.0.num_batches_tracked', 'fixed_gnn.convs.1.nn.norms.0.weight', 'local_gnn.convs.1.nn.norms.1.running_var', 'fixed_gnn.convs.0.nn.norms.1.running_var', 'encoder_atom.atom_embedding_list.9.weight', 'local_gnn.convs.0.nn.norms.1.bias', 'fixed_gnn.convs.0.eps', 'local_gnn.convs.0.eps', 'encoder_atom.atom_embedding_list.19.weight', 'fixed_gnn.convs.0.nn.norms.1.weight', 'local_gnn.convs.0.nn.norms.0.running_var', 'encoder_atom.atom_embedding_list.17.weight', 'fixed_gnn.convs.1.nn.norms.1.running_var', 'fixed_gnn.convs.1.nn.norms.1.bias', 'fixed_gnn.convs.0.nn.linears.1.bias', 'local_gnn.convs.1.nn.norms.1.num_batches_tracked', 'local_gnn.convs.1.nn.linears.1.bias', 'encoder_atom.atom_embedding_list.15.weight', 'local_gnn.convs.1.nn.norms.1.running_mean', 'local_gnn.convs.1.nn.norms.0.num_batches_tracked', 'local_gnn.convs.1.eps', 'local_gnn.convs.1.nn.linears.0.weight', 'fixed_gnn.convs.1.nn.linears.1.weight', 'encoder_atom.atom_embedding_list.0.weight', 'local_gnn.convs.0.nn.norms.1.weight', 'local_gnn.convs.0.nn.norms.1.num_batches_tracked', 'local_gnn.convs.0.nn.norms.0.weight', 'local_gnn.convs.1.nn.linears.1.weight', 'encoder_atom.atom_embedding_list.16.weight', 'local_gnn.convs.1.nn.norms.0.running_var', 'fixed_gnn.convs.1.nn.norms.0.bias', 'encoder_atom.atom_embedding_list.8.weight', 'fixed_gnn.convs.0.nn.norms.1.running_mean'}.\n",
      "2023-01-10 20:33:23,736 (trainer:344)INFO: After register default hooks,\n",
      "\tthe hooks_in_train is:\n",
      "\t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\",\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\",\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\n",
      "\t  ],\n",
      "\t  \"on_batch_backward\": [\n",
      "\t    \"_hook_on_batch_backward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t};\n",
      "\tthe hooks_in_eval is:\n",
      "            t{\n",
      "\t  \"on_fit_start\": [\n",
      "\t    \"_hook_on_fit_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_epoch_start\": [\n",
      "\t    \"_hook_on_epoch_start\"\n",
      "\t  ],\n",
      "\t  \"on_batch_start\": [\n",
      "\t    \"_hook_on_batch_start_init\"\n",
      "\t  ],\n",
      "\t  \"on_batch_forward\": [\n",
      "\t    \"_hook_on_batch_forward\"\n",
      "\t  ],\n",
      "\t  \"on_batch_end\": [\n",
      "\t    \"_hook_on_batch_end\"\n",
      "\t  ],\n",
      "\t  \"on_fit_end\": [\n",
      "\t    \"_hook_on_fit_end\"\n",
      "\t  ]\n",
      "\t}\n",
      "2023-01-10 20:33:23,748 (server:628)INFO: ----------- Starting training (Round #0) -------------\n",
      "2023-01-10 20:33:26,132 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_loss': 1298.065254, 'train_avg_loss': 2.535284, 'train_imp_ratio': -9467.108694, 'train_total': 512}}\n",
      "2023-01-10 20:33:26,595 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_loss': 106.193823, 'train_avg_loss': 0.707959, 'train_imp_ratio': -47.84099, 'train_acc': 0.466667, 'train_total': 150}}\n",
      "2023-01-10 20:33:27,350 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #9', 'Round': 0, 'Results_raw': {'train_loss': 183.666658, 'train_avg_loss': 0.685323, 'train_imp_ratio': -30.594239, 'train_acc': 0.578358, 'train_total': 268}}\n",
      "2023-01-10 20:33:28,069 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #10', 'Round': 0, 'Results_raw': {'train_loss': 194.05405, 'train_avg_loss': 0.695534, 'train_imp_ratio': -9.004049, 'train_acc': 0.580645, 'train_total': 279}}\n",
      "2023-01-10 20:38:45,348 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #14', 'Round': 0, 'Results_raw': {'train_loss': 4860.918242, 'train_avg_loss': 0.029994, 'train_imp_ratio': -284.53853, 'train_total': 162063}}\n",
      "2023-01-10 20:38:48,727 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_loss': 1209.878846, 'train_avg_loss': 0.741802, 'train_imp_ratio': -59.376409, 'train_acc': 0.337216, 'train_total': 1631}}\n",
      "2023-01-10 20:38:55,642 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_loss': 10672.528759, 'train_avg_loss': 3.176348, 'train_imp_ratio': -468.118042, 'train_total': 3360}}\n",
      "2023-01-10 20:45:40,453 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #15', 'Round': 0, 'Results_raw': {'train_loss': 29835.072021, 'train_avg_loss': 0.149501, 'train_imp_ratio': -270.970916, 'train_total': 199564}}\n",
      "2023-01-10 20:45:42,867 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_loss': 680.207024, 'train_avg_loss': 0.590457, 'train_imp_ratio': -9.868746, 'train_acc': 0.811632, 'train_total': 1152}}\n",
      "2023-01-10 20:45:43,599 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_loss': 199.187041, 'train_avg_loss': 0.724317, 'train_imp_ratio': -51.312286, 'train_acc': 0.465455, 'train_total': 275}}\n",
      "2023-01-10 20:49:16,303 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #16', 'Round': 0, 'Results_raw': {'train_loss': 8086.829163, 'train_avg_loss': 0.077265, 'train_imp_ratio': -1739.635095, 'train_total': 104664}}\n",
      "2023-01-10 20:49:23,200 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #12', 'Round': 0, 'Results_raw': {'train_loss': 2309.55983, 'train_avg_loss': 0.699655, 'train_imp_ratio': -35.659079, 'train_acc': 0.494396, 'train_total': 3301}}\n",
      "2023-01-10 20:49:25,698 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_loss': 841.353132, 'train_avg_loss': 0.695333, 'train_imp_ratio': -36.672756, 'train_acc': 0.508264, 'train_total': 1210}}\n",
      "2023-01-10 20:49:27,691 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_loss': 13273.671219, 'train_avg_loss': 14.732155, 'train_imp_ratio': -1493.871459, 'train_total': 901}}\n",
      "2023-01-10 20:49:31,546 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_loss': 1259.876621, 'train_avg_loss': 0.680646, 'train_imp_ratio': -42.633989, 'train_acc': 0.547272, 'train_total': 1851}}\n",
      "2023-01-10 20:49:38,513 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #13', 'Round': 0, 'Results_raw': {'train_loss': 2282.89366, 'train_avg_loss': 0.694311, 'train_imp_ratio': -35.892849, 'train_acc': 0.510036, 'train_total': 3288}}\n",
      "2023-01-10 20:49:38,615 (laplacian_server:160)INFO: Server #0: Starting evaluation at the end of round 0.\n",
      "2023-01-10 20:49:38,618 (laplacian_server:167)INFO: ----------- Starting a new training round (Round #1) -------------\n",
      "2023-01-10 20:49:38,760 (client:410)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'test_loss': 1402.329707, 'test_avg_loss': 12.409997, 'test_imp_ratio': -1242.637243, 'test_total': 113, 'val_loss': 1433.100946, 'val_avg_loss': 12.682309, 'val_imp_ratio': -1272.098794, 'val_total': 113}}\n",
      "2023-01-10 20:49:38,760 (monitor:513)INFO: current_best=-1272.098794, should_save=True\n",
      "2023-01-10 20:49:38,761 (client:431)INFO: Client: #1, val_imp_ratio: -1272.098794. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for aggregation 1: 41.37563705444336\n",
      "Time for aggregation 2: 82.2300910949707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 20:49:38,882 (client:410)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'test_loss': 81.241631, 'test_avg_loss': 1.2694, 'test_imp_ratio': -4690.190031, 'test_total': 64, 'val_loss': 75.861988, 'val_avg_loss': 1.204159, 'val_imp_ratio': -4443.994058, 'val_total': 63}}\n",
      "2023-01-10 20:49:38,884 (monitor:513)INFO: current_best=-4443.994058, should_save=True\n",
      "2023-01-10 20:49:38,884 (client:431)INFO: Client: #2, val_imp_ratio: -4443.994058. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model2.pth\n",
      "2023-01-10 20:49:39,145 (client:410)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'test_loss': 588.642463, 'test_avg_loss': 1.40153, 'test_imp_ratio': -150.676028, 'test_total': 420, 'val_loss': 573.26908, 'val_avg_loss': 1.364926, 'val_imp_ratio': -144.129197, 'val_total': 420}}\n",
      "2023-01-10 20:49:39,146 (monitor:513)INFO: current_best=-144.129197, should_save=True\n",
      "2023-01-10 20:49:39,146 (client:431)INFO: Client: #3, val_imp_ratio: -144.129197. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model3.pth\n",
      "2023-01-10 20:49:39,320 (client:410)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'test_loss': 104.952886, 'test_avg_loss': 0.69048, 'test_imp_ratio': -28.685719, 'test_acc': 0.572368, 'test_total': 152, 'val_loss': 104.584664, 'val_avg_loss': 0.692614, 'val_imp_ratio': -33.989369, 'val_acc': 0.529801, 'val_total': 151}}\n",
      "2023-01-10 20:49:39,320 (monitor:513)INFO: current_best=-33.989369, should_save=True\n",
      "2023-01-10 20:49:39,321 (client:431)INFO: Client: #4, val_imp_ratio: -33.989369. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model4.pth\n",
      "2023-01-10 20:49:39,511 (client:410)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'test_loss': 148.469754, 'test_avg_loss': 0.727793, 'test_imp_ratio': -69.29262, 'test_acc': 0.254902, 'test_total': 204, 'val_loss': 149.44619, 'val_avg_loss': 0.732579, 'val_imp_ratio': -72.835779, 'val_acc': 0.22549, 'val_total': 204}}\n",
      "2023-01-10 20:49:39,512 (monitor:513)INFO: current_best=-72.835779, should_save=True\n",
      "2023-01-10 20:49:39,514 (client:431)INFO: Client: #5, val_imp_ratio: -72.835779. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model5.pth\n",
      "2023-01-10 20:49:39,719 (client:410)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'test_loss': 160.399648, 'test_avg_loss': 0.691378, 'test_imp_ratio': -43.070917, 'test_acc': 0.543103, 'test_total': 232, 'val_loss': 159.869662, 'val_avg_loss': 0.692076, 'val_imp_ratio': -43.278245, 'val_acc': 0.541126, 'val_total': 231}}\n",
      "2023-01-10 20:49:39,720 (monitor:513)INFO: current_best=-43.278245, should_save=True\n",
      "2023-01-10 20:49:39,720 (client:431)INFO: Client: #6, val_imp_ratio: -43.278245. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model6.pth\n",
      "2023-01-10 20:49:39,819 (client:410)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'test_loss': 13.694875, 'test_avg_loss': 0.720783, 'test_imp_ratio': -64.704429, 'test_acc': 0.315789, 'test_total': 19, 'val_loss': 13.668665, 'val_avg_loss': 0.719403, 'val_imp_ratio': -64.704429, 'val_acc': 0.315789, 'val_total': 19}}\n",
      "2023-01-10 20:49:39,820 (monitor:513)INFO: current_best=-64.704429, should_save=True\n",
      "2023-01-10 20:49:39,820 (client:431)INFO: Client: #7, val_imp_ratio: -64.704429. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model7.pth\n",
      "2023-01-10 20:49:39,929 (client:410)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'test_loss': 25.134489, 'test_avg_loss': 0.718128, 'test_imp_ratio': -61.147639, 'test_acc': 0.371429, 'test_total': 35, 'val_loss': 24.012182, 'val_avg_loss': 0.706241, 'val_imp_ratio': -53.851834, 'val_acc': 0.441176, 'val_total': 34}}\n",
      "2023-01-10 20:49:39,930 (monitor:513)INFO: current_best=-53.851834, should_save=True\n",
      "2023-01-10 20:49:39,930 (client:431)INFO: Client: #8, val_imp_ratio: -53.851834. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model8.pth\n",
      "2023-01-10 20:49:40,045 (client:410)INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'test_loss': 22.473437, 'test_avg_loss': 0.660983, 'test_imp_ratio': -4.70207, 'test_acc': 0.794118, 'test_total': 34, 'val_loss': 23.518884, 'val_avg_loss': 0.691732, 'val_imp_ratio': -36.468047, 'val_acc': 0.529412, 'val_total': 34}}\n",
      "2023-01-10 20:49:40,046 (monitor:513)INFO: current_best=-36.468047, should_save=True\n",
      "2023-01-10 20:49:40,047 (client:431)INFO: Client: #9, val_imp_ratio: -36.468047. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model9.pth\n",
      "2023-01-10 20:49:40,156 (client:410)INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'test_loss': 24.138518, 'test_avg_loss': 0.689672, 'test_imp_ratio': -14.926008, 'test_acc': 0.542857, 'test_total': 35, 'val_loss': 23.926309, 'val_avg_loss': 0.683609, 'val_imp_ratio': -10.448429, 'val_acc': 0.571429, 'val_total': 35}}\n",
      "2023-01-10 20:49:40,156 (monitor:513)INFO: current_best=-10.448429, should_save=True\n",
      "2023-01-10 20:49:40,157 (client:431)INFO: Client: #10, val_imp_ratio: -10.448429. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model10.pth\n",
      "2023-01-10 20:49:40,318 (client:410)INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'test_loss': 79.115868, 'test_avg_loss': 0.549416, 'test_imp_ratio': -6.687643, 'test_acc': 0.840278, 'test_total': 144, 'val_loss': 81.162755, 'val_avg_loss': 0.56363, 'val_imp_ratio': -9.772349, 'val_acc': 0.8125, 'val_total': 144}}\n",
      "2023-01-10 20:49:40,318 (monitor:513)INFO: current_best=-9.772349, should_save=True\n",
      "2023-01-10 20:49:40,319 (client:431)INFO: Client: #11, val_imp_ratio: -9.772349. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model11.pth\n",
      "2023-01-10 20:49:40,617 (client:410)INFO: {'Role': 'Client #12', 'Round': 1, 'Results_raw': {'test_loss': 285.282805, 'test_avg_loss': 0.690757, 'test_imp_ratio': -30.675735, 'test_acc': 0.532688, 'test_total': 413, 'val_loss': 286.092804, 'val_avg_loss': 0.692719, 'val_imp_ratio': -31.936176, 'val_acc': 0.523002, 'val_total': 413}}\n",
      "2023-01-10 20:49:40,618 (monitor:513)INFO: current_best=-31.936176, should_save=True\n",
      "2023-01-10 20:49:40,619 (client:431)INFO: Client: #12, val_imp_ratio: -31.936176. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model12.pth\n",
      "2023-01-10 20:49:40,896 (client:410)INFO: {'Role': 'Client #13', 'Round': 1, 'Results_raw': {'test_loss': 284.578667, 'test_avg_loss': 0.692406, 'test_imp_ratio': -35.472349, 'test_acc': 0.513382, 'test_total': 411, 'val_loss': 287.068628, 'val_avg_loss': 0.698464, 'val_imp_ratio': -40.671259, 'val_acc': 0.472019, 'val_total': 411}}\n",
      "2023-01-10 20:49:40,896 (monitor:513)INFO: current_best=-40.671259, should_save=True\n",
      "2023-01-10 20:49:40,897 (client:431)INFO: Client: #13, val_imp_ratio: -40.671259. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model13.pth\n",
      "2023-01-10 20:49:48,754 (client:410)INFO: {'Role': 'Client #14', 'Round': 1, 'Results_raw': {'test_loss': 1941007206.875, 'test_avg_loss': 95814.355162, 'test_imp_ratio': -1228389022.596154, 'test_total': 20258, 'val_loss': 1938165621.0625, 'val_avg_loss': 95674.085352, 'val_imp_ratio': -1226590845.51282, 'val_total': 20258}}\n",
      "2023-01-10 20:49:48,754 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 20:49:59,399 (client:410)INFO: {'Role': 'Client #15', 'Round': 1, 'Results_raw': {'test_loss': 131690.236749, 'test_avg_loss': 5.279012, 'test_imp_ratio': -12999.285864, 'test_total': 24946, 'val_loss': 131522.15999, 'val_avg_loss': 5.272275, 'val_imp_ratio': -12982.566983, 'val_total': 24946}}\n",
      "2023-01-10 20:49:59,401 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 20:50:04,661 (client:410)INFO: {'Role': 'Client #16', 'Round': 1, 'Results_raw': {'test_loss': 58921696130.0, 'test_avg_loss': 4503339.661419, 'test_imp_ratio': -107222368947.61905, 'test_total': 13084, 'val_loss': 58765147047.0, 'val_avg_loss': 4491718.034625, 'val_imp_ratio': -106945666566.66666, 'val_total': 13083}}\n",
      "2023-01-10 20:50:04,662 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 20:50:11,521 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_loss': 6434.050797, 'train_avg_loss': 1.914896, 'train_imp_ratio': -242.496157, 'train_total': 3360}}\n",
      "2023-01-10 20:57:04,973 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #15', 'Round': 1, 'Results_raw': {'train_loss': 31147.205749, 'train_avg_loss': 0.156076, 'train_imp_ratio': -287.285986, 'train_total': 199564}}\n",
      "2023-01-10 20:57:11,991 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #13', 'Round': 1, 'Results_raw': {'train_loss': 2290.509299, 'train_avg_loss': 0.696627, 'train_imp_ratio': -35.816394, 'train_acc': 0.510645, 'train_total': 3288}}\n",
      "2023-01-10 20:57:12,750 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'train_loss': 190.920219, 'train_avg_loss': 0.684302, 'train_imp_ratio': -7.880643, 'train_acc': 0.587814, 'train_total': 279}}\n",
      "2023-01-10 20:57:14,797 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_loss': 11735.922381, 'train_avg_loss': 13.025441, 'train_imp_ratio': -1309.222137, 'train_total': 901}}\n",
      "2023-01-10 20:57:17,352 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_loss': 836.18714, 'train_avg_loss': 0.691064, 'train_imp_ratio': -35.643044, 'train_acc': 0.516529, 'train_total': 1210}}\n",
      "2023-01-10 20:57:20,823 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_loss': 1179.844198, 'train_avg_loss': 0.723387, 'train_imp_ratio': -53.319801, 'train_acc': 0.387492, 'train_total': 1631}}\n",
      "2023-01-10 20:57:23,292 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_loss': 630.85264, 'train_avg_loss': 0.547615, 'train_imp_ratio': -6.591246, 'train_acc': 0.841146, 'train_total': 1152}}\n",
      "2023-01-10 20:57:30,241 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #12', 'Round': 1, 'Results_raw': {'train_loss': 2298.742826, 'train_avg_loss': 0.696378, 'train_imp_ratio': -34.476341, 'train_acc': 0.503484, 'train_total': 3301}}\n",
      "2023-01-10 20:57:34,075 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_loss': 1271.022894, 'train_avg_loss': 0.686668, 'train_imp_ratio': -42.4641, 'train_acc': 0.548892, 'train_total': 1851}}\n",
      "2023-01-10 21:01:05,273 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #16', 'Round': 1, 'Results_raw': {'train_loss': 3150.29925, 'train_avg_loss': 0.030099, 'train_imp_ratio': -616.646734, 'train_total': 104664}}\n",
      "2023-01-10 21:01:05,990 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'train_loss': 184.527173, 'train_avg_loss': 0.688534, 'train_imp_ratio': -35.07203, 'train_acc': 0.541045, 'train_total': 268}}\n",
      "2023-01-10 21:06:31,456 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #14', 'Round': 1, 'Results_raw': {'train_loss': 4028.863934, 'train_avg_loss': 0.02486, 'train_imp_ratio': -218.716161, 'train_total': 162063}}\n",
      "2023-01-10 21:06:32,224 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_loss': 196.32338, 'train_avg_loss': 0.713903, 'train_imp_ratio': -51.312286, 'train_acc': 0.465455, 'train_total': 275}}\n",
      "2023-01-10 21:06:32,677 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_loss': 105.465832, 'train_avg_loss': 0.703106, 'train_imp_ratio': -50.821504, 'train_acc': 0.44, 'train_total': 150}}\n",
      "2023-01-10 21:06:33,793 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_loss': 437.435776, 'train_avg_loss': 0.854367, 'train_imp_ratio': -3124.025357, 'train_total': 512}}\n",
      "2023-01-10 21:06:33,797 (server:480)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_loss': 3803927390.472906, 'test_avg_loss': 287448.82552, 'test_imp_ratio': -6778173588.273094, 'test_total': 3785.25, 'val_loss': 3793965464.112829, 'val_avg_loss': 286713.719795, 'val_imp_ratio': -6760767290.807777, 'val_total': 3784.9375, 'test_acc': 0.528091, 'val_acc': 0.496175}}\n",
      "2023-01-10 21:06:33,798 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 21:06:33,798 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 21:06:33,932 (laplacian_server:160)INFO: Server #0: Starting evaluation at the end of round 1.\n",
      "2023-01-10 21:06:33,936 (laplacian_server:167)INFO: ----------- Starting a new training round (Round #2) -------------\n",
      "2023-01-10 21:06:34,082 (client:410)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'test_loss': 1375.829936, 'test_avg_loss': 12.175486, 'test_imp_ratio': -1217.265667, 'test_total': 113, 'val_loss': 1404.262461, 'val_avg_loss': 12.427101, 'val_imp_ratio': -1244.487843, 'val_total': 113}}\n",
      "2023-01-10 21:06:34,083 (monitor:513)INFO: current_best=-1244.487843, should_save=True\n",
      "2023-01-10 21:06:34,083 (client:431)INFO: Client: #1, val_imp_ratio: -1244.487843. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for aggregation 1: 46.22793197631836\n",
      "Time for aggregation 2: 106.7957878112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 21:06:34,206 (client:410)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'test_loss': 65.321632, 'test_avg_loss': 1.020651, 'test_imp_ratio': -3751.511793, 'test_total': 64, 'val_loss': 60.661054, 'val_avg_loss': 0.962874, 'val_imp_ratio': -3533.4861, 'val_total': 63}}\n",
      "2023-01-10 21:06:34,207 (monitor:513)INFO: current_best=-3533.4861, should_save=True\n",
      "2023-01-10 21:06:34,208 (client:431)INFO: Client: #2, val_imp_ratio: -3533.4861. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model2.pth\n",
      "2023-01-10 21:06:34,496 (client:410)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'test_loss': 695.010515, 'test_avg_loss': 1.654787, 'test_imp_ratio': -195.97334, 'test_total': 420, 'val_loss': 714.266716, 'val_avg_loss': 1.700635, 'val_imp_ratio': -204.173685, 'val_total': 420}}\n",
      "2023-01-10 21:06:34,498 (monitor:513)INFO: current_best=-144.129197, should_save=False\n",
      "2023-01-10 21:06:34,672 (client:410)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'test_loss': 104.966623, 'test_avg_loss': 0.69057, 'test_imp_ratio': -28.685719, 'test_acc': 0.572368, 'test_total': 152, 'val_loss': 104.651981, 'val_avg_loss': 0.693059, 'val_imp_ratio': -33.989369, 'val_acc': 0.529801, 'val_total': 151}}\n",
      "2023-01-10 21:06:34,673 (monitor:513)INFO: current_best=-33.989369, should_save=True\n",
      "2023-01-10 21:06:34,674 (client:431)INFO: Client: #4, val_imp_ratio: -33.989369. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model4.pth\n",
      "2023-01-10 21:06:34,890 (client:410)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'test_loss': 148.122039, 'test_avg_loss': 0.726088, 'test_imp_ratio': -69.29262, 'test_acc': 0.254902, 'test_total': 204, 'val_loss': 149.084876, 'val_avg_loss': 0.730808, 'val_imp_ratio': -72.835779, 'val_acc': 0.22549, 'val_total': 204}}\n",
      "2023-01-10 21:06:34,891 (monitor:513)INFO: current_best=-72.835779, should_save=True\n",
      "2023-01-10 21:06:34,891 (client:431)INFO: Client: #5, val_imp_ratio: -72.835779. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model5.pth\n",
      "2023-01-10 21:06:35,099 (client:410)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'test_loss': 159.182971, 'test_avg_loss': 0.686133, 'test_imp_ratio': -42.167281, 'test_acc': 0.551724, 'test_total': 232, 'val_loss': 158.515844, 'val_avg_loss': 0.686216, 'val_imp_ratio': -41.916923, 'val_acc': 0.554113, 'val_total': 231}}\n",
      "2023-01-10 21:06:35,100 (monitor:513)INFO: current_best=-41.916923, should_save=True\n",
      "2023-01-10 21:06:35,100 (client:431)INFO: Client: #6, val_imp_ratio: -41.916923. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model6.pth\n",
      "2023-01-10 21:06:35,217 (client:410)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'test_loss': 13.561762, 'test_avg_loss': 0.713777, 'test_imp_ratio': -64.704429, 'test_acc': 0.315789, 'test_total': 19, 'val_loss': 13.545555, 'val_avg_loss': 0.712924, 'val_imp_ratio': -64.704429, 'val_acc': 0.315789, 'val_total': 19}}\n",
      "2023-01-10 21:06:35,218 (monitor:513)INFO: current_best=-64.704429, should_save=True\n",
      "2023-01-10 21:06:35,219 (client:431)INFO: Client: #7, val_imp_ratio: -64.704429. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model7.pth\n",
      "2023-01-10 21:06:35,336 (client:410)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'test_loss': 25.178975, 'test_avg_loss': 0.719399, 'test_imp_ratio': -61.147639, 'test_acc': 0.371429, 'test_total': 35, 'val_loss': 24.023612, 'val_avg_loss': 0.706577, 'val_imp_ratio': -53.851834, 'val_acc': 0.441176, 'val_total': 34}}\n",
      "2023-01-10 21:06:35,337 (monitor:513)INFO: current_best=-53.851834, should_save=True\n",
      "2023-01-10 21:06:35,338 (client:431)INFO: Client: #8, val_imp_ratio: -53.851834. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model8.pth\n",
      "2023-01-10 21:06:35,461 (client:410)INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'test_loss': 22.3862, 'test_avg_loss': 0.658418, 'test_imp_ratio': -4.70207, 'test_acc': 0.794118, 'test_total': 34, 'val_loss': 23.515163, 'val_avg_loss': 0.691622, 'val_imp_ratio': -36.468047, 'val_acc': 0.529412, 'val_total': 34}}\n",
      "2023-01-10 21:06:35,462 (monitor:513)INFO: current_best=-36.468047, should_save=True\n",
      "2023-01-10 21:06:35,463 (client:431)INFO: Client: #9, val_imp_ratio: -36.468047. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model9.pth\n",
      "2023-01-10 21:06:35,569 (client:410)INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'test_loss': 24.126268, 'test_avg_loss': 0.689322, 'test_imp_ratio': -14.926008, 'test_acc': 0.542857, 'test_total': 35, 'val_loss': 23.930264, 'val_avg_loss': 0.683722, 'val_imp_ratio': -10.448429, 'val_acc': 0.571429, 'val_total': 35}}\n",
      "2023-01-10 21:06:35,570 (monitor:513)INFO: current_best=-10.448429, should_save=True\n",
      "2023-01-10 21:06:35,571 (client:431)INFO: Client: #10, val_imp_ratio: -10.448429. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model10.pth\n",
      "2023-01-10 21:06:35,743 (client:410)INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'test_loss': 79.514711, 'test_avg_loss': 0.552185, 'test_imp_ratio': -6.687643, 'test_acc': 0.840278, 'test_total': 144, 'val_loss': 81.295774, 'val_avg_loss': 0.564554, 'val_imp_ratio': -9.772349, 'val_acc': 0.8125, 'val_total': 144}}\n",
      "2023-01-10 21:06:35,744 (monitor:513)INFO: current_best=-9.772349, should_save=True\n",
      "2023-01-10 21:06:35,745 (client:431)INFO: Client: #11, val_imp_ratio: -9.772349. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model11.pth\n",
      "2023-01-10 21:06:36,051 (client:410)INFO: {'Role': 'Client #12', 'Round': 2, 'Results_raw': {'test_loss': 285.517846, 'test_avg_loss': 0.691327, 'test_imp_ratio': -30.675735, 'test_acc': 0.532688, 'test_total': 413, 'val_loss': 286.022954, 'val_avg_loss': 0.69255, 'val_imp_ratio': -31.936176, 'val_acc': 0.523002, 'val_total': 413}}\n",
      "2023-01-10 21:06:36,057 (monitor:513)INFO: current_best=-31.936176, should_save=True\n",
      "2023-01-10 21:06:36,058 (client:431)INFO: Client: #12, val_imp_ratio: -31.936176. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model12.pth\n",
      "2023-01-10 21:06:36,367 (client:410)INFO: {'Role': 'Client #13', 'Round': 2, 'Results_raw': {'test_loss': 284.189789, 'test_avg_loss': 0.691459, 'test_imp_ratio': -35.16653, 'test_acc': 0.515815, 'test_total': 411, 'val_loss': 286.217151, 'val_avg_loss': 0.696392, 'val_imp_ratio': -40.671259, 'val_acc': 0.472019, 'val_total': 411}}\n",
      "2023-01-10 21:06:36,368 (monitor:513)INFO: current_best=-40.671259, should_save=True\n",
      "2023-01-10 21:06:36,369 (client:431)INFO: Client: #13, val_imp_ratio: -40.671259. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model13.pth\n",
      "2023-01-10 21:06:45,003 (client:410)INFO: {'Role': 'Client #14', 'Round': 2, 'Results_raw': {'test_loss': 506.198869, 'test_avg_loss': 0.024988, 'test_imp_ratio': -220.35388, 'test_total': 20258, 'val_loss': 504.700119, 'val_avg_loss': 0.024914, 'val_imp_ratio': -219.405387, 'val_total': 20258}}\n",
      "2023-01-10 21:06:45,004 (monitor:513)INFO: current_best=-219.405387, should_save=True\n",
      "2023-01-10 21:06:45,005 (client:431)INFO: Client: #14, val_imp_ratio: -219.405387. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model14.pth\n",
      "2023-01-10 21:06:55,565 (client:410)INFO: {'Role': 'Client #15', 'Round': 2, 'Results_raw': {'test_loss': 4071.881094, 'test_avg_loss': 0.163228, 'test_imp_ratio': -305.031827, 'test_total': 24946, 'val_loss': 4111.350646, 'val_avg_loss': 0.16481, 'val_imp_ratio': -308.957895, 'val_total': 24946}}\n",
      "2023-01-10 21:06:55,567 (monitor:513)INFO: current_best=-308.957895, should_save=True\n",
      "2023-01-10 21:06:55,568 (client:431)INFO: Client: #15, val_imp_ratio: -308.957895. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model15.pth\n",
      "2023-01-10 21:07:00,880 (client:410)INFO: {'Role': 'Client #16', 'Round': 2, 'Results_raw': {'test_loss': 30512.412182, 'test_avg_loss': 2.33204, 'test_imp_ratio': -55424.763607, 'test_total': 13084, 'val_loss': 30332.053562, 'val_avg_loss': 2.318433, 'val_imp_ratio': -55100.769788, 'val_total': 13083}}\n",
      "2023-01-10 21:07:00,881 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 21:07:05,003 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_loss': 1267.887405, 'train_avg_loss': 0.684974, 'train_imp_ratio': -41.784542, 'train_acc': 0.555375, 'train_total': 1851}}\n",
      "2023-01-10 21:12:46,045 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #14', 'Round': 2, 'Results_raw': {'train_loss': 4131.607591, 'train_avg_loss': 0.025494, 'train_imp_ratio': -226.844052, 'train_total': 162063}}\n",
      "2023-01-10 21:12:46,764 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_loss': 197.403789, 'train_avg_loss': 0.717832, 'train_imp_ratio': -51.312286, 'train_acc': 0.465455, 'train_total': 275}}\n",
      "2023-01-10 21:12:51,476 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_loss': 1178.400919, 'train_avg_loss': 0.722502, 'train_imp_ratio': -53.393662, 'train_acc': 0.386879, 'train_total': 1631}}\n",
      "2023-01-10 21:12:55,217 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_loss': 635.151917, 'train_avg_loss': 0.551347, 'train_imp_ratio': -6.494849, 'train_acc': 0.842014, 'train_total': 1152}}\n",
      "2023-01-10 21:19:54,857 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #15', 'Round': 2, 'Results_raw': {'train_loss': 37458.975798, 'train_avg_loss': 0.187704, 'train_imp_ratio': -365.76689, 'train_total': 199564}}\n",
      "2023-01-10 21:19:55,309 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_loss': 105.431158, 'train_avg_loss': 0.702874, 'train_imp_ratio': -50.076376, 'train_acc': 0.446667, 'train_total': 150}}\n",
      "2023-01-10 21:20:02,328 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #12', 'Round': 2, 'Results_raw': {'train_loss': 2297.276048, 'train_avg_loss': 0.695933, 'train_imp_ratio': -33.214755, 'train_acc': 0.513178, 'train_total': 3301}}\n",
      "2023-01-10 21:20:03,048 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'train_loss': 191.255094, 'train_avg_loss': 0.685502, 'train_imp_ratio': -13.497677, 'train_acc': 0.551971, 'train_total': 279}}\n",
      "2023-01-10 21:20:10,004 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #13', 'Round': 2, 'Results_raw': {'train_loss': 2282.720497, 'train_avg_loss': 0.694258, 'train_imp_ratio': -35.395894, 'train_acc': 0.51399, 'train_total': 3288}}\n",
      "2023-01-10 21:20:11,113 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_loss': 370.592432, 'train_avg_loss': 0.723813, 'train_imp_ratio': -2631.371376, 'train_total': 512}}\n",
      "2023-01-10 21:20:11,807 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'train_loss': 182.572902, 'train_avg_loss': 0.681242, 'train_imp_ratio': -28.355343, 'train_acc': 0.597015, 'train_total': 268}}\n",
      "2023-01-10 21:20:14,307 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_loss': 835.431663, 'train_avg_loss': 0.690439, 'train_imp_ratio': -34.716304, 'train_acc': 0.523967, 'train_total': 1210}}\n",
      "2023-01-10 21:20:21,258 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_loss': 5996.499832, 'train_avg_loss': 1.784673, 'train_imp_ratio': -219.204546, 'train_total': 3360}}\n",
      "2023-01-10 21:20:23,277 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_loss': 11427.468362, 'train_avg_loss': 12.683095, 'train_imp_ratio': -1272.183812, 'train_total': 901}}\n",
      "2023-01-10 21:24:12,762 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #16', 'Round': 2, 'Results_raw': {'train_loss': 3289.245059, 'train_avg_loss': 0.031427, 'train_imp_ratio': -648.254802, 'train_total': 104664}}\n",
      "2023-01-10 21:24:12,764 (server:480)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_loss': 2398.337588, 'test_avg_loss': 1.511866, 'test_imp_ratio': -3842.065987, 'test_total': 3785.25, 'val_loss': 2392.381108, 'val_avg_loss': 1.528574, 'val_imp_ratio': -3812.992206, 'val_total': 3784.9375, 'test_acc': 0.529197, 'val_acc': 0.497473}}\n",
      "2023-01-10 21:24:12,765 (monitor:513)INFO: current_best=-10000, should_save=False\n",
      "2023-01-10 21:24:12,765 (monitor:513)INFO: current_best=-3812.992206, should_save=True\n",
      "2023-01-10 21:24:12,866 (laplacian_server:160)INFO: Server #0: Starting evaluation at the end of round 2.\n",
      "2023-01-10 21:24:12,868 (laplacian_server:167)INFO: ----------- Starting a new training round (Round #3) -------------\n",
      "2023-01-10 21:24:13,013 (client:410)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_loss': 1349.723986, 'test_avg_loss': 11.94446, 'test_imp_ratio': -1192.271002, 'test_total': 113, 'val_loss': 1376.220061, 'val_avg_loss': 12.178939, 'val_imp_ratio': -1217.639275, 'val_total': 113}}\n",
      "2023-01-10 21:24:13,014 (monitor:513)INFO: current_best=-1217.639275, should_save=True\n",
      "2023-01-10 21:24:13,014 (client:431)INFO: Client: #1, val_imp_ratio: -1217.639275. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for aggregation 1: 39.162635803222656\n",
      "Time for aggregation 2: 81.92682266235352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 21:24:13,128 (client:410)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'test_loss': 48.265923, 'test_avg_loss': 0.754155, 'test_imp_ratio': -2745.868075, 'test_total': 64, 'val_loss': 44.689132, 'val_avg_loss': 0.709351, 'val_imp_ratio': -2576.797363, 'val_total': 63}}\n",
      "2023-01-10 21:24:13,129 (monitor:513)INFO: current_best=-2576.797363, should_save=True\n",
      "2023-01-10 21:24:13,131 (client:431)INFO: Client: #2, val_imp_ratio: -2576.797363. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model2.pth\n",
      "2023-01-10 21:24:13,410 (client:410)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'test_loss': 673.922431, 'test_avg_loss': 1.604577, 'test_imp_ratio': -186.992879, 'test_total': 420, 'val_loss': 687.857094, 'val_avg_loss': 1.637755, 'val_imp_ratio': -192.927032, 'val_total': 420}}\n",
      "2023-01-10 21:24:13,411 (monitor:513)INFO: current_best=-144.129197, should_save=False\n",
      "2023-01-10 21:24:13,573 (client:410)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'test_loss': 104.905148, 'test_avg_loss': 0.690165, 'test_imp_ratio': -29.505423, 'test_acc': 0.565789, 'test_total': 152, 'val_loss': 104.682305, 'val_avg_loss': 0.69326, 'val_imp_ratio': -33.989369, 'val_acc': 0.529801, 'val_total': 151}}\n",
      "2023-01-10 21:24:13,574 (monitor:513)INFO: current_best=-33.989369, should_save=True\n",
      "2023-01-10 21:24:13,575 (client:431)INFO: Client: #4, val_imp_ratio: -33.989369. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model4.pth\n",
      "2023-01-10 21:24:13,774 (client:410)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'test_loss': 147.472438, 'test_avg_loss': 0.722904, 'test_imp_ratio': -68.702094, 'test_acc': 0.259804, 'test_total': 204, 'val_loss': 148.216666, 'val_avg_loss': 0.726552, 'val_imp_ratio': -72.835779, 'val_acc': 0.22549, 'val_total': 204}}\n",
      "2023-01-10 21:24:13,775 (monitor:513)INFO: current_best=-72.835779, should_save=True\n",
      "2023-01-10 21:24:13,775 (client:431)INFO: Client: #5, val_imp_ratio: -72.835779. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model5.pth\n",
      "2023-01-10 21:24:13,965 (client:410)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'test_loss': 159.435733, 'test_avg_loss': 0.687223, 'test_imp_ratio': -44.87819, 'test_acc': 0.525862, 'test_total': 232, 'val_loss': 158.042491, 'val_avg_loss': 0.684167, 'val_imp_ratio': -42.824471, 'val_acc': 0.545455, 'val_total': 231}}\n",
      "2023-01-10 21:24:13,966 (monitor:513)INFO: current_best=-41.916923, should_save=False\n",
      "2023-01-10 21:24:14,074 (client:410)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'test_loss': 13.501167, 'test_avg_loss': 0.710588, 'test_imp_ratio': -64.704429, 'test_acc': 0.315789, 'test_total': 19, 'val_loss': 13.481401, 'val_avg_loss': 0.709547, 'val_imp_ratio': -64.704429, 'val_acc': 0.315789, 'val_total': 19}}\n",
      "2023-01-10 21:24:14,074 (monitor:513)INFO: current_best=-64.704429, should_save=True\n",
      "2023-01-10 21:24:14,075 (client:431)INFO: Client: #7, val_imp_ratio: -64.704429. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model7.pth\n",
      "2023-01-10 21:24:14,187 (client:410)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'test_loss': 25.234882, 'test_avg_loss': 0.720997, 'test_imp_ratio': -61.147639, 'test_acc': 0.371429, 'test_total': 35, 'val_loss': 24.023209, 'val_avg_loss': 0.706565, 'val_imp_ratio': -53.851834, 'val_acc': 0.441176, 'val_total': 34}}\n",
      "2023-01-10 21:24:14,188 (monitor:513)INFO: current_best=-53.851834, should_save=True\n",
      "2023-01-10 21:24:14,189 (client:431)INFO: Client: #8, val_imp_ratio: -53.851834. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model8.pth\n",
      "2023-01-10 21:24:14,305 (client:410)INFO: {'Role': 'Client #9', 'Round': 3, 'Results_raw': {'test_loss': 22.363515, 'test_avg_loss': 0.65775, 'test_imp_ratio': -4.70207, 'test_acc': 0.794118, 'test_total': 34, 'val_loss': 23.505255, 'val_avg_loss': 0.691331, 'val_imp_ratio': -36.468047, 'val_acc': 0.529412, 'val_total': 34}}\n",
      "2023-01-10 21:24:14,306 (monitor:513)INFO: current_best=-36.468047, should_save=True\n",
      "2023-01-10 21:24:14,307 (client:431)INFO: Client: #9, val_imp_ratio: -36.468047. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model9.pth\n",
      "2023-01-10 21:24:14,409 (client:410)INFO: {'Role': 'Client #10', 'Round': 3, 'Results_raw': {'test_loss': 24.123107, 'test_avg_loss': 0.689232, 'test_imp_ratio': -14.926008, 'test_acc': 0.542857, 'test_total': 35, 'val_loss': 23.925454, 'val_avg_loss': 0.683584, 'val_imp_ratio': -10.448429, 'val_acc': 0.571429, 'val_total': 35}}\n",
      "2023-01-10 21:24:14,410 (monitor:513)INFO: current_best=-10.448429, should_save=True\n",
      "2023-01-10 21:24:14,411 (client:431)INFO: Client: #10, val_imp_ratio: -10.448429. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model10.pth\n",
      "2023-01-10 21:24:14,572 (client:410)INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'test_loss': 80.388565, 'test_avg_loss': 0.558254, 'test_imp_ratio': -6.687643, 'test_acc': 0.840278, 'test_total': 144, 'val_loss': 81.840772, 'val_avg_loss': 0.568339, 'val_imp_ratio': -9.772349, 'val_acc': 0.8125, 'val_total': 144}}\n",
      "2023-01-10 21:24:14,573 (monitor:513)INFO: current_best=-9.772349, should_save=True\n",
      "2023-01-10 21:24:14,573 (client:431)INFO: Client: #11, val_imp_ratio: -9.772349. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model11.pth\n",
      "2023-01-10 21:24:14,865 (client:410)INFO: {'Role': 'Client #12', 'Round': 3, 'Results_raw': {'test_loss': 285.755681, 'test_avg_loss': 0.691902, 'test_imp_ratio': -30.675735, 'test_acc': 0.532688, 'test_total': 413, 'val_loss': 286.048471, 'val_avg_loss': 0.692611, 'val_imp_ratio': -31.936176, 'val_acc': 0.523002, 'val_total': 413}}\n",
      "2023-01-10 21:24:14,866 (monitor:513)INFO: current_best=-31.936176, should_save=True\n",
      "2023-01-10 21:24:14,867 (client:431)INFO: Client: #12, val_imp_ratio: -31.936176. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model12.pth\n",
      "2023-01-10 21:24:15,160 (client:410)INFO: {'Role': 'Client #13', 'Round': 3, 'Results_raw': {'test_loss': 283.944618, 'test_avg_loss': 0.690863, 'test_imp_ratio': -33.943257, 'test_acc': 0.525547, 'test_total': 411, 'val_loss': 286.092332, 'val_avg_loss': 0.696088, 'val_imp_ratio': -40.671259, 'val_acc': 0.472019, 'val_total': 411}}\n",
      "2023-01-10 21:24:15,161 (monitor:513)INFO: current_best=-40.671259, should_save=True\n",
      "2023-01-10 21:24:15,162 (client:431)INFO: Client: #13, val_imp_ratio: -40.671259. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model13.pth\n",
      "2023-01-10 21:24:23,599 (client:410)INFO: {'Role': 'Client #14', 'Round': 3, 'Results_raw': {'test_loss': 429.539858, 'test_avg_loss': 0.021203, 'test_imp_ratio': -171.839376, 'test_total': 20258, 'val_loss': 427.479313, 'val_avg_loss': 0.021102, 'val_imp_ratio': -170.535286, 'val_total': 20258}}\n",
      "2023-01-10 21:24:23,600 (monitor:513)INFO: current_best=-170.535286, should_save=True\n",
      "2023-01-10 21:24:23,601 (client:431)INFO: Client: #14, val_imp_ratio: -170.535286. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model14.pth\n",
      "2023-01-10 21:24:35,136 (client:410)INFO: {'Role': 'Client #15', 'Round': 3, 'Results_raw': {'test_loss': 4974.020121, 'test_avg_loss': 0.199391, 'test_imp_ratio': -394.767951, 'test_total': 24946, 'val_loss': 5019.991193, 'val_avg_loss': 0.201234, 'val_imp_ratio': -399.340722, 'val_total': 24946}}\n",
      "2023-01-10 21:24:35,138 (monitor:513)INFO: current_best=-308.957895, should_save=False\n",
      "2023-01-10 21:24:40,481 (client:410)INFO: {'Role': 'Client #16', 'Round': 3, 'Results_raw': {'test_loss': 1050.552296, 'test_avg_loss': 0.080293, 'test_imp_ratio': -1811.735251, 'test_total': 13084, 'val_loss': 1067.499467, 'val_avg_loss': 0.081594, 'val_imp_ratio': -1842.723635, 'val_total': 13083}}\n",
      "2023-01-10 21:24:40,482 (monitor:513)INFO: current_best=-1842.723635, should_save=True\n",
      "2023-01-10 21:24:40,483 (client:431)INFO: Client: #16, val_imp_ratio: -1842.723635. model saved at exp/test_dir/Laplacian_MINE_VAE_test_no_KLD_gin_on_graph-dt_lr0.1_lstep1_/sub_exp_20230110202554/model16.pth\n",
      "2023-01-10 21:24:47,787 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #12', 'Round': 3, 'Results_raw': {'train_loss': 2301.697499, 'train_avg_loss': 0.697273, 'train_imp_ratio': -34.712889, 'train_acc': 0.501666, 'train_total': 3301}}\n",
      "2023-01-10 21:24:48,585 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #9', 'Round': 3, 'Results_raw': {'train_loss': 182.75788, 'train_avg_loss': 0.681932, 'train_imp_ratio': -30.14646, 'train_acc': 0.58209, 'train_total': 268}}\n",
      "2023-01-10 21:24:49,645 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_loss': 315.587158, 'train_avg_loss': 0.616381, 'train_imp_ratio': -2225.966673, 'train_total': 512}}\n",
      "2023-01-10 21:24:53,581 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'train_loss': 1259.959455, 'train_avg_loss': 0.680691, 'train_imp_ratio': -40.991724, 'train_acc': 0.562939, 'train_total': 1851}}\n",
      "2023-01-10 21:24:54,035 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'train_loss': 107.148764, 'train_avg_loss': 0.714325, 'train_imp_ratio': -58.272792, 'train_acc': 0.373333, 'train_total': 150}}\n",
      "2023-01-10 21:30:33,678 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #14', 'Round': 3, 'Results_raw': {'train_loss': 4542.362179, 'train_avg_loss': 0.028028, 'train_imp_ratio': -259.338087, 'train_total': 162063}}\n",
      "2023-01-10 21:30:34,405 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #10', 'Round': 3, 'Results_raw': {'train_loss': 194.12937, 'train_avg_loss': 0.695804, 'train_imp_ratio': -6.195532, 'train_acc': 0.598566, 'train_total': 279}}\n",
      "2023-01-10 21:34:06,040 (laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client:144)INFO: {'Role': 'Client #16', 'Round': 3, 'Results_raw': {'train_loss': 3714.951978, 'train_avg_loss': 0.035494, 'train_imp_ratio': -745.097005, 'train_total': 104664}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn [10], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m Fed_runner \u001B[38;5;241m=\u001B[39m FedRunner(data\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m      5\u001B[0m                        server_class\u001B[38;5;241m=\u001B[39mLaplacianServer,\n\u001B[1;32m      6\u001B[0m                        client_class\u001B[38;5;241m=\u001B[39mLaplacianDomainSeparation1MINEOtherDiffClient,\n\u001B[1;32m      7\u001B[0m                        config\u001B[38;5;241m=\u001B[39mcfg\u001B[38;5;241m.\u001B[39mclone(),\n\u001B[1;32m      8\u001B[0m                        client_config\u001B[38;5;241m=\u001B[39mclient_cfg)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mFed_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:186\u001B[0m, in \u001B[0;36mFedRunner.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    185\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue\u001B[38;5;241m.\u001B[39mpopleft()\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mfinish_fed_runner(fl_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/fed_runner.py:325\u001B[0m, in \u001B[0;36mFedRunner._handle_msg\u001B[0;34m(self, msg, rcv)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 325\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m[\u001B[49m\u001B[43meach_receiver\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_handlers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmsg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmsg_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[each_receiver]\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mtrack_download_bytes(\n\u001B[1;32m    327\u001B[0m         download_bytes)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/workers/laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client.py:135\u001B[0m, in \u001B[0;36mLaplacianDomainSeparation1MINEOtherDiffClient.callback_funcs_for_model_para\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_monitor\u001B[38;5;241m.\u001B[39mlocal_converged()\n\u001B[0;32m--> 135\u001B[0m sample_size, model_para_all, omega_set, results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39mshare_local_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \\\n\u001B[1;32m    137\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39monline_aggr:\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/auxiliaries/decorators.py:28\u001B[0m, in \u001B[0;36muse_diff_laplacian.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     26\u001B[0m     before_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(target_data_split_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m num_samples_train, model_para, omega, result_metric \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39muse_diff:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# TODO: any issue for subclasses?\u001B[39;00m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.py:309\u001B[0m, in \u001B[0;36mLaplacianDomainSeparation1MINE_Other_Diff_VAETrainer.train\u001B[0;34m(self, state, target_data_split_name, hooks_set)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcheck_data_split(target_data_split_name)\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_routine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODE\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_data_split_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_round \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/core/trainers/trainer.py:276\u001B[0m, in \u001B[0;36mTrainer._run_routine\u001B[0;34m(self, mode, hooks_set, dataset_name)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m hooks_set[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_batch_forward\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 276\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx\u001B[38;5;241m.\u001B[39mcur_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/contrib/trainer/laplacian_trainer_with_domain_separation_with_summation_1MINE_otherDiffLoss_VAE.py:143\u001B[0m, in \u001B[0;36mLaplacianDomainSeparation1MINE_Other_Diff_VAETrainer._hook_on_batch_forward\u001B[0;34m(self, ctx)\u001B[0m\n\u001B[1;32m    142\u001B[0m batch \u001B[38;5;241m=\u001B[39m ctx\u001B[38;5;241m.\u001B[39mdata_batch\u001B[38;5;241m.\u001B[39mto(ctx\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 143\u001B[0m pred, kld_loss, rec_loss, diff_local_global, mi_global_fixed \u001B[38;5;241m=\u001B[39m \u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m ctx\u001B[38;5;241m.\u001B[39mdiff_local_global \u001B[38;5;241m=\u001B[39m diff_local_global\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/gfl/model/graph_level.py:284\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    283\u001B[0m initial \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(input_dim, output_dim) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m init_range \u001B[38;5;241m-\u001B[39m init_range\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mParameter(initial)\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/federatedscope/gfl/model/graph_level.py:78\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(self, input1, input2)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"GNN model with pre-linear layer, pooling layer\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m    and output layer for graph classification tasks.\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;124;03mArguments:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124;03m    pooling (str): pooling method, use (\"add\", \"mean\" or \"max\").\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m---> 78\u001B[0m              in_channels,\n\u001B[1;32m     79\u001B[0m              out_channels,\n\u001B[1;32m     80\u001B[0m              hidden\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m,\n\u001B[1;32m     81\u001B[0m              max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     82\u001B[0m              dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.0\u001B[39m,\n\u001B[1;32m     83\u001B[0m              gnn\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgcn\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     84\u001B[0m              pooling\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     85\u001B[0m              edge_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     86\u001B[0m              rho \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m):\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden \u001B[38;5;241m=\u001B[39m hidden\n",
      "File \u001B[0;32m~/Master-Thesis/CKIM_Competition/venv/lib/python3.9/site-packages/torch/functional.py:1495\u001B[0m, in \u001B[0;36mnorm\u001B[0;34m(input, p, dim, keepdim, out, dtype)\u001B[0m\n\u001B[1;32m   1494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1495\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdim\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:197\u001B[0m, in \u001B[0;36mformat_stack\u001B[0;34m(f, limit)\u001B[0m\n\u001B[1;32m    196\u001B[0m     f \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39m_getframe()\u001B[38;5;241m.\u001B[39mf_back\n\u001B[0;32m--> 197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m format_list(\u001B[43mextract_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:211\u001B[0m, in \u001B[0;36mextract_stack\u001B[0;34m(f, limit)\u001B[0m\n\u001B[1;32m    210\u001B[0m     f \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39m_getframe()\u001B[38;5;241m.\u001B[39mf_back\n\u001B[0;32m--> 211\u001B[0m stack \u001B[38;5;241m=\u001B[39m \u001B[43mStackSummary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwalk_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    212\u001B[0m stack\u001B[38;5;241m.\u001B[39mreverse()\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:366\u001B[0m, in \u001B[0;36mStackSummary.extract\u001B[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001B[0m\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m result:\n\u001B[0;32m--> 366\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/usr/lib/python3.9/traceback.py:288\u001B[0m, in \u001B[0;36mFrameSummary.line\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 288\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;241m=\u001B[39m \u001B[43mlinecache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetline\u001B[49m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilename, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineno)\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from federatedscope.contrib.workers.laplacian_with_domain_separation_1MINE_Other_DiffLoss_VAE_client import LaplacianDomainSeparation1MINEOtherDiffClient\n",
    "from federatedscope.contrib.workers.laplacian_server import LaplacianServer\n",
    "\n",
    "Fed_runner = FedRunner(data=data,\n",
    "                       server_class=LaplacianServer,\n",
    "                       client_class=LaplacianDomainSeparation1MINEOtherDiffClient,\n",
    "                       config=cfg.clone(),\n",
    "                       client_config=client_cfg)\n",
    "Fed_runner.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "client 0 times: 0.346s\n",
    "bei normal fedavg: 0.15s\n",
    "mit MINE: 1.7 Sekunden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "+"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "777-431\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ",,0After 10 rounds:\n",
    "\n",
    "diff: 0, csd: 0:\n",
    "server: -8\n",
    "c1 t/val: 0.375 /0.37\n",
    "c2 t/val: 0.678 /0.606\n",
    "c3 t/val: 0.699 /0.608\n",
    "c4 t/val: 0.599 /0.537\n",
    "\n",
    "diff: 0, csd: 0:\n",
    "server: -4.5\n",
    "c1 t/val: 0.372879 /0.328\n",
    "c2 t/val: 0.678992 /0.605809\n",
    "c3 t/val: 0.70166 /0.608609\n",
    "c4 t/val: 0.597455 /0.534253\n",
    "\n",
    "\n",
    "\n",
    "diff: 10, csd: 0:\n",
    "server: -35\n",
    "c1 t/val: 0.482/0.52\n",
    "c2 t/val: 0.694/0.65\n",
    "c3 t/val: 0.724/0.65\n",
    "c4 t/val: 0.674/0.575\n",
    "\n",
    "diff: 1, csd: 0:\n",
    "server: -9.6\n",
    "c1 t/val: 0.378194/0.319349\n",
    "c2 t/val: 0.67461/0.609163\n",
    "c3 t/val: 0.705559/0.615019\n",
    "c4 t/val: 0.605581/0.572086\n",
    "\n",
    "diff: 0, csd: 1e4:\n",
    "server: -18\n",
    "c1 t/val: 0.280962/0.23074\n",
    "c2 t/val: 0.682652/0.603175\n",
    "c3 t/val: 0.699094/0.67027\n",
    "c4 t/val: 0.594985/0.609611\n",
    "\n",
    "diff: 0 csd: 1e8\n",
    "server: -18\n",
    "c1 t/val: 0.2606/0.348(0.197)\n",
    "c2 t/val: 0.653/0.0.602\n",
    "c3 t/val: 0.691/0.597\n",
    "c4 t/val: 0.581/0.629\n",
    "\n",
    "diff: 0 csd: 1e8\n",
    "server: -12.7\n",
    "c1 t/val: 0.262647/0.249875\n",
    "c2 t/val: 0.649273/0.0.600435\n",
    "c3 t/val: 0.696132/0.615158\n",
    "c4 t/val: 0.586597/0.656992\n",
    "\n",
    "\n",
    "diff: 0.1 csd: 0\n",
    "server: -11\n",
    "c1 t/val: 0.2606/0.332837\n",
    "c2 t/val: 0.678326/0.0.610099\n",
    "c3 t/val: 0.704083/0.616179\n",
    "c4 t/val: 0.604177/0.559658\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
